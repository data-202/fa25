[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Part\nWeek\nDay\nTopics\nLabs\nPapers\nReadings\n\n\n\n\nI\n1\nWed, Jan 15\nIntroduction\nLab 0\n\nCase study 1 files\n\n\n\n2\nWed, Jan 22\nFoundations\n\n\nPelham (2013, ch. 1)\n\n\n\n3\nWed, Jan 29\nTheory construction\n\nAnnotated bibliography\nFrisby (2024)\n\n\n\n4\nWed, Feb 5\nProbability theory\n\n\nGarcia, López, & Vélez (2018)\n\n\nII\n5\nWed, Feb 12\nUnivariate analysis\nLab 1\n\nCase study 2 files\n\n\n\n6\nWed, Feb 19\nBivariate analysis\n\n\n\n\n\n\n7\nWed, Feb 26\nExploratory analysis\n\nPaper 1\n\n\n\n\n8\nWed, Mar 12\nHypothesis testing\n\n\n\n\n\nIII\n9\nWed, Mar 19\nNotes on causal theories\n\n\nCase study 3 files\n\n\n\n10\nWed, Mar 26\nModeling social in/justice\nLab 2\n\n\n\n\n\n11\nWed, Apr 2\nOn regression\n\n\n\n\n\n\n12\nWed, Apr 9\nMore on regression\n\n\n\n\n\nIV\n13\nWed, Apr 16\nStatistical learning\n\nPaper 2\nCase study 4 files\n\n\n\n14\nWed, Apr 23\nOverview of additional models"
  },
  {
    "objectID": "computing.html",
    "href": "computing.html",
    "title": "Computing",
    "section": "",
    "text": "For Lab #0 you will download two software programs to your computer.\nPlease watch the below video to help you download R and RStudio.\n\n\n\n\nWatch this video to complete the steps below:\n\n\n\n\n\n\n\n\n\n\n\nOnce you have completed your downloads, check to see that you can open RStudio (not R).\nWe’ll pick up here in class next week.\n\n\n\nAfter completing Lab 0, you will use OpenAlex to support your literature identification process. OpenAlex is a comprehensive open catalog of the global research system that can help you find relevant publications for your research.\nOnce you are set up in R, try working with the code below:\n\nlibrary(openalexR)\n\n# Search for works related to your social justice topic\nworks_search &lt;- oa_fetch(\n  entity = \"works\",\n  title.search = c(\"keyword1\", \"your specific topic\"),\n  from_publication_date = \"2020-01-01\",\n  options = list(sort = \"cited_by_count:desc\"),\n  verbose = TRUE\n)\n\n# Display the top results\nworks_search |&gt;\n  head(10) |&gt;\n  show_works() |&gt;\n  knitr::kable()",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#lab-0-downloading-r-and-rstudio.",
    "href": "computing.html#lab-0-downloading-r-and-rstudio.",
    "title": "Computing",
    "section": "",
    "text": "For Lab #0 you will download two software programs to your computer.\nPlease watch the below video to help you download R and RStudio.\n\n\n\n\nWatch this video to complete the steps below:\n\n\n\n\n\n\n\n\n\n\n\nOnce you have completed your downloads, check to see that you can open RStudio (not R).\nWe’ll pick up here in class next week.\n\n\n\nAfter completing Lab 0, you will use OpenAlex to support your literature identification process. OpenAlex is a comprehensive open catalog of the global research system that can help you find relevant publications for your research.\nOnce you are set up in R, try working with the code below:\n\nlibrary(openalexR)\n\n# Search for works related to your social justice topic\nworks_search &lt;- oa_fetch(\n  entity = \"works\",\n  title.search = c(\"keyword1\", \"your specific topic\"),\n  from_publication_date = \"2020-01-01\",\n  options = list(sort = \"cited_by_count:desc\"),\n  verbose = TRUE\n)\n\n# Display the top results\nworks_search |&gt;\n  head(10) |&gt;\n  show_works() |&gt;\n  knitr::kable()",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "On the previous page, we ended with the following three points:\n\nThe syllabus provides a high-level view of the course.\nCanvas is the go-to for submissions and provides readings and assignments.\nThis course site provides technical items and code to help you complete your assignments.\n\nWe’ll focus on the syllabus, Canvas, and this companion site to get a detailed overview of our course.\n\n\nA high-level view of the course.\nPlease note: this section is only a summary of our syllabus. The full syllabus is available on our Canvas site here. I have summarized some important items found on the syllabus below:\nInstructor: Nathan Alexander, PhD\n\nContact information:\nEmail: nathan.alexander@howard.edu\nOffice hours: By appointment at https://nathanalexander.youcanbook.me\nCourse information:\nCourse meeting times: Wednesdays at 5:10pm EST (10:10pm UTC)\nCourse meeting location: Zoom (see Canvas)\n\n\n\n\nTable 1: DATA 202 course schedule (fall 2025)\n\n\n\n\n\nCourse component\nWeeks\nDates1\n\n\n\n\nPart I: Statistics and society\n4 weeks\nAug 20 - Sept 10\n\n\nPart II: Data and people\n4 weeks\nSept 17 - Oct 8\n\n\nPart III: Data and policy\n4 weeks\nOct 15 - Nov 5\n\n\nPart IV: Data in practice\n2 weeks\nNov 12 - Nov 19\n\n\n\n\n\n\n\n\n\nCanvas is the go-to for submissions, and where you can find readings and assignment rubrics. Here is another link to Canvas, I’ll try to drop these as often as possible. Two things about Canvas: it has your assignments and it has your readings.\n\n\n\nThe three categories for assignments in this course are as follows:\n\nLabs reports. Three long-form lab reports [60 points]\nHomework. Various problems related to course content [10 points]\nResearch papers\nAnnotated Bibliography. Statistical studies [10 points]\nFinal Paper. One 20-page paper [30 points]\n\n\n\n\n\n\n\n\n\n\n\nThis course should be viewed as an intense but remote introduction to what we might label “critical statistics” or “social justice statistics”. It will be important that we gain both a conceptual and theoretical understanding of the various concepts we will explore, and then a technical understanding of the complex issues that relate to them. We also want to communicate our ideas. These can be difficult tasks.\nBut I encourage you to explore and to be creative, and to take chances. Errors should mostly remind us that there is always the backspace button. Below are some general expectations to keep us all moving forward as a community:\n\n\nCommunicate early and often\nShow up to class on time\nDo not schedule other meetings during class time\nNo late work will be accepted without prior discussion\n\n\n\n\n\n\nYou can return to this page to remind yourself of the four parts of our course, especially when we dive deep into specific projects. This page will remain static (it will not be updated), so use it as an archive that you can return to; start in this page position if you have questions about the schedule, procedures, expectations (above) …then assignments (next).\n\n\n\nIn the next section, we’ll start with a brief overview of assignments and dive into your first two assignments (ungraded). The HW #0 and Lab #0 assignments will serve two purposes: first, they will help introduce you to the tools we’ll use as we begin to review statistical concepts; second, they will set you up for your first graded assignment coming up in two weeks.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#a-slightly-more-detailed-overview.",
    "href": "course-overview.html#a-slightly-more-detailed-overview.",
    "title": "Course overview",
    "section": "",
    "text": "On the previous page, we ended with the following three points:\n\nThe syllabus provides a high-level view of the course.\nCanvas is the go-to for submissions and provides readings and assignments.\nThis course site provides technical items and code to help you complete your assignments.\n\nWe’ll focus on the syllabus, Canvas, and this companion site to get a detailed overview of our course.\n\n\nA high-level view of the course.\nPlease note: this section is only a summary of our syllabus. The full syllabus is available on our Canvas site here. I have summarized some important items found on the syllabus below:\nInstructor: Nathan Alexander, PhD\n\nContact information:\nEmail: nathan.alexander@howard.edu\nOffice hours: By appointment at https://nathanalexander.youcanbook.me\nCourse information:\nCourse meeting times: Wednesdays at 5:10pm EST (10:10pm UTC)\nCourse meeting location: Zoom (see Canvas)\n\n\n\n\nTable 1: DATA 202 course schedule (fall 2025)\n\n\n\n\n\nCourse component\nWeeks\nDates1\n\n\n\n\nPart I: Statistics and society\n4 weeks\nAug 20 - Sept 10\n\n\nPart II: Data and people\n4 weeks\nSept 17 - Oct 8\n\n\nPart III: Data and policy\n4 weeks\nOct 15 - Nov 5\n\n\nPart IV: Data in practice\n2 weeks\nNov 12 - Nov 19\n\n\n\n\n\n\n\n\n\nCanvas is the go-to for submissions, and where you can find readings and assignment rubrics. Here is another link to Canvas, I’ll try to drop these as often as possible. Two things about Canvas: it has your assignments and it has your readings.\n\n\n\nThe three categories for assignments in this course are as follows:\n\nLabs reports. Three long-form lab reports [60 points]\nHomework. Various problems related to course content [10 points]\nResearch papers\nAnnotated Bibliography. Statistical studies [10 points]\nFinal Paper. One 20-page paper [30 points]\n\n\n\n\n\n\n\n\n\n\n\nThis course should be viewed as an intense but remote introduction to what we might label “critical statistics” or “social justice statistics”. It will be important that we gain both a conceptual and theoretical understanding of the various concepts we will explore, and then a technical understanding of the complex issues that relate to them. We also want to communicate our ideas. These can be difficult tasks.\nBut I encourage you to explore and to be creative, and to take chances. Errors should mostly remind us that there is always the backspace button. Below are some general expectations to keep us all moving forward as a community:\n\n\nCommunicate early and often\nShow up to class on time\nDo not schedule other meetings during class time\nNo late work will be accepted without prior discussion\n\n\n\n\n\n\nYou can return to this page to remind yourself of the four parts of our course, especially when we dive deep into specific projects. This page will remain static (it will not be updated), so use it as an archive that you can return to; start in this page position if you have questions about the schedule, procedures, expectations (above) …then assignments (next).\n\n\n\nIn the next section, we’ll start with a brief overview of assignments and dive into your first two assignments (ungraded). The HW #0 and Lab #0 assignments will serve two purposes: first, they will help introduce you to the tools we’ll use as we begin to review statistical concepts; second, they will set you up for your first graded assignment coming up in two weeks.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#footnotes",
    "href": "course-overview.html#footnotes",
    "title": "Course overview",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlease note that these are rough estimates↩︎",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "cases/case01.html",
    "href": "cases/case01.html",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "",
    "text": "In Case Study 1, we will explore the ethics and quantification.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 1"
    ]
  },
  {
    "objectID": "cases/case01.html#learning-objectives",
    "href": "cases/case01.html#learning-objectives",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe goal of this lab is to introduce you to or remind you of the historical case that contributed to the development of the Institutional Review Board. This case is the Tuskegee Study of Untreated Syphilis in the Negro Male. Case files can be found below and in week 1.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 1"
    ]
  },
  {
    "objectID": "cases/case01.html#learning-activities",
    "href": "cases/case01.html#learning-activities",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this case study you will be able to:\n\nIdentify historical issues of ethics and quantification\nDiscuss the Institutional Review Board (IRB) and its purposes",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 1"
    ]
  },
  {
    "objectID": "cases/case01.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "href": "cases/case01.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Case Study 1: Tuskegee Experiement of Untreated Syphillis",
    "text": "Case Study 1: Tuskegee Experiement of Untreated Syphillis\nTo help you prepare for our forthcoming discussions and readings, you should explore information about our first case study. One place to start is here: “The Tuskegee Experiment: Crash Course Black American History #29” in the video below:",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 1"
    ]
  },
  {
    "objectID": "cases/week01-slides.html#learning-objectives",
    "href": "cases/week01-slides.html#learning-objectives",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe goal of this lab is to introduce you to or remind you of the historical case that contributed to the development of the Institutional Review Board. This case is the Tuskegee Study of Untreated Syphilis in the Negro Male. Case files can be found below and in week 1."
  },
  {
    "objectID": "cases/week01-slides.html#learning-activities",
    "href": "cases/week01-slides.html#learning-activities",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this case study you will be able to:\n\nIdentify historical issues of ethics and quantification\nDiscuss the Institutional Review Board (IRB) and its purposes"
  },
  {
    "objectID": "cases/week01-slides.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "href": "cases/week01-slides.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "title": "Case Study 1: Tuskegee Study of Untreated Syphillis in the Negro Male",
    "section": "Case Study 1: Tuskegee Experiement of Untreated Syphillis",
    "text": "Case Study 1: Tuskegee Experiement of Untreated Syphillis\nTo help you prepare for our forthcoming discussions and readings, you should explore information about our first case study. One place to start is here: “The Tuskegee Experiment: Crash Course Black American History #29” in the video below:"
  },
  {
    "objectID": "cases/case02-pt2.html",
    "href": "cases/case02-pt2.html",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "",
    "text": "In Case Study 2, we will explore the social politics of maps and globally oriented data to help us make sense of what we mean by a “population.” The case study will integrate a series of new packages, functions, and code to support our explorations.\nThere are two parts to this case study, this is part 2.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#learning-objectives",
    "href": "cases/case02-pt2.html#learning-objectives",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThis case study component will teach you how to use functions in dplyr to manipulate variables and data frames. You will also learn some base-R functions to conduct univariate analysis in the RStudio IDE.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#learning-activities",
    "href": "cases/case02-pt2.html#learning-activities",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this case study you will be able to:\n\nInstall and/or update R packages\nAssign data frames to different names for efficient exploration\nGenerate a set of outputs using the dplyr package\nOverwrite a data frame while using the pipe operator\nProduce simple plots using data located in an R package\n\n\nReminder: Load lackages and libraries\n\n# install package\n# install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n# install.packages(\"remotes\", repos = \"http://cran.us.r-project.org\")\n \n# load the necessary libraries\nlibrary(tidyverse) #collection of R packages designed for data science\nlibrary(dplyr)\nlibrary(remotes)",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#task-2.1-load-the-africa_data_all-data",
    "href": "cases/case02-pt2.html#task-2.1-load-the-africa_data_all-data",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Task 2.1: Load the africa_data_all data",
    "text": "Task 2.1: Load the africa_data_all data\nThe africa_data_all data set will be used for instructional purposes only.\nThe data in this data frame was collected from the internet.\nThe data frame contains data on African countries and territories for two years: 2020 and 2023.\n\nTask 2.1.1: Call the africa_data_all data\nWe begin by taking a look at the data.\n\ncritstats::africa_data_all \n\nWhat are some of your early observations?\n\n\nTask 2.1.2: Inspect africa_data_all documentation\nThe documentation can help us get a better idea of the data frame’s content.\n\n??critstats::africa_data_all \n\nIf, by chance, you cannot load the documentation or experience issues with the critstats data package, you may need to restart your RStudio session.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#task-2.2-prepare-the-africa_data_all-data",
    "href": "cases/case02-pt2.html#task-2.2-prepare-the-africa_data_all-data",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Task 2.2: Prepare the africa_data_all data",
    "text": "Task 2.2: Prepare the africa_data_all data\nTo be efficient, we will only use specific functions to explore the data set.\nPlease note that there are many other approaches to exploration.\nThe approach taken below is one of many possibiliites.\n\nTask 2.2.1: Assign africa_data_all to df2\nUse the assignment operator to assign the africa_data_all data frame to the object df2.\n\ndf2 &lt;- critstats::africa_data_all\n\nWe can now work more efficiently by typing df2 when we want to call the data frame. Notice that I did not overwrite df1 in the event you want to return to Part 1 of this case study.\n\n\nTask 2.2.2: Inspect your data\nThe str() function displays the structure of R objects.\n\nstr(df2)\n\ntibble [116 × 13] (S3: tbl_df/tbl/data.frame)\n $ country          : chr [1:116] \"Nigeria\" \"Ethiopia\" \"Egypt\" \"DR Congo\" ...\n $ pop              : num [1:116] 2.06e+08 1.15e+08 1.02e+08 8.96e+07 5.93e+07 ...\n $ pop.yearly.change: num [1:116] 2.58 2.57 1.94 3.19 1.28 2.98 2.28 3.32 1.85 2.42 ...\n $ pop.net.change   : num [1:116] 5175990 2884858 1946331 2770836 750420 ...\n $ density          : num [1:116] 226 115 103 40 49 67 94 229 18 25 ...\n $ area             : num [1:116] 910770 1000000 995450 2267050 1213090 ...\n $ migrants         : num [1:116] -60000 30000 -38033 23861 145405 ...\n $ fertility.rate   : num [1:116] 5.4 4.3 3.3 6 2.4 4.9 3.5 5 3.1 4.4 ...\n $ med.age          : num [1:116] 18 19 25 17 28 18 20 17 29 20 ...\n $ urban.pop        : num [1:116] 52 21 43 46 67 37 28 26 73 35 ...\n $ world.share      : num [1:116] 2.64 1.47 1.31 1.15 0.76 0.77 0.69 0.59 0.56 0.56 ...\n $ pop_in_mill      : num [1:116] 206.1 115 102.3 89.6 59.3 ...\n $ year             : num [1:116] 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 ...\n\n\nUse head() to view the “top” of your data.\n\nhead(df2)\n\n# A tibble: 6 × 13\n  country           pop pop.yearly.change pop.net.change density   area migrants\n  &lt;chr&gt;           &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Nigeria        2.06e8              2.58        5175990     226 9.11e5   -60000\n2 Ethiopia       1.15e8              2.57        2884858     115 1   e6    30000\n3 Egypt          1.02e8              1.94        1946331     103 9.95e5   -38033\n4 DR Congo       8.96e7              3.19        2770836      40 2.27e6    23861\n5 South Africa   5.93e7              1.28         750420      49 1.21e6   145405\n6 Tanzania       5.97e7              2.98        1728755      67 8.86e5   -40076\n# ℹ 6 more variables: fertility.rate &lt;dbl&gt;, med.age &lt;dbl&gt;, urban.pop &lt;dbl&gt;,\n#   world.share &lt;dbl&gt;, pop_in_mill &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nUse tail() to view the “bottom” of your data.\n\ntail(df2)\n\n# A tibble: 6 × 13\n  country           pop pop.yearly.change pop.net.change density   area migrants\n  &lt;chr&gt;           &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Cabo Verde     598682              0.93           5533     149   4030    -1227\n2 Western Sahara 587259              1.96          11273       2 266000     5600\n3 Mayotte        335995              3.03           9894     896    375        0\n4 Sao Tome & Pr… 231856              1.97           4476     242    960     -600\n5 Seychelles     107660              0.51            542     234    460     -200\n6 Saint Helena     5314             -1.12            -60      14    390        0\n# ℹ 6 more variables: fertility.rate &lt;dbl&gt;, med.age &lt;dbl&gt;, urban.pop &lt;dbl&gt;,\n#   world.share &lt;dbl&gt;, pop_in_mill &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nView your data using the view() command.\n\nView(df2)\n\nGet a summary of your data with summary().\n\nsummary(df2)\n\n   country               pop            pop.yearly.change pop.net.change   \n Length:116         Min.   :     5314   Min.   :-1.120    Min.   :    -60  \n Class :character   1st Qu.:  2346300   1st Qu.: 1.567    1st Qu.:  46843  \n Mode  :character   Median : 12705220   Median : 2.400    Median : 320017  \n                    Mean   : 24147241   Mean   : 2.141    Mean   : 571374  \n                    3rd Qu.: 29236208   3rd Qu.: 2.732    3rd Qu.: 700895  \n                    Max.   :223804632   Max.   : 3.840    Max.   :5263420  \n                                                                           \n    density           area            migrants       fertility.rate \n Min.   :  2.0   Min.   :    375   Min.   :-174200   Min.   :1.400  \n 1st Qu.: 25.0   1st Qu.:  28120   1st Qu.: -10024   1st Qu.:3.150  \n Median : 64.0   Median : 269800   Median :  -4000   Median :4.100  \n Mean   :124.5   Mean   : 511181   Mean   :  -8680   Mean   :3.983  \n 3rd Qu.:137.2   3rd Qu.: 823290   3rd Qu.:   -100   3rd Qu.:4.700  \n Max.   :896.0   Max.   :2381740   Max.   : 168694   Max.   :7.000  \n                                   NA's   :1         NA's   :1      \n    med.age       urban.pop       world.share      pop_in_mill       \n Min.   :15.0   Min.   : 14.00   Min.   :0.0000   Min.   :5.314e-03  \n 1st Qu.:18.0   1st Qu.: 35.00   1st Qu.:0.0300   1st Qu.:2.346e+00  \n Median :19.0   Median : 46.00   Median :0.1600   Median :1.271e+01  \n Mean   :21.3   Mean   : 49.15   Mean   :0.3048   Mean   :2.415e+01  \n 3rd Qu.:22.5   3rd Qu.: 66.25   3rd Qu.:0.3650   3rd Qu.:2.924e+01  \n Max.   :53.0   Max.   :100.00   Max.   :2.7800   Max.   :2.238e+02  \n NA's   :1                                                           \n      year     \n Min.   :2020  \n 1st Qu.:2020  \n Median :2022  \n Mean   :2022  \n 3rd Qu.:2023  \n Max.   :2023  \n               \n\n\nTake note of the content and values of the data and its structure.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#task-2.3-examine-the-data-in-detail",
    "href": "cases/case02-pt2.html#task-2.3-examine-the-data-in-detail",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Task 2.3: Examine the data in detail",
    "text": "Task 2.3: Examine the data in detail\nBefore starting any analyses, we want to make sure we really understand our data.\nYou may have noticed that there is a year variable in the data set.\nSpecifically, the variable year separates the 2020 and 2023 data.\n\nTask 2.3.1: Make a table of a single variable’s contents\nTo examine how many data values are listed by year we can use table().\n\n# create a table of the number of observations by year\ntable(df2$year)\n\n\n2020 2023 \n  58   58 \n\n\nWe notice 58 values for each year. What does this say about our data?\n\n\nTask 2.3.2: Gather summary statistics for the data by year\nThere are different ways to gather summary statistics by year.\nI can nest the request using some logic and the year 2020 as follows:\n\nsummary(filter(df2, year == 2020))\n\n   country               pop            pop.yearly.change pop.net.change   \n Length:58          Min.   :     6077   Min.   :0.170     Min.   :     18  \n Class :character   1st Qu.:  2257207   1st Qu.:1.555     1st Qu.:  47292  \n Mode  :character   Median : 12006992   Median :2.450     Median : 269752  \n                    Mean   : 23113761   Mean   :2.212     Mean   : 560930  \n                    3rd Qu.: 27404729   3rd Qu.:2.810     3rd Qu.: 667545  \n                    Max.   :206139589   Max.   :3.840     Max.   :5175990  \n                                                                           \n    density           area            migrants       fertility.rate \n Min.   :  2.0   Min.   :    375   Min.   :-174200   Min.   :1.400  \n 1st Qu.: 25.0   1st Qu.:  28680   1st Qu.: -10047   1st Qu.:3.300  \n Median : 61.5   Median : 269800   Median :  -4000   Median :4.400  \n Mean   :119.0   Mean   : 511181   Mean   :  -8124   Mean   :4.144  \n 3rd Qu.:131.5   3rd Qu.: 814062   3rd Qu.:      0   3rd Qu.:4.800  \n Max.   :728.0   Max.   :2381740   Max.   : 168694   Max.   :7.000  \n                                   NA's   :1         NA's   :1      \n    med.age        urban.pop       world.share      pop_in_mill       \n Min.   :15.00   Min.   : 14.00   Min.   :0.0000   Min.   :6.077e-03  \n 1st Qu.:18.00   1st Qu.: 35.50   1st Qu.:0.0300   1st Qu.:2.257e+00  \n Median :19.00   Median : 46.00   Median :0.1550   Median :1.201e+01  \n Mean   :21.46   Mean   : 48.90   Mean   :0.2964   Mean   :2.311e+01  \n 3rd Qu.:23.00   3rd Qu.: 63.75   3rd Qu.:0.3550   3rd Qu.:2.740e+01  \n Max.   :37.00   Max.   :100.00   Max.   :2.6400   Max.   :2.061e+02  \n NA's   :1                                                            \n      year     \n Min.   :2020  \n 1st Qu.:2020  \n Median :2020  \n Mean   :2020  \n 3rd Qu.:2020  \n Max.   :2020  \n               \n\n\nConsider why filter(summary(df2, year == 2020)) returns an error.\nWe can also use the %&gt;% operator to list the commands in order for 2020.\n\n# gather summary statistics for all variables for year == 2020\ndf2 %&gt;% \n  filter(year == 2020) %&gt;% \n  summary()\n\n   country               pop            pop.yearly.change pop.net.change   \n Length:58          Min.   :     6077   Min.   :0.170     Min.   :     18  \n Class :character   1st Qu.:  2257207   1st Qu.:1.555     1st Qu.:  47292  \n Mode  :character   Median : 12006992   Median :2.450     Median : 269752  \n                    Mean   : 23113761   Mean   :2.212     Mean   : 560930  \n                    3rd Qu.: 27404729   3rd Qu.:2.810     3rd Qu.: 667545  \n                    Max.   :206139589   Max.   :3.840     Max.   :5175990  \n                                                                           \n    density           area            migrants       fertility.rate \n Min.   :  2.0   Min.   :    375   Min.   :-174200   Min.   :1.400  \n 1st Qu.: 25.0   1st Qu.:  28680   1st Qu.: -10047   1st Qu.:3.300  \n Median : 61.5   Median : 269800   Median :  -4000   Median :4.400  \n Mean   :119.0   Mean   : 511181   Mean   :  -8124   Mean   :4.144  \n 3rd Qu.:131.5   3rd Qu.: 814062   3rd Qu.:      0   3rd Qu.:4.800  \n Max.   :728.0   Max.   :2381740   Max.   : 168694   Max.   :7.000  \n                                   NA's   :1         NA's   :1      \n    med.age        urban.pop       world.share      pop_in_mill       \n Min.   :15.00   Min.   : 14.00   Min.   :0.0000   Min.   :6.077e-03  \n 1st Qu.:18.00   1st Qu.: 35.50   1st Qu.:0.0300   1st Qu.:2.257e+00  \n Median :19.00   Median : 46.00   Median :0.1550   Median :1.201e+01  \n Mean   :21.46   Mean   : 48.90   Mean   :0.2964   Mean   :2.311e+01  \n 3rd Qu.:23.00   3rd Qu.: 63.75   3rd Qu.:0.3550   3rd Qu.:2.740e+01  \n Max.   :37.00   Max.   :100.00   Max.   :2.6400   Max.   :2.061e+02  \n NA's   :1                                                            \n      year     \n Min.   :2020  \n 1st Qu.:2020  \n Median :2020  \n Mean   :2020  \n 3rd Qu.:2020  \n Max.   :2020  \n               \n\n\nWe can use the same commands to filter the data for 2023.\n\n# gather summary statistics for all variables for year == 2023\ndf2 %&gt;% \n  filter(year == 2023) %&gt;% \n  summary()\n\n   country               pop            pop.yearly.change pop.net.change   \n Length:58          Min.   :     5314   Min.   :-1.120    Min.   :    -60  \n Class :character   1st Qu.:  2478468   1st Qu.: 1.580    1st Qu.:  45111  \n Mode  :character   Median : 13475694   Median : 2.300    Median : 324628  \n                    Mean   : 25180720   Mean   : 2.071    Mean   : 581818  \n                    3rd Qu.: 29962558   3rd Qu.: 2.667    3rd Qu.: 702468  \n                    Max.   :223804632   Max.   : 3.800    Max.   :5263420  \n    density            area            migrants       fertility.rate \n Min.   :  2.00   Min.   :    375   Min.   :-126181   Min.   :1.400  \n 1st Qu.: 27.25   1st Qu.:  28680   1st Qu.: -10000   1st Qu.:2.825  \n Median : 65.50   Median : 269800   Median :  -4000   Median :3.900  \n Mean   :130.05   Mean   : 511181   Mean   :  -9228   Mean   :3.824  \n 3rd Qu.:143.50   3rd Qu.: 814062   3rd Qu.:   -300   3rd Qu.:4.375  \n Max.   :896.00   Max.   :2381740   Max.   :  58496   Max.   :6.700  \n    med.age        urban.pop      world.share      pop_in_mill       \n Min.   :15.00   Min.   :15.00   Min.   :0.0000   Min.   :5.314e-03  \n 1st Qu.:17.00   1st Qu.:35.50   1st Qu.:0.0300   1st Qu.:2.478e+00  \n Median :19.00   Median :46.00   Median :0.1650   Median :1.348e+01  \n Mean   :21.14   Mean   :49.40   Mean   :0.3133   Mean   :2.518e+01  \n 3rd Qu.:22.00   3rd Qu.:66.75   3rd Qu.:0.3750   3rd Qu.:2.996e+01  \n Max.   :53.00   Max.   :95.00   Max.   :2.7800   Max.   :2.238e+02  \n      year     \n Min.   :2023  \n 1st Qu.:2023  \n Median :2023  \n Mean   :2023  \n 3rd Qu.:2023  \n Max.   :2023",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#task-2.4-get-univariate-statistics",
    "href": "cases/case02-pt2.html#task-2.4-get-univariate-statistics",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Task 2.4: Get univariate statistics",
    "text": "Task 2.4: Get univariate statistics\nTo help advance our understanding of statistical analyses in the RStudio IDE, we will lean a few tasks to compute univariate statistics. You are likely familiar with univariate statistics. Univariate statistics are statistics done on a single variable. Some base R functions for univariate statistics are as follows:\n\nmean() returns the mean of a single numeric variable\nmedian() returns the middle value of a single numeric variable\nmode() returns the variable type for the mode of a single variable\ntable() returns a frequency table with counts of each level for a single variable\nmax() returns the maximum value of a single numeric variable\nmin() returns the minimum value of a single numeric variable\nrange() returns the min() and max() values of a single numeric variable\nIQR() returns the interquartile range values for a single numeric variable\nsd() returns the standard deviation for a single numeric variable\nboxplot() returns a boxplot of a numeric variable or variables\nhist() returns a histogram of a single numeric variable\nstem() provides a stem-and-leaf plot when a single numeric variable is input.\nplot() provides a scatter plot of data values by its index, \\(i\\).\nplot(density()) provides a density plot of a single numeric variable\n\nEach of the above functions provides a different perspective on the distribution of values for a single variable.\n\nTask 2.4.1: Inspect data prior to analysis\nFrom our earlier observations, we see that the africa_data_all (df2) contains data across two years: 2020 and 2023. Let’s use pipes %&gt;% to create separate data from for each year.\n\n# create a separate data frame for 2020\ndata_2020 &lt;- df2 %&gt;% \n  filter(year == 2020)\n\ndata_2020 # view the data for 2020\n\n# A tibble: 58 × 13\n   country          pop pop.yearly.change pop.net.change density   area migrants\n   &lt;chr&gt;          &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 Nigeria       2.06e8              2.58        5175990     226 9.11e5   -60000\n 2 Ethiopia      1.15e8              2.57        2884858     115 1   e6    30000\n 3 Egypt         1.02e8              1.94        1946331     103 9.95e5   -38033\n 4 DR Congo      8.96e7              3.19        2770836      40 2.27e6    23861\n 5 South Africa  5.93e7              1.28         750420      49 1.21e6   145405\n 6 Tanzania      5.97e7              2.98        1728755      67 8.86e5   -40076\n 7 Kenya         5.38e7              2.28        1197323      94 5.69e5   -10000\n 8 Uganda        4.57e7              3.32        1471413     229 2.00e5   168694\n 9 Algeria       4.39e7              1.85         797990      18 2.38e6   -10000\n10 Sudan         4.38e7              2.42        1036022      25 1.77e6   -50000\n# ℹ 48 more rows\n# ℹ 6 more variables: fertility.rate &lt;dbl&gt;, med.age &lt;dbl&gt;, urban.pop &lt;dbl&gt;,\n#   world.share &lt;dbl&gt;, pop_in_mill &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nIt is not clear that this data is for 2020. As a result, we can reorganize the columns and overwrite the data frame.\nI am moving the year variable to the second position in the data frame.\n\ndata_2020 &lt;- df2 %&gt;% \n  filter(year == 2020) %&gt;% \n  relocate(country, year)\n\ndata_2020 # view the data for 2020\n\n# A tibble: 58 × 13\n   country  year    pop pop.yearly.change pop.net.change density   area migrants\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 Nigeria  2020 2.06e8              2.58        5175990     226 9.11e5   -60000\n 2 Ethiop…  2020 1.15e8              2.57        2884858     115 1   e6    30000\n 3 Egypt    2020 1.02e8              1.94        1946331     103 9.95e5   -38033\n 4 DR Con…  2020 8.96e7              3.19        2770836      40 2.27e6    23861\n 5 South …  2020 5.93e7              1.28         750420      49 1.21e6   145405\n 6 Tanzan…  2020 5.97e7              2.98        1728755      67 8.86e5   -40076\n 7 Kenya    2020 5.38e7              2.28        1197323      94 5.69e5   -10000\n 8 Uganda   2020 4.57e7              3.32        1471413     229 2.00e5   168694\n 9 Algeria  2020 4.39e7              1.85         797990      18 2.38e6   -10000\n10 Sudan    2020 4.38e7              2.42        1036022      25 1.77e6   -50000\n# ℹ 48 more rows\n# ℹ 5 more variables: fertility.rate &lt;dbl&gt;, med.age &lt;dbl&gt;, urban.pop &lt;dbl&gt;,\n#   world.share &lt;dbl&gt;, pop_in_mill &lt;dbl&gt;\n\n\nWe can run the same functions for year == 2023.\n\n# create a separate data frame for 2023\ndata_2023 &lt;- df2 %&gt;% \n  filter(year == 2023) %&gt;% \n  relocate(country, year)\n\ndata_2023 # view the data for 2023\n\n# A tibble: 58 × 13\n   country  year    pop pop.yearly.change pop.net.change density   area migrants\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 Nigeria  2023 2.24e8              2.41        5263420     246 9.11e5   -59996\n 2 Ethiop…  2023 1.27e8              2.55        3147136     127 1   e6   -11999\n 3 Egypt    2023 1.13e8              1.56        1726495     113 9.95e5   -29998\n 4 DR Con…  2023 1.02e8              3.29        3252596      45 2.27e6   -14999\n 5 Tanzan…  2023 6.74e7              2.96        1940358      76 8.86e5   -39997\n 6 South …  2023 6.04e7              0.87         520610      50 1.21e6    58496\n 7 Kenya    2023 5.51e7              1.99        1073099      97 5.69e5   -10000\n 8 Sudan    2023 4.81e7              2.63        1234802      27 1.77e6    -9999\n 9 Uganda   2023 4.86e7              2.82        1332749     243 2.00e5  -126181\n10 Algeria  2023 4.56e7              1.57         703255      19 2.38e6    -9999\n# ℹ 48 more rows\n# ℹ 5 more variables: fertility.rate &lt;dbl&gt;, med.age &lt;dbl&gt;, urban.pop &lt;dbl&gt;,\n#   world.share &lt;dbl&gt;, pop_in_mill &lt;dbl&gt;\n\n\nIt is now clearer which year we are loading when we view the data frames.\n\n\nTask 2.4.1a: Check for missing data\nWe can check the entire data frame for missing values using is.na().\n\nis.na(data_2020)\n\nis.na(data_2023)\n\nYou can see that this output is far too extensive.\nWe should check for missing values for a specific variable first.\nLet’s use the migrants variable in the df2 data frame by inserting df2$migrants.\nThe code to check for missing values in the 2020 data frame for the variable migrant is as follows:\n\nis.na(data_2020$migrants)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nNotice that there is a missing value for the variable migrant in the 2020 data.\nIt may be important to see the total number of missing values in the data frame. We can check the number of missing values for each variable using sapply(). The sapply() is a base-R function and it is used for different purposes. Here is an example:\n\nsapply(data_2020, function(x) sum(is.na(x)))\n\n          country              year               pop pop.yearly.change \n                0                 0                 0                 0 \n   pop.net.change           density              area          migrants \n                0                 0                 0                 1 \n   fertility.rate           med.age         urban.pop       world.share \n                1                 1                 0                 0 \n      pop_in_mill \n                0 \n\n\nsapply() is a loop function and the above code iterates the function for each variable in the df2 data set.\nThe logic of the function is sapply(data, FUNction...).\nFrom the output, we notice that a few different variables have a missing value.\nYou can use the view() function to take a closer look at the data to find the missing values.\nWhat do you notice about the source of the missing values when using view()?\n\n\nTask 2.4.1b: Working with missing values\nIn class, we will learn how to deal with missing values. For now, you can remove missing values using the code below or select those variables that has no missing values for your case study reports.\nWhen conducting univariate statistics, we can simply tell R to ignore missing values.\n\n# mean returns `NA` since there are missing values\nmean(data_2020$migrants)\n\n[1] NA\n\n\nUse na.rm = TRUE to remove missing values from a numeric variable\n\n# instruct R to remove missing values from the analysis using `\nmean(data_2020$migrants, na.rm = TRUE)\n\n[1] -8123.684\n\n\nThere are some exceptions here and it relates to the type of variable being used. We’ll explore missing values in class.\n\nFor our next set of tasks, we will focus on variables in the data_2020 data frame.\nRecall that data_2020 was used as a label for africa_data_all when year == 2020.\n\n\nTask 2.4.2: mean()\nThe mean() function returns the mean of a single numeric variable.\n\n# find the average population in 2020\nmean(data_2020$pop)\n\n[1] 23113761\n\n# find the average percent urban population in 2020\nmean(data_2020$urban.pop)\n\n[1] 48.89655\n\n# find the average of median age in 2020\nmean(data_2020$med.age)\n\n[1] NA\n\n\nNotice that the last command returns NA due to missing values.\nWe can correct this by using na.rm = TRUE.\n\n# check to see missing data in the variable\nis.na(data_2020$med.age)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n# compute the mean using the na.rm = TRUE\nmean(data_2020$med.age, na.rm = TRUE)\n\n[1] 21.45614\n\n\n\n\nTask 2.4.3: median()\nThe median() function returns the middle value of a single numeric variable.\n\nmedian(data_2020$pop)\n\n[1] 12006992\n\n\nWe can also use pipe operators to filter the countries that are above and below the median values.\n\n# filter data to show countries that are below the median\ndata_2020 %&gt;% \n  filter(pop &lt; median(pop)) %&gt;% \n  select(country, pop)\n\n# A tibble: 29 × 2\n   country                       pop\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 Tunisia                  11818619\n 2 Burundi                  11890784\n 3 South Sudan              11193725\n 4 Togo                      8278724\n 5 Sierra Leone              7976983\n 6 Libya                     6871292\n 7 Congo                     5518087\n 8 Liberia                   5057681\n 9 Central African Republic  4829767\n10 Mauritania                4649658\n# ℹ 19 more rows\n\n# filter data to show countries that are above the median\ndata_2020 %&gt;% \n  filter(pop &gt; median(pop)) %&gt;% \n  select(country, pop)\n\n# A tibble: 29 × 2\n   country            pop\n   &lt;chr&gt;            &lt;dbl&gt;\n 1 Nigeria      206139589\n 2 Ethiopia     114963588\n 3 Egypt        102334404\n 4 DR Congo      89561403\n 5 South Africa  59308690\n 6 Tanzania      59734218\n 7 Kenya         53771296\n 8 Uganda        45741007\n 9 Algeria       43851044\n10 Sudan         43849260\n# ℹ 19 more rows\n\n\n\n\nTask 2.4.4: mode() and table()\nThe mode() function returns the variable type for the mode of a single variable.\n\n# what does this output tell us about the mode of the med.age variable?\nmode(data_2020$med.age) \n\n[1] \"numeric\"\n\n\nWe can use the table() function to get our mode.\nThe table() function returns a frequency table with counts of each level for a single variable.\n\n# what does this updated output tell us about the mode of the med.age variable?\ntable(data_2020$med.age) \n\n\n15 16 17 18 19 20 21 22 23 24 25 27 28 29 30 33 34 36 37 \n 1  1  6  9 14  7  1  3  1  2  1  1  3  2  1  1  1  1  1 \n\n\n\n\nTask 2.4.5: max() and min()\nThe max() function returns the maximum value of a single numeric variable.\n\n# get the maximum value\nmax(data_2020$pop)\n\n[1] 206139589\n\n# use pipes to gather details about which country or territory has the max value\ndata_2020 %&gt;% \n  filter(pop == max(pop)) %&gt;% \n  select(country, pop)\n\n# A tibble: 1 × 2\n  country       pop\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Nigeria 206139589\n\n\nThe min() function returns the minimum value of a single numeric variable.\n\n# get the minimum value\nmin(data_2020$pop)\n\n[1] 6077\n\n# use pipes to gather details about which country or territory has the min value\ndata_2020 %&gt;% \n  filter(pop == min(pop)) %&gt;% \n  select(country, pop)\n\n# A tibble: 1 × 2\n  country        pop\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Saint Helena  6077\n\n\n\n\nTask 2.4.6: range()\nThe range() function returns the min() and max() values of a single numeric variable.\n\nrange(data_2020$pop)\n\n[1]      6077 206139589\n\n\nHowever, we can manually compute the range by using arithmetic with our functions.\n\n# generate a new variable call population range that is the maximum minus the minimum value\npop_range_2020 &lt;- max(data_2020$pop) - min(data_2020$pop)\npop_range_2020 # we must call the object back to see its value\n\n[1] 206133512\n\n\n\n\nTask 2.4.7: IQR()\n\n# find the IQR for the 2020 population variable\nIQR(data_2020$pop)\n\n[1] 25147522\n\n# find the IQR for the 2020 percent urban population variable\nIQR(data_2020$urban.pop)\n\n[1] 28.25\n\n\n\n\nTask 2.4.8: sd()\nThe sd() function returns the standard deviation for a single numeric variable.\n\n# find the standard deviation of the 2020 population variable\nsd(data_2020$pop)\n\n[1] 35061685\n\n# find the standard deviation of the 2020 urban population variable\nsd(data_2020$urban.pop)\n\n[1] 19.83501\n\n\n\n\nTask 2.4.8: Use summary()\nThe summary() function is often more efficient for a quick check of univariate statistics.\n\nsummary(data_2020)\n\n   country               year           pop            pop.yearly.change\n Length:58          Min.   :2020   Min.   :     6077   Min.   :0.170    \n Class :character   1st Qu.:2020   1st Qu.:  2257207   1st Qu.:1.555    \n Mode  :character   Median :2020   Median : 12006992   Median :2.450    \n                    Mean   :2020   Mean   : 23113761   Mean   :2.212    \n                    3rd Qu.:2020   3rd Qu.: 27404729   3rd Qu.:2.810    \n                    Max.   :2020   Max.   :206139589   Max.   :3.840    \n                                                                        \n pop.net.change       density           area            migrants      \n Min.   :     18   Min.   :  2.0   Min.   :    375   Min.   :-174200  \n 1st Qu.:  47292   1st Qu.: 25.0   1st Qu.:  28680   1st Qu.: -10047  \n Median : 269752   Median : 61.5   Median : 269800   Median :  -4000  \n Mean   : 560930   Mean   :119.0   Mean   : 511181   Mean   :  -8124  \n 3rd Qu.: 667545   3rd Qu.:131.5   3rd Qu.: 814062   3rd Qu.:      0  \n Max.   :5175990   Max.   :728.0   Max.   :2381740   Max.   : 168694  \n                                                     NA's   :1        \n fertility.rate     med.age        urban.pop       world.share    \n Min.   :1.400   Min.   :15.00   Min.   : 14.00   Min.   :0.0000  \n 1st Qu.:3.300   1st Qu.:18.00   1st Qu.: 35.50   1st Qu.:0.0300  \n Median :4.400   Median :19.00   Median : 46.00   Median :0.1550  \n Mean   :4.144   Mean   :21.46   Mean   : 48.90   Mean   :0.2964  \n 3rd Qu.:4.800   3rd Qu.:23.00   3rd Qu.: 63.75   3rd Qu.:0.3550  \n Max.   :7.000   Max.   :37.00   Max.   :100.00   Max.   :2.6400  \n NA's   :1       NA's   :1                                        \n  pop_in_mill       \n Min.   :6.077e-03  \n 1st Qu.:2.257e+00  \n Median :1.201e+01  \n Mean   :2.311e+01  \n 3rd Qu.:2.740e+01  \n Max.   :2.061e+02  \n                    \n\n\nNot, however, the values that summary() returns and those that it does not. While the function can be used to be more efficient, it should not replace a thorough inspection of your data. We will discuss this more in exploratory data anlaysis.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#task-2.5-create-basic-plots",
    "href": "cases/case02-pt2.html#task-2.5-create-basic-plots",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Task 2.5: Create basic plots",
    "text": "Task 2.5: Create basic plots\n\nTask 2.5.1: boxplot()\nboxplot() returns a box plot of a numeric variable or variables.\n\nboxplot(data_2020$pop)\n\n\n\n\n\n\n\n\n\n\nTask 2.5.2: hist()\nhist() returns a histogram of a single numeric variable.\n\nhist(data_2020$pop)\n\n\n\n\n\n\n\n\n\n\nTask 2.5.3: stem()\nstem() provides a stem-and-leaf plot when a single numeric variable is input.\n\nstem(data_2020$med.age)\n\n\n  The decimal point is at the |\n\n  14 | 0\n  16 | 0000000\n  18 | 00000000000000000000000\n  20 | 00000000\n  22 | 0000\n  24 | 000\n  26 | 0\n  28 | 00000\n  30 | 0\n  32 | 0\n  34 | 0\n  36 | 00\n\n\n\n\nTask 2.5.4: plot()\nplot() provides a scatter plot of data values by its index, \\(i\\).\n\nplot(data_2020$med.age)\n\n\n\n\n\n\n\n\n\n\nTask 2.5.5: plot(density())\nplot(density()) provides a density plot of a single numeric variable\n\nplot(density(data_2020$pop))",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#report-1.6",
    "href": "cases/case02-pt2.html#report-1.6",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Report 1.6",
    "text": "Report 1.6\nState each variable and variable type in the africa_data_all data frame.\nWhat code provides us with the requested information most efficiently?",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#report-1.7",
    "href": "cases/case02-pt2.html#report-1.7",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Report 1.7",
    "text": "Report 1.7\nWhy does filter(summary(df2, year == 2020)) return an error?\nRecall that df2 was used as a label for africa_data_all.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#report-1.8",
    "href": "cases/case02-pt2.html#report-1.8",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Report 1.8",
    "text": "Report 1.8\nWhen using view(data_2020) after running the sapply(data_2020, function(x) sum(is.na(x))), what do you notice? Specifically, what country (or territory) is the source of the missing data values?\nRecall that data_2020 was used as a label for africa_data_all when year == 2020.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#report-1.9",
    "href": "cases/case02-pt2.html#report-1.9",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Report 1.9",
    "text": "Report 1.9\nCompute univariate statistics for two numeric variables in africa_data_all for year == 2023.\nUnivariate statistics for each variable should include: mean(), median(), a method to find the mode of the varaible, if it exists, max() and min(), a method to find the range of the varaible, IQR(), and sd().",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "cases/case02-pt2.html#report-1.10",
    "href": "cases/case02-pt2.html#report-1.10",
    "title": "Case Study 2, Part 2: The True Size of Africa",
    "section": "Report 1.10",
    "text": "Report 1.10\nCreate basic plots (i.e., boxplot(), hist(), plot(), and plot(density())) for the two numeric variables that you used in Report 1.9 (above). Add a title to each plot.\n{Save each plot in your directory}.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 2"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html",
    "href": "papers/papers-more-info.html",
    "title": "More information for course papers",
    "section": "",
    "text": "As noted before, the course papers all require that you do original data analysis.\nPapers should be written as research reports (try to make the text clear but sound professional, though the research questions may be relatively simple), and they should include the elements described below in narrative form. Please give each paper a substantive title (in addition to “Paper #_“).\nEach paper should have, at minimum, five sections: Introduction, Theory, Method, Analysis, and Conclusion.\n\n\nUsing research literature, either from OpenAlex, Web of Science (WoS), or some other search (such as Research Rabbit), you should outline - based on the literature - the main goals of your paper.\n\n\n\nThe research question(s) should close out the introductory section of your paper.\n\n\n\nEach theory (or logic graph) should be described fully in about a paragraph or two.\nDescribe and justify the relationships involving the theoretical variables that will be examined (including what’s the unit of analysis and “what’s the story,” in terms of why we care about the issue(s); this is a great place to insert historical work). Include a graph along with this at the beginning of the paper.\n\n\n\nNext, describe the data that you will be using to examine the theory. Describe the data source that you are using, and for any survey data describe the sampling method. For the General Social Survey (GSS) someone could say something like “The 2012 GSS sample is a multistage area probability sample to the segment or block level. At the block level, households are enumerated and a full probability sample is drawn.” You will need to find this type of detailed information in the code provided. Describe the specific measures you are using and how they were obtained. Comment on how well the measures fit your theoretical variables (i.e., the face validity of the measures). In the case of survey data, report the full question wordings (verbatim) and specify the response categories and report how the variables were coded and re-coded. Present the frequency distributions (so your coding and treatment of missing data can be checked); if you want to comment on the frequency distributions, you should do so in no more than a couple sentences.\n\n\n\nSpecify the hypotheses for the expected relationships (coefficients / correlations) in the context of the specified equations and operational flow graph. Then report the statistical results, coefficients, etc. and other relevant statistics and any additional calculations required. Describe to what extent the evidence is consistent with your hypothesis or hypotheses and lends support to your theorizing.\n\n\n\nWhat can you conclude about your original theorizing based upon your analysis? Were you on the right track? Were your findings different from what you originally theorized?",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#introduction",
    "href": "papers/papers-more-info.html#introduction",
    "title": "More information for course papers",
    "section": "",
    "text": "Using research literature, either from OpenAlex, Web of Science (WoS), or some other search (such as Research Rabbit), you should outline - based on the literature - the main goals of your paper.",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#research-question",
    "href": "papers/papers-more-info.html#research-question",
    "title": "More information for course papers",
    "section": "",
    "text": "The research question(s) should close out the introductory section of your paper.",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#theory",
    "href": "papers/papers-more-info.html#theory",
    "title": "More information for course papers",
    "section": "",
    "text": "Each theory (or logic graph) should be described fully in about a paragraph or two.\nDescribe and justify the relationships involving the theoretical variables that will be examined (including what’s the unit of analysis and “what’s the story,” in terms of why we care about the issue(s); this is a great place to insert historical work). Include a graph along with this at the beginning of the paper.",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#method-or-measurement",
    "href": "papers/papers-more-info.html#method-or-measurement",
    "title": "More information for course papers",
    "section": "",
    "text": "Next, describe the data that you will be using to examine the theory. Describe the data source that you are using, and for any survey data describe the sampling method. For the General Social Survey (GSS) someone could say something like “The 2012 GSS sample is a multistage area probability sample to the segment or block level. At the block level, households are enumerated and a full probability sample is drawn.” You will need to find this type of detailed information in the code provided. Describe the specific measures you are using and how they were obtained. Comment on how well the measures fit your theoretical variables (i.e., the face validity of the measures). In the case of survey data, report the full question wordings (verbatim) and specify the response categories and report how the variables were coded and re-coded. Present the frequency distributions (so your coding and treatment of missing data can be checked); if you want to comment on the frequency distributions, you should do so in no more than a couple sentences.",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#statistical-analysis",
    "href": "papers/papers-more-info.html#statistical-analysis",
    "title": "More information for course papers",
    "section": "",
    "text": "Specify the hypotheses for the expected relationships (coefficients / correlations) in the context of the specified equations and operational flow graph. Then report the statistical results, coefficients, etc. and other relevant statistics and any additional calculations required. Describe to what extent the evidence is consistent with your hypothesis or hypotheses and lends support to your theorizing.",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/papers-more-info.html#conclusion",
    "href": "papers/papers-more-info.html#conclusion",
    "title": "More information for course papers",
    "section": "",
    "text": "What can you conclude about your original theorizing based upon your analysis? Were you on the right track? Were your findings different from what you originally theorized?",
    "crumbs": [
      "Appendix",
      "Papers",
      "More information for papers"
    ]
  },
  {
    "objectID": "papers/paper2.html",
    "href": "papers/paper2.html",
    "title": "Paper 2",
    "section": "",
    "text": "For review, you may also refer to more information for course papers in two additional documents:",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper2.html#path-diagram",
    "href": "papers/paper2.html#path-diagram",
    "title": "Paper 2",
    "section": "Path Diagram",
    "text": "Path Diagram\n\n\n\n\n\nflowchart LR\n  A[Income] --&gt; B[Strength of support for a political party]\n  A --&gt; C[Religious affiliation]\n  \n\n\n\n\n\n\nIn the code below, we will focus on the relationship between A and B.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper2.html#prepare-files",
    "href": "papers/paper2.html#prepare-files",
    "title": "Paper 2",
    "section": "Prepare files",
    "text": "Prepare files\nTo investigate the relationship outlined in the path diagram, we will use data from the General Social Survey (GSS). To begin your exploratory analysis, start a new RScript in your stats-pt2 RStudio project directory and give your RScript a proper preamble.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper2.html#data-set",
    "href": "papers/paper2.html#data-set",
    "title": "Paper 2",
    "section": "Data set",
    "text": "Data set\nFor paper #2, you will use the gss_cat data located in the forcats package.\nTo test our hypothesis, two survey variables/measures are selected from the gss_cat data:\n\nrincome (respondent’s reported income)\npartyid (respondent’s levels of support for one of three major US political parties)\n\n\nLoad the libraries\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidycensus)\n\n\n\nView data in your current R session\n\ndata()\n\nLocate the gss_cat data in the forcats pacakge.\nThis is a data set for us to examine the use of categorical data and factor variable types.\n\n\nView documentation for your data\n\n?gss_cat\n\nView your data\n\ngss_cat\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Ind,near … Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Not str r… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Ind,near … Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Not str d… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Strong de… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Not str r… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Ind,near … Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Not str d… Prot… Other       0\n10  2000 Married          47 White $25000 or more Strong re… Prot… Sout…       3\n# ℹ 21,473 more rows\n\n\nBe sure to check the categories and codes for your variables.\n\nCategories for rincome\n\nsummary(gss_cat$rincome)\n\n     No answer     Don't know        Refused $25000 or more $20000 - 24999 \n           183            267            975           7363           1283 \n$15000 - 19999 $10000 - 14999  $8000 to 9999  $7000 to 7999  $6000 to 6999 \n          1048           1168            340            188            215 \n $5000 to 5999  $4000 to 4999  $3000 to 3999  $1000 to 2999       Lt $1000 \n           227            226            276            395            286 \nNot applicable \n          7043 \n\n\n\n\nCategories for partyid\n\nsummary(gss_cat$partyid)\n\n         No answer         Don't know        Other party  Strong republican \n               154                  1                393               2314 \nNot str republican       Ind,near rep        Independent       Ind,near dem \n              3032               1791               4119               2499 \n  Not str democrat    Strong democrat \n              3690               3490 \n\n\nNotice how each variable is measured and take notes for the measurement section of your paper.\nYou will need to re-code these values prior to any statistical analysis.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper2.html#prepare-data-for-analysis",
    "href": "papers/paper2.html#prepare-data-for-analysis",
    "title": "Paper 2",
    "section": "Prepare data for analysis",
    "text": "Prepare data for analysis\nBegin exploratory analyses on each variable.\nWhile doing exploratory analyses, you should prepare your data for statistical analysis.\n\nInspect your data using str()\nCheck the distribution of your variables using count()\nDecide how you will work with missing data, such as na.omit()\n\n\nRemove missing values from your analysis\nFor this paper, it is fine to drop all missing observations.\nWe will also explore the data from the year 2000.\n\ndf &lt;- gss_cat %&gt;% \n  na.omit() %&gt;% \n  filter(year == 2000) %&gt;% \n  select(year, rincome, partyid)\n\nExamine the reduced data frame.\n\ndf\n\n# A tibble: 1,824 × 3\n    year rincome        partyid           \n   &lt;int&gt; &lt;fct&gt;          &lt;fct&gt;             \n 1  2000 $8000 to 9999  Ind,near rep      \n 2  2000 Not applicable Independent       \n 3  2000 Not applicable Ind,near rep      \n 4  2000 Not applicable Not str democrat  \n 5  2000 $25000 or more Not str republican\n 6  2000 $25000 or more Not str democrat  \n 7  2000 $25000 or more Strong republican \n 8  2000 $25000 or more Not str democrat  \n 9  2000 $25000 or more Strong democrat   \n10  2000 $25000 or more Ind,near dem      \n# ℹ 1,814 more rows\n\n\nView the top and bottom of your data using head and tail, respectively.\n\nhead(df)\n\n# A tibble: 6 × 3\n   year rincome        partyid           \n  &lt;int&gt; &lt;fct&gt;          &lt;fct&gt;             \n1  2000 $8000 to 9999  Ind,near rep      \n2  2000 Not applicable Independent       \n3  2000 Not applicable Ind,near rep      \n4  2000 Not applicable Not str democrat  \n5  2000 $25000 or more Not str republican\n6  2000 $25000 or more Not str democrat  \n\ntail(df)\n\n# A tibble: 6 × 3\n   year rincome        partyid          \n  &lt;int&gt; &lt;fct&gt;          &lt;fct&gt;            \n1  2000 $25000 or more Not str democrat \n2  2000 $25000 or more Strong republican\n3  2000 $10000 - 14999 Independent      \n4  2000 $25000 or more Strong republican\n5  2000 $25000 or more Ind,near rep     \n6  2000 $7000 to 7999  Strong republican\n\n\nIn paper 2, you will conduct original statistical analyses.\n\n\nGet frequency tables for your data\nUsing the count() function, we will get frequency tables for each variable.\n\ndf %&gt;% \n  count(rincome)\n\n# A tibble: 16 × 2\n   rincome            n\n   &lt;fct&gt;          &lt;int&gt;\n 1 No answer         15\n 2 Don't know        22\n 3 Refused           92\n 4 $25000 or more   590\n 5 $20000 - 24999   126\n 6 $15000 - 19999   115\n 7 $10000 - 14999   139\n 8 $8000 to 9999     45\n 9 $7000 to 7999     18\n10 $6000 to 6999     24\n11 $5000 to 5999     17\n12 $4000 to 4999     20\n13 $3000 to 3999     22\n14 $1000 to 2999     36\n15 Lt $1000          24\n16 Not applicable   519\n\n\n\ndf %&gt;% \n  count(partyid)\n\n# A tibble: 9 × 2\n  partyid                n\n  &lt;fct&gt;              &lt;int&gt;\n1 No answer              3\n2 Other party           22\n3 Strong republican    180\n4 Not str republican   244\n5 Ind,near rep         168\n6 Independent          392\n7 Ind,near dem         213\n8 Not str democrat     331\n9 Strong democrat      271\n\n\nFrom our frequency tables, it is clear that we will need to transform our data.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper2.html#recode-categories-into-two-levels-dichotomous",
    "href": "papers/paper2.html#recode-categories-into-two-levels-dichotomous",
    "title": "Paper 2",
    "section": "Recode categories into two-levels (dichotomous)",
    "text": "Recode categories into two-levels (dichotomous)\nFor this analysis, we will transform our data into two dichotomous variables. Let’s examine the outputs before overwriting our data frame.\nWe will use the logic operator != to imply we do not want to keep these values (i.e., we will filter the values that are not equal to the right hand side).\n\ndf %&gt;% \n  filter(year == 2000) %&gt;% \n  filter(rincome != \"No answer\"\n         & rincome != \"Refused\"\n         & rincome != \"Not applicable\")\n\n# A tibble: 1,198 × 3\n    year rincome        partyid           \n   &lt;int&gt; &lt;fct&gt;          &lt;fct&gt;             \n 1  2000 $8000 to 9999  Ind,near rep      \n 2  2000 $25000 or more Not str republican\n 3  2000 $25000 or more Not str democrat  \n 4  2000 $25000 or more Strong republican \n 5  2000 $25000 or more Not str democrat  \n 6  2000 $25000 or more Strong democrat   \n 7  2000 $25000 or more Ind,near dem      \n 8  2000 $25000 or more Strong democrat   \n 9  2000 $25000 or more Independent       \n10  2000 $10000 - 14999 Not str democrat  \n# ℹ 1,188 more rows\n\n\nWe now recode the categories using mutuate() and recode().\n\ndf %&gt;% \n  mutate(rincome = fct_recode(rincome, \n          \"More than 10000\" = \"$25000 or more\",\n          \"More than 10000\" = \"$20000 to 24999\",\n          \"More than 10000\" = \"$15000 to 19999\",\n          \"More than 10000\" = \"$10000 to 14999\",\n          \"Less than 10000\" = \"$8000 to 9999\",\n          \"Less than 10000\" = \"$7000 to 7999\",\n          \"Less than 10000\" = \"$6000 to 6999\",\n          \"Less than 10000\" = \"$5000 to 5999\",\n          \"Less than 10000\" = \"$4000 to 4999\",\n          \"Less than 10000\" = \"$3000 to 3999\",\n          \"Less than 10000\" = \"$1000 to 2999\",\n          \"Less than 10000\" = \"$Lt $1000\"))\n\n# A tibble: 1,824 × 3\n    year rincome         partyid           \n   &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;             \n 1  2000 Less than 10000 Ind,near rep      \n 2  2000 Not applicable  Independent       \n 3  2000 Not applicable  Ind,near rep      \n 4  2000 Not applicable  Not str democrat  \n 5  2000 More than 10000 Not str republican\n 6  2000 More than 10000 Not str democrat  \n 7  2000 More than 10000 Strong republican \n 8  2000 More than 10000 Not str democrat  \n 9  2000 More than 10000 Strong democrat   \n10  2000 More than 10000 Ind,near dem      \n# ℹ 1,814 more rows\n\n\n\ndf %&gt;% \n  mutate(partyid = fct_recode(partyid,\n                              \"Republican\" = \"Strong republican\",\n                              \"Republican\" = \"Not str republican\",\n                              \"Republican\" = \"Ind,near rep\",\n                              \"Democrat\" = \"Ind,near dem\",\n                              \"Democrat\" = \"Not str democrat\",\n                              \"Democrat\" = \"Strong democrat\"))\n\n# A tibble: 1,824 × 3\n    year rincome        partyid    \n   &lt;int&gt; &lt;fct&gt;          &lt;fct&gt;      \n 1  2000 $8000 to 9999  Republican \n 2  2000 Not applicable Independent\n 3  2000 Not applicable Republican \n 4  2000 Not applicable Democrat   \n 5  2000 $25000 or more Republican \n 6  2000 $25000 or more Democrat   \n 7  2000 $25000 or more Republican \n 8  2000 $25000 or more Democrat   \n 9  2000 $25000 or more Democrat   \n10  2000 $25000 or more Democrat   \n# ℹ 1,814 more rows\n\n\nWe can stack our variable transformations together into one chunk of code.\nTake note of the way we are creating our new data set for analysis.\n\ndf %&gt;% \n  filter(year == 2000) %&gt;% \n  filter(rincome != \"No answer\"\n         & rincome != \"Refused\"\n         & rincome != \"Not applicable\") %&gt;% \n  mutate(rincome = fct_recode(rincome, \n          \"More than 20000\" = \"$25000 or more\",\n          \"More than 20000\" = \"$20000 - 24999\",\n          \"Less than 20000\" = \"$15000 - 19999\",\n          \"Less than 20000\" = \"$10000 - 14999\",\n          \"Less than 20000\" = \"$8000 to 9999\",\n          \"Less than 20000\" = \"$7000 to 7999\",\n          \"Less than 20000\" = \"$6000 to 6999\",\n          \"Less than 20000\" = \"$5000 to 5999\",\n          \"Less than 20000\" = \"$4000 to 4999\",\n          \"Less than 20000\" = \"$3000 to 3999\",\n          \"Less than 20000\" = \"$1000 to 2999\",\n          \"Less than 20000\" = \"Lt $1000\")) %&gt;%\n  mutate(partyid = fct_recode(partyid,\n                              \"Republican\" = \"Strong republican\",\n                              \"Republican\" = \"Not str republican\",\n                              \"Republican\" = \"Ind,near rep\",\n                              \"Democrat\" = \"Ind,near dem\",\n                              \"Democrat\" = \"Not str democrat\",\n                              \"Democrat\" = \"Strong democrat\"))\n\n# A tibble: 1,198 × 3\n    year rincome         partyid    \n   &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;      \n 1  2000 Less than 20000 Republican \n 2  2000 More than 20000 Republican \n 3  2000 More than 20000 Democrat   \n 4  2000 More than 20000 Republican \n 5  2000 More than 20000 Democrat   \n 6  2000 More than 20000 Democrat   \n 7  2000 More than 20000 Democrat   \n 8  2000 More than 20000 Democrat   \n 9  2000 More than 20000 Independent\n10  2000 Less than 20000 Democrat   \n# ℹ 1,188 more rows\n\n\nAs you examine the code more closely, you will notice that I created two categories:\n\nPeople making less than $20,000\nPeople making more than $20,000",
    "crumbs": [
      "Appendix",
      "Papers",
      "Final Paper"
    ]
  },
  {
    "objectID": "papers/paper1.html",
    "href": "papers/paper1.html",
    "title": "Paper 1",
    "section": "",
    "text": "This is an individual paper. All papers should be no less than twenty (20) pages in length and written as narrative essays in 12-point Times New Roman font with one-inch margins.\nIn writing the paper, you should structure it by using section headings and relevant citations for any referenced work.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Paper 1"
    ]
  },
  {
    "objectID": "papers/paper1.html#paper-requirements",
    "href": "papers/paper1.html#paper-requirements",
    "title": "Paper 1",
    "section": "",
    "text": "This is an individual paper. All papers should be no less than twenty (20) pages in length and written as narrative essays in 12-point Times New Roman font with one-inch margins.\nIn writing the paper, you should structure it by using section headings and relevant citations for any referenced work.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Paper 1"
    ]
  },
  {
    "objectID": "papers/paper1.html#paper-overview",
    "href": "papers/paper1.html#paper-overview",
    "title": "Paper 1",
    "section": "Paper overview",
    "text": "Paper overview\nIn this paper, you should write about a theory concerning the relationships between and among two variables, that is some dependent variable and particular independent variables (you may have one or more than one independent variable of interest at the outset). After introducing your theory you will use real-world data and statistical analysis to examine the theory.\nFor review, you may also refer to more information for course papers in two additional documents:\n\nInstructions for papers\nMore information for course papers",
    "crumbs": [
      "Appendix",
      "Papers",
      "Paper 1"
    ]
  },
  {
    "objectID": "papers/paper1.html#paper-contents",
    "href": "papers/paper1.html#paper-contents",
    "title": "Paper 1",
    "section": "Paper contents",
    "text": "Paper contents\nYour paper should be clear on the following:\n- What are the variables (especially the dependent one that is explained by the independent variable(s))?\n\n- What is the unit of analysis?\n\n- Draw and discuss a path diagram (flow graph) for the theory.\n\n- What are the measurement, data collection, and sampling strategies?\n\n- How are the variables to be measured?\n\n- What are the categories of the variables/measures?\n\n- What are the hypotheses concerning the relationships among the variables/measures?\n\n- Explain how this study offers evidence bearing on the relationship(s) of interest.",
    "crumbs": [
      "Appendix",
      "Papers",
      "Paper 1"
    ]
  },
  {
    "objectID": "analysis/yahoo_data.html",
    "href": "analysis/yahoo_data.html",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "",
    "text": "Load the libraries we needed. Be sure to install.packages() where needed.\n\nlibrary(critstats)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "analysis/yahoo_data.html#load-the-data-from-github",
    "href": "analysis/yahoo_data.html#load-the-data-from-github",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Load the data from github",
    "text": "Load the data from github\nWe’ll use data on the gender pay gap that I have prepared for today’s discussion.\n\nyahoo &lt;- critstats::yahoo_data"
  },
  {
    "objectID": "analysis/yahoo_data.html#view",
    "href": "analysis/yahoo_data.html#view",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "View",
    "text": "View\nView a summary of the data.\n\nsummary(yahoo)\n\n   race_eth           response        \n Length:1059        Length:1059       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\nAlternatively, you can use View(yaho) to see the data frame in a separate window."
  },
  {
    "objectID": "analysis/yahoo_data.html#glimpse",
    "href": "analysis/yahoo_data.html#glimpse",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Glimpse",
    "text": "Glimpse\nTake a glimpse of the data.\n\nglimpse(yahoo)\n\nRows: 1,059\nColumns: 2\n$ race_eth &lt;chr&gt; \"White\", \"White\", \"White\", \"White\", \"White\", \"White\", \"White\"…\n$ response &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…"
  },
  {
    "objectID": "analysis/yahoo_data.html#head-tail",
    "href": "analysis/yahoo_data.html#head-tail",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Head / Tail",
    "text": "Head / Tail\nView the top (head) and bottom (tail) of the data.\n\nhead(yahoo)\n\n# A tibble: 6 × 2\n  race_eth response\n  &lt;chr&gt;    &lt;chr&gt;   \n1 White    Yes     \n2 White    Yes     \n3 White    Yes     \n4 White    Yes     \n5 White    Yes     \n6 White    Yes     \n\ntail(yahoo)\n\n# A tibble: 6 × 2\n  race_eth response\n  &lt;chr&gt;    &lt;chr&gt;   \n1 Other    Not sure\n2 Other    Not sure\n3 Other    Not sure\n4 Other    Not sure\n5 Other    Not sure\n6 Other    Not sure"
  },
  {
    "objectID": "analysis/yahoo_data.html#counts-and-proportions",
    "href": "analysis/yahoo_data.html#counts-and-proportions",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Counts and proportions",
    "text": "Counts and proportions\nCreate a table of variable counts.\n\ntable(yahoo$race_eth)\n\n\n   Black Hispanic    Other    White \n     101      104       82      772 \n\ntable(yahoo$response)\n\n\n      No Not sure      Yes \n     700      123      236 \n\n\nCreate a table of variable proportions\n\nprop.table(table(yahoo$race_eth))\n\n\n     Black   Hispanic      Other      White \n0.09537299 0.09820585 0.07743154 0.72898961 \n\nprop.table(table(yahoo$response))\n\n\n       No  Not sure       Yes \n0.6610009 0.1161473 0.2228517"
  },
  {
    "objectID": "analysis/yahoo_data.html#visualize",
    "href": "analysis/yahoo_data.html#visualize",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Visualize",
    "text": "Visualize\nStart with the plot outline.\n\nggplot(yahoo)\n\n\n\n\n\n\n\n\nAdd the variable categories to the plot using aesthetics (aes).\n\nggplot(yahoo, aes(x = race_eth))\n\n\n\n\n\n\n\n\nAdd bars to the plot using plus (+) geom_bar().\n\nggplot(yahoo, aes(x = race_eth)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can improve this plot with some additional code.\n\nggplot(yahoo, aes(x = race_eth, fill = race_eth)) +\n  geom_bar(width = 0.7, color = \"black\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(x = \"Race/Ethnicity\", y = \"Count\", title = \"Distribution of Race/Ethnicity\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))\n\n\n\n\n\n\n\n\nWe can also add counts to our bars.\n\nggplot(yahoo, aes(x = race_eth, fill = race_eth)) +\n  geom_bar(width = 0.7, color = \"black\") +\n  geom_text(stat = \"count\", aes(label = after_stat(count)), \n            vjust = -0.5, color = \"black\", size = 3.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(x = \"Race/Ethnicity\", y = \"Count\", title = \"Distribution of Race/Ethnicity\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15)))"
  },
  {
    "objectID": "analysis/yahoo_data.html#sample-size",
    "href": "analysis/yahoo_data.html#sample-size",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Sample size",
    "text": "Sample size\nGet a count of the sample size.\n\ncount(df)\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1  1059"
  },
  {
    "objectID": "analysis/yahoo_data.html#relative-frequencies",
    "href": "analysis/yahoo_data.html#relative-frequencies",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Relative frequencies",
    "text": "Relative frequencies\nGet relative frequencies by the race variable.\n\ndf %&gt;% \n  count(race) %&gt;% \n  mutate(prop = prop.table(n))\n\n# A tibble: 4 × 3\n  race         n   prop\n  &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 Black      101 0.0954\n2 Hispanic   104 0.0982\n3 Other       82 0.0774\n4 White      772 0.729 \n\n\nGet relative frequencies by the responce variable.\n\ndf %&gt;% \n  count(response) %&gt;% \n  mutate(prop = prop.table(n))\n\n# A tibble: 3 × 3\n  response     n  prop\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n1 No         700 0.661\n2 Not sure   123 0.116\n3 Yes        236 0.223"
  },
  {
    "objectID": "analysis/yahoo_data.html#crosstab",
    "href": "analysis/yahoo_data.html#crosstab",
    "title": "DATA 202 - Analysis of Yahoo! News Poll",
    "section": "Crosstab",
    "text": "Crosstab\nGet a crosstab of the race and response variables.\n\ncrosstab(df$response, df$race, plot=F)\n\n   Cell Contents \n|-------------------------|\n|                   Count | \n|-------------------------|\n\n=======================================================\n               df$race\ndf$response    Black   Hispanic   Other   White   Total\n-------------------------------------------------------\nNo                92         75      47     486     700\n-------------------------------------------------------\nNot sure           3         14      21      85     123\n-------------------------------------------------------\nYes                6         15      14     201     236\n-------------------------------------------------------\nTotal            101        104      82     772    1059\n=======================================================\n\n\nStandardize the frequencies.\n\ncrosstab(df$response, df$race, plot=F, prop.c=T)\n\n   Cell Contents \n|-------------------------|\n|                   Count | \n|          Column Percent | \n|-------------------------|\n\n=======================================================\n               df$race\ndf$response    Black   Hispanic   Other   White   Total\n-------------------------------------------------------\nNo               92         75      47     486     700 \n               91.1%      72.1%   57.3%   63.0%        \n-------------------------------------------------------\nNot sure          3         14      21      85     123 \n                3.0%      13.5%   25.6%   11.0%        \n-------------------------------------------------------\nYes               6         15      14     201     236 \n                5.9%      14.4%   17.1%   26.0%        \n-------------------------------------------------------\nTotal           101        104      82     772    1059 \n                9.5%       9.8%    7.7%   72.9%        \n=======================================================\n\n\nCreate a crosstab with raw frequencies.\n\ncrosstab(df$response, df$race, plot=F)\n\n   Cell Contents \n|-------------------------|\n|                   Count | \n|-------------------------|\n\n=======================================================\n               df$race\ndf$response    Black   Hispanic   Other   White   Total\n-------------------------------------------------------\nNo                92         75      47     486     700\n-------------------------------------------------------\nNot sure           3         14      21      85     123\n-------------------------------------------------------\nYes                6         15      14     201     236\n-------------------------------------------------------\nTotal            101        104      82     772    1059\n=======================================================\n\n\nGather the expected values.\n\ncrosstab(df$response, df$race,\n         expected=T, #Add expected frequency to each cell\n         plot=F)\n\n   Cell Contents \n|-------------------------|\n|                   Count | \n|         Expected Values | \n|-------------------------|\n\n=======================================================\n               df$race\ndf$response    Black   Hispanic   Other   White   Total\n-------------------------------------------------------\nNo                92         75      47     486     700\n                66.8       68.7    54.2   510.3        \n-------------------------------------------------------\nNot sure           3         14      21      85     123\n                11.7       12.1     9.5    89.7        \n-------------------------------------------------------\nYes                6         15      14     201     236\n                22.5       23.2    18.3   172.0        \n-------------------------------------------------------\nTotal            101        104      82     772    1059\n=======================================================\n\n\nAdd the chi-square contributions.\n\ncrosstab(df$response, df$race,\n         expected=T, #Add expected frequency to each cell\n         prop.chisq = T, #Total contribution of each cell \n         plot=F)\n\n   Cell Contents \n|-------------------------|\n|                   Count | \n|         Expected Values | \n| Chi-square contribution | \n|-------------------------|\n\n=========================================================\n               df$race\ndf$response     Black   Hispanic    Other   White   Total\n---------------------------------------------------------\nNo                 92         75       47     486     700\n                 66.8       68.7     54.2   510.3        \n                9.542      0.569    0.957   1.156        \n---------------------------------------------------------\nNot sure            3         14       21      85     123\n                 11.7       12.1      9.5    89.7        \n                6.498      0.305   13.828   0.243        \n---------------------------------------------------------\nYes                 6         15       14     201     236\n                 22.5       23.2     18.3   172.0        \n               12.107      2.885    1.000   4.874        \n---------------------------------------------------------\nTotal             101        104       82     772    1059\n=========================================================\n\n\nCalculate your degrees of freedom:\n\\[\ndf_{\\chi^2} = (r-1)(c-1)\n\\] Where r equals the number of rows and c equals the number of columns.\nIn our case we have \\(r = 3\\) and \\(c=4\\), so we get:\n\\[\ndf_{\\chi^2} = (3-1)(4-1) = (2)(3) = 6\n\\]\nUse the chi-square critical values.\nGather the critical value of chi-square.\n\nqchisq(.05, 6, lower.tail=F)\n\n[1] 12.59159\n\n\nTake note of the \\(6\\) in our code; that will change based on your analysis.\nGet the chi-square statistic.\n\nchisq.test(df$response, df$race)\n\n\n    Pearson's Chi-squared test\n\ndata:  df$response and df$race\nX-squared = 53.964, df = 6, p-value = 7.5e-10\n\n\nFrom here you want to critically interpret your values."
  },
  {
    "objectID": "analysis/multivars.html",
    "href": "analysis/multivars.html",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "",
    "text": "There are multiple options when conducting the analysis of multiple variables (i.e., more than two variables). In this file, I provide some very basic code to help you get started on your analysis for your paper on analyzing the relationship between multiple variables."
  },
  {
    "objectID": "analysis/multivars.html#load-sample-data-from-github",
    "href": "analysis/multivars.html#load-sample-data-from-github",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Load sample data from github",
    "text": "Load sample data from github\nWe’ll use the gender pay gap data again that I have prepared.\n\npay_gap_data &lt;- read.csv(\"https://raw.githubusercontent.com/data-202/sp25/refs/heads/master/data/pay_data.csv\")"
  },
  {
    "objectID": "analysis/multivars.html#anlayzing-bivariate-relationships",
    "href": "analysis/multivars.html#anlayzing-bivariate-relationships",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Anlayzing bivariate relationships",
    "text": "Anlayzing bivariate relationships\nWe then want to analyze the bivariate relationship between each of the variables in our model.\n\nNumeric-Numeric relationships\nWe’ll start with a scatter plot to visualize the relationship between the numeric variables.\n\npairs(pay_gap_data[, c(\"annual_salary\", \"years_experience\")],\n      main = \"Pairwise Scatterplot Matrix\")\n\n\n\n\n\n\n\n\n\nggplot(pay_gap_data, aes(x = years_experience, y = annual_salary)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Experience vs Salary Relationship\",\n       x = \"Years of Experience\", y = \"Annual Salary\")\n\n\n\n\n\n\n\n\n\n# check correlation value\ncor.test(pay_gap_data$annual_salary, pay_gap_data$years_experience)\n\n\n    Pearson's product-moment correlation\n\ndata:  pay_gap_data$annual_salary and pay_gap_data$years_experience\nt = 15.413, df = 98, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7726828 0.8906291\nsample estimates:\n      cor \n0.8414022 \n\n\n\n\nCategorical-Numeric relationships\n\n## Gender vs Salary\nggplot(pay_gap_data, aes(x = gender, \n                         y = annual_salary, \n                         fill = gender)) +\n  geom_boxplot() +\n  labs(title = \"Salary Distribution by Gender\")\n\n\n\n\n\n\n\n\n\n## Job Title vs Salary (sorted by median salary)\npay_gap_data %&gt;%\n  mutate(job_title = reorder(job_title, annual_salary, median)) %&gt;%\n  ggplot(aes(x = job_title, y = annual_salary, fill = job_title)) +\n  geom_boxplot() +\n  coord_flip() +  # Better readability for long job titles\n  labs(title = \"Salary Distribution by Job Title\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n## Job Title vs Experience\npay_gap_data %&gt;%\n  mutate(job_title = reorder(job_title, years_experience, median)) %&gt;%\n  ggplot(aes(x = job_title, y = years_experience, fill = job_title)) +\n  geom_boxplot() +\n  coord_flip() +\n  labs(title = \"Experience Distribution by Job Title\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nCategorical-Categorical relationship\n\n# bar chart of the categorical relationships\nggplot(pay_gap_data, aes(x = job_title, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  coord_flip() +\n  labs(title = \"Gender Distribution Across Job Titles\",\n       x = \"Job Title\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(angle = 0, hjust = 1))\n\n\n\n\n\n\n\n\nWe can then conduct a chi-square test to see if there is a relation.\n\n## Chi-square test\nchisq.test(pay_gap_data$gender, pay_gap_data$job_title)\n\n\n    Pearson's Chi-squared test\n\ndata:  pay_gap_data$gender and pay_gap_data$job_title\nX-squared = 10.259, df = 8, p-value = 0.2473"
  },
  {
    "objectID": "analysis/multivars.html#visualizing-the-combined-relationships",
    "href": "analysis/multivars.html#visualizing-the-combined-relationships",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Visualizing the combined relationships",
    "text": "Visualizing the combined relationships\n\n## Salary ~ Experience faceted by Gender\nggplot(pay_gap_data, aes(x = years_experience, y = annual_salary)) +\n  geom_point(aes(color = gender)) +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~gender) +\n  labs(title = \"Experience-Salary Relationship by Gender\")\n\n\n\n\n\n\n\n\n\n## Salary ~ Experience colored by Job Title\nggplot(pay_gap_data, aes(x = years_experience, y = annual_salary, color = job_title)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Experience-Salary Relationship by Job Title\")"
  },
  {
    "objectID": "analysis/multivars.html#research-questions",
    "href": "analysis/multivars.html#research-questions",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Research questions",
    "text": "Research questions\nRQ1: Does gender, job title, and years of experience significantly impact an individual’s annual salary?\nRQ2: How much variance in salary can be explained by gender and job title after controlling for years of experience?"
  },
  {
    "objectID": "analysis/multivars.html#base-statistical-models",
    "href": "analysis/multivars.html#base-statistical-models",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Base statistical models",
    "text": "Base statistical models\nBelow, I provide the base statistical models to answer the listed research questions. However, be reminded that you should utilize your theoretical framework to drive your analysis. The most important component of our modeling here are the post-hoc tests of our assumptions.\n\nResearch Question 1\nRQ1: Does gender, job title, and years of experience significantly impact an individual’s annual salary?\n\n# Fit the model\nmodel &lt;- lm(annual_salary ~ gender + job_title + years_experience, data = pay_gap_data)\n\n# Get the summary of the model\nsummary(model)\n\n\nCall:\nlm(formula = annual_salary ~ gender + job_title + years_experience, \n    data = pay_gap_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13703  -3632   -128   2751  19370 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                36711.50    1968.85  18.646  &lt; 2e-16 ***\ngenderMale                 13964.08    1411.79   9.891 3.87e-16 ***\ngenderNon-binary            7665.83    2841.64   2.698  0.00831 ** \njob_titleChemist              -5.78    2140.76  -0.003  0.99785    \njob_titleData Scientist      -47.80    2148.50  -0.022  0.98230    \njob_titleOther              4453.30    2029.46   2.194  0.03073 *  \njob_titleSoftware Engineer   622.90    2142.47   0.291  0.77191    \nyears_experience            1893.49      89.47  21.165  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6617 on 92 degrees of freedom\nMultiple R-squared:  0.8623,    Adjusted R-squared:  0.8519 \nF-statistic: 82.33 on 7 and 92 DF,  p-value: &lt; 2.2e-16\n\n\n\nChecking Assumptions\nWe then want to check the assumptions for our multiple linear regression model.\nWe use the which command here to call for specific results.\n\n# Linearity and homoscedasticity\nplot(model, which = 1)\n\n\n\n\n\n\n\n\n\n# Normality of residuals\nplot(model, which = 2)\n\n\n\n\n\n\n\n\n\n# Influential points\nplot(model, which = 4)\n\n\n\n\n\n\n\n\n\n# Multicollinearity\nvif(model)\n\n                     GVIF Df GVIF^(1/(2*Df))\ngender           1.118704  2        1.028440\njob_title        1.121275  4        1.014411\nyears_experience 1.014016  1        1.006983\n\n\n\n# Heteroscedasticity test\nbptest(model)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model\nBP = 8.3223, df = 7, p-value = 0.305\n\n\n\n\n\nResearch Question 2\nRQ2: How much variance in salary can be explained by gender and job title after controlling for years of experience?\n\n# Extract R-squared values\nr_squared_full &lt;- model$r.squared\n\nr_squared_experience &lt;- \n  summary(lm(annual_salary ~ years_experience, \n             data = pay_gap_data))$r.squared\n\n# Calculate the additional variance explained\nvariance.model &lt;- r_squared_full - r_squared_experience\nvariance.model\n\nnumeric(0)\n\n\n\n\nAdditional tests to examine differences by groupings\n\n## ANOVA: Job Title vs Salary\nsummary(aov(annual_salary ~ job_title, data = pay_gap_data))\n\n            Df    Sum Sq   Mean Sq F value Pr(&gt;F)\njob_title    4 2.704e+08  67594834   0.221  0.926\nResiduals   95 2.900e+10 305225060               \n\n\n\n## Kruskal-Wallis test (a non-parametric alternative)\nkruskal.test(annual_salary ~ job_title, data = pay_gap_data)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  annual_salary by job_title\nKruskal-Wallis chi-squared = 0.87467, df = 4, p-value = 0.9282\n\n\n\n## ANOVA for Gender Differences (3 groups)\n# For normally distributed data\ngender_salary_aov &lt;- aov(annual_salary ~ gender, data = pay_gap_data)\nsummary(gender_salary_aov)\n\n            Df    Sum Sq   Mean Sq F value   Pr(&gt;F)    \ngender       2 5.462e+09 2.731e+09   11.13 4.46e-05 ***\nResiduals   97 2.380e+10 2.454e+08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ngender_experience_aov &lt;- aov(years_experience ~ gender, data = pay_gap_data)\nsummary(gender_experience_aov)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ngender       2     37   18.58   0.327  0.722\nResiduals   97   5511   56.81               \n\n## Post-hoc pairwise comparisons (if ANOVA is significant)\n# Tukey's Honest Significant Differences\nTukeyHSD(gender_salary_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = annual_salary ~ gender, data = pay_gap_data)\n\n$gender\n                      diff        lwr       upr     p adj\nMale-Female        15511.1   7611.431 23410.770 0.0000283\nNon-binary-Female   5386.1  -9982.659 20754.859 0.6827936\nNon-binary-Male   -10125.0 -25073.224  4823.224 0.2453817\n\nTukeyHSD(gender_experience_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = years_experience ~ gender, data = pay_gap_data)\n\n$gender\n                        diff       lwr      upr     p adj\nMale-Female        0.9510135 -2.849798 4.751825 0.8228241\nNon-binary-Female -1.0436293 -8.438085 6.350827 0.9397284\nNon-binary-Male   -1.9946429 -9.186764 5.197479 0.7870735\n\n## Non-parametric alternative (Kruskal-Wallis)\nkruskal.test(annual_salary ~ gender, data = pay_gap_data)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  annual_salary by gender\nKruskal-Wallis chi-squared = 17.035, df = 2, p-value = 2e-04\n\nkruskal.test(years_experience ~ gender, data = pay_gap_data)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  years_experience by gender\nKruskal-Wallis chi-squared = 0.69574, df = 2, p-value = 0.7062\n\n## Pairwise Wilcoxon Rank Sum tests with Bonferroni correction\npairwise.wilcox.test(pay_gap_data$annual_salary, pay_gap_data$gender,\n                     p.adjust.method = \"bonferroni\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  pay_gap_data$annual_salary and pay_gap_data$gender \n\n           Female  Male   \nMale       0.00013 -      \nNon-binary 1.00000 0.62443\n\nP value adjustment method: bonferroni \n\npairwise.wilcox.test(pay_gap_data$years_experience, pay_gap_data$gender,\n                     p.adjust.method = \"bonferroni\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  pay_gap_data$years_experience and pay_gap_data$gender \n\n           Female Male\nMale       1      -   \nNon-binary 1      1   \n\nP value adjustment method: bonferroni \n\n## Enhanced gender-salary plot\nggplot(pay_gap_data, aes(x = gender, y = annual_salary, fill = gender)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.2, alpha = 0.4) +\n  stat_compare_means(method = \"anova\", label.y = max(pay_gap_data$annual_salary)*1.1) +\n  labs(title = \"Salary Distribution Across Gender Groups\",\n       subtitle = \"Three-group comparison with ANOVA results\")\n\n\n\n\n\n\n\n## Faceted experience-salary relationship\nggplot(pay_gap_data, aes(x = years_experience, y = annual_salary)) +\n  geom_point(aes(color = gender)) +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~gender, ncol = 3) +\n  labs(title = \"Experience-Salary Relationship by Gender Group\")"
  },
  {
    "objectID": "analysis/multivars.html#research-question",
    "href": "analysis/multivars.html#research-question",
    "title": "DATA 202 - Analyzing Multiple Variables",
    "section": "Research question",
    "text": "Research question\nRQ1: Do gender and job title jointly influence both salary and years of experience?\nRQ2: Are there significant differences in salary distributions across job titles when accounting for gender and experience?\n\n\n\n\n\n\n\nMANOVA\nRQ1: Do gender and job title jointly influence both salary and years of experience?\nTo answer RQ1, we’ll first run a multiple analysis of variance (MANOVA) on our data.\n\nmanova_result &lt;- manova(cbind(annual_salary, years_experience) ~ gender + job_title, data = pay_gap_data)\n\nsummary(manova_result)\n\n          Df  Pillai approx F num Df den Df    Pr(&gt;F)    \ngender     2 0.51380  16.0756      4    186 2.532e-11 ***\njob_title  4 0.08312   1.0082      8    186    0.4313    \nResiduals 93                                             \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# Perform univariate ANOVAs for each dependent variable\nsummary.aov(manova_result)\n\n Response annual_salary :\n            Df     Sum Sq    Mean Sq F value   Pr(&gt;F)    \ngender       2 5.4621e+09 2731054952  10.742 6.35e-05 ***\njob_title    4 1.6067e+08   40167715   0.158   0.9589    \nResiduals   93 2.3644e+10  254236336                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response years_experience :\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ngender       2   37.2  18.578  0.3158 0.7300\njob_title    4   39.5   9.881  0.1680 0.9542\nResiduals   93 5471.0  58.828               \n\n\n\n# Post-hoc tests for job title (if significant)\nTukeyHSD(aov(annual_salary ~ job_title, data = pay_gap_data))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = annual_salary ~ job_title, data = pay_gap_data)\n\n$job_title\n                                       diff       lwr      upr     p adj\nChemist-Biologist                 2744.7368 -12819.59 18309.07 0.9880828\nData Scientist-Biologist          4902.6316 -10661.70 20466.96 0.9050536\nOther-Biologist                   3676.0870 -11177.98 18530.15 0.9585863\nSoftware Engineer-Biologist       1955.2632 -13609.07 17519.59 0.9967520\nData Scientist-Chemist            2157.8947 -13604.72 17920.50 0.9954695\nOther-Chemist                      931.3501 -14130.35 15993.05 0.9998006\nSoftware Engineer-Chemist         -789.4737 -16552.08 14973.14 0.9999138\nOther-Data Scientist             -1226.5446 -16288.24 13835.15 0.9994066\nSoftware Engineer-Data Scientist -2947.3684 -18709.98 12815.24 0.9851493\nSoftware Engineer-Other          -1720.8238 -16782.52 13340.87 0.9977552\n\nTukeyHSD(aov(years_experience ~ job_title, data = pay_gap_data))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = years_experience ~ job_title, data = pay_gap_data)\n\n$job_title\n                                       diff       lwr      upr     p adj\nChemist-Biologist                 0.8871053 -5.890221 7.664432 0.9961911\nData Scientist-Biologist          1.6607895 -5.116537 8.438116 0.9600164\nOther-Biologist                  -0.3419565 -6.810004 6.126091 0.9998930\nSoftware Engineer-Biologist       0.4502632 -6.327063 7.227590 0.9997349\nData Scientist-Chemist            0.7736842 -6.089981 7.637350 0.9978703\nOther-Chemist                    -1.2290618 -7.787521 5.329398 0.9850252\nSoftware Engineer-Chemist        -0.4368421 -7.300507 6.426823 0.9997764\nOther-Data Scientist             -2.0027460 -8.561205 4.555713 0.9143543\nSoftware Engineer-Data Scientist -1.2105263 -8.074192 5.653139 0.9880778\nSoftware Engineer-Other           0.7922197 -5.766240 7.350679 0.9972112\n\n\n\nCheck MANOVA assumptions\n\n# Multivariate normality\nmshapiro.test(t(model.matrix(manova_result)[, -1]))\n\n\n    Shapiro-Wilk normality test\n\ndata:  Z\nW = 0.74976, p-value = 9.227e-12\n\n\n\n# Homogeneity of covariance matrices\nleveneTest(annual_salary ~ gender * job_title, data = pay_gap_data)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup 12   0.597 0.8391\n      87               \n\nleveneTest(years_experience ~ gender * job_title, data = pay_gap_data)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup 12  0.6305 0.8108\n      87               \n\n\n\n\n\nVisual of the results\n\nggplot(pay_gap_data, aes(x = job_title, y = annual_salary, fill = gender)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Salary Distribution by Job Title and Gender\",\n       x = \"Job Title\", y = \"Annual Salary\")\n\n\n\n\n\n\n\nggplot(pay_gap_data, aes(x = job_title, y = years_experience, fill = gender)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Years of Experience Distribution by Job Title and Gender\",\n       x = \"Job Title\", y = \"Years of Experience\")\n\n\n\n\n\n\n\n\nRQ2: Are there significant differences in salary distributions across job titles when accounting for gender and experience?\nTo answer research question two, we’ll run some additoinal analyses.\n\nmodel_salary &lt;- lm(annual_salary ~ job_title + gender + years_experience, data = pay_gap_data)\nanova(model_salary)\n\nAnalysis of Variance Table\n\nResponse: annual_salary\n                 Df     Sum Sq    Mean Sq  F value Pr(&gt;F)    \njob_title         4 2.7038e+08 6.7595e+07   1.5436 0.1962    \ngender            2 5.3524e+09 2.6762e+09  61.1142 &lt;2e-16 ***\nyears_experience  1 1.9615e+10 1.9615e+10 447.9384 &lt;2e-16 ***\nResiduals        92 4.0287e+09 4.3790e+07                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model_salary)\n\n\nCall:\nlm(formula = annual_salary ~ job_title + gender + years_experience, \n    data = pay_gap_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13703  -3632   -128   2751  19370 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                36711.50    1968.85  18.646  &lt; 2e-16 ***\njob_titleChemist              -5.78    2140.76  -0.003  0.99785    \njob_titleData Scientist      -47.80    2148.50  -0.022  0.98230    \njob_titleOther              4453.30    2029.46   2.194  0.03073 *  \njob_titleSoftware Engineer   622.90    2142.47   0.291  0.77191    \ngenderMale                 13964.08    1411.79   9.891 3.87e-16 ***\ngenderNon-binary            7665.83    2841.64   2.698  0.00831 ** \nyears_experience            1893.49      89.47  21.165  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6617 on 92 degrees of freedom\nMultiple R-squared:  0.8623,    Adjusted R-squared:  0.8519 \nF-statistic: 82.33 on 7 and 92 DF,  p-value: &lt; 2.2e-16\n\n\nAs noted in class, these are base models to help you consider your analysis. However, your theory should lead all of your work. Please let me know if you have any questions."
  },
  {
    "objectID": "weeks/week01.html",
    "href": "weeks/week01.html",
    "title": "DATA 202 - Week 1",
    "section": "",
    "text": "In this course, students will develop an understanding of statistics as a research tool. Students are expected to have some basic knowledge of statistics from a prior course. Emphasis will be placed on understanding statistical concepts and applying and interpreting tests of statistical inference for real-life applications. The content will include, but not be limited to, visual representations of data, descriptive statistics, correlation and simple regression, sampling distributions, and the assumptions associated with and the application of selected inferential statistical procedures. Throughout the course, there will be a strong emphasis on how statistical modeling can be a driving force for social justice.",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01.html#course-description",
    "href": "weeks/week01.html#course-description",
    "title": "DATA 202 - Week 1",
    "section": "",
    "text": "In this course, students will develop an understanding of statistics as a research tool. Students are expected to have some basic knowledge of statistics from a prior course. Emphasis will be placed on understanding statistical concepts and applying and interpreting tests of statistical inference for real-life applications. The content will include, but not be limited to, visual representations of data, descriptive statistics, correlation and simple regression, sampling distributions, and the assumptions associated with and the application of selected inferential statistical procedures. Throughout the course, there will be a strong emphasis on how statistical modeling can be a driving force for social justice.",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01.html#course-learning-objectives",
    "href": "weeks/week01.html#course-learning-objectives",
    "title": "DATA 202 - Week 1",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\n\nAppreciate and understand the role of statistics in your field\nEvaluate, comprehend, and explain the statistical findings in a data set\nExplore data in R\nApply appropriate application and interpretation of various inferential statistical procedures\nWrite a simple description of methodology and results from analysis\nDevelop an ability to apply appropriate statistical methods to summarize and analyze data\nMake sense of data and be able to report the results in appropriate tables or statistical terms",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01.html#course-companion-site",
    "href": "weeks/week01.html#course-companion-site",
    "title": "DATA 202 - Week 1",
    "section": "Course companion site",
    "text": "Course companion site\nThe landing page for our companion site can be found here.",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01.html#initial-assignments",
    "href": "weeks/week01.html#initial-assignments",
    "title": "DATA 202 - Week 1",
    "section": "Initial assignments",
    "text": "Initial assignments\n\nAnnotated Bibliography\nYour annotated bibliography is due Sun Feb 2 using OpenAlex or the Web of Science (WoS).\n\n\nLab #1\nLab 1 is due Sun Feb 16.\n\n\nPaper #1\nYou can read more about paper #1 here.\nSee the instructions for paper assignments here.\nAlso, learn more about paper assignments here.",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "href": "weeks/week01.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "title": "DATA 202 - Week 1",
    "section": "Case Study 1: Tuskegee Experiement of Untreated Syphillis",
    "text": "Case Study 1: Tuskegee Experiement of Untreated Syphillis\nTo help you prepare for our forthcoming discussions and readings, you should explore information about our first case study. One place to start is here: “The Tuskegee Experiment: Crash Course Black American History #29” in the video below:",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week01-slides.html#course-description",
    "href": "weeks/week01-slides.html#course-description",
    "title": "DATA 202 - Week 1",
    "section": "Course Description",
    "text": "Course Description\nIn this course, students will develop an understanding of statistics as a research tool. Students are expected to have some basic knowledge of statistics from a prior course. Emphasis will be placed on understanding statistical concepts and applying and interpreting tests of statistical inference for real-life applications. The content will include, but not be limited to, visual representations of data, descriptive statistics, correlation and simple regression, sampling distributions, and the assumptions associated with and the application of selected inferential statistical procedures. Throughout the course, there will be a strong emphasis on how statistical modeling can be a driving force for social justice."
  },
  {
    "objectID": "weeks/week01-slides.html#course-learning-objectives",
    "href": "weeks/week01-slides.html#course-learning-objectives",
    "title": "DATA 202 - Week 1",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\n\nAppreciate and understand the role of statistics in your field\nEvaluate, comprehend, and explain the statistical findings in a data set\nExplore data in R\nApply appropriate application and interpretation of various inferential statistical procedures\nWrite a simple description of methodology and results from analysis\nDevelop an ability to apply appropriate statistical methods to summarize and analyze data\nMake sense of data and be able to report the results in appropriate tables or statistical terms"
  },
  {
    "objectID": "weeks/week01-slides.html#course-companion-site",
    "href": "weeks/week01-slides.html#course-companion-site",
    "title": "DATA 202 - Week 1",
    "section": "Course companion site",
    "text": "Course companion site\nThe landing page for our companion site can be found here."
  },
  {
    "objectID": "weeks/week01-slides.html#initial-assignments",
    "href": "weeks/week01-slides.html#initial-assignments",
    "title": "DATA 202 - Week 1",
    "section": "Initial assignments",
    "text": "Initial assignments\nAnnotated Bibliography\nYour annotated bibliography is due Sun Feb 2 using OpenAlex or the Web of Science (WoS).\nLab #1\nLab 1 is due Sun Feb 16.\nPaper #1\nYou can read more about paper #1 here.\nSee the instructions for paper assignments here.\nAlso, learn more about paper assignments here."
  },
  {
    "objectID": "weeks/week01-slides.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "href": "weeks/week01-slides.html#case-study-1-tuskegee-experiement-of-untreated-syphillis",
    "title": "DATA 202 - Week 1",
    "section": "Case Study 1: Tuskegee Experiement of Untreated Syphillis",
    "text": "Case Study 1: Tuskegee Experiement of Untreated Syphillis\nTo help you prepare for our forthcoming discussions and readings, you should explore information about our first case study. One place to start is here: “The Tuskegee Experiment: Crash Course Black American History #29” in the video below:"
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Lab 2",
    "section": "",
    "text": "For Lab 2, you may submit your solutions to Canvas as a .pdf or an RMarkdown.\nPlease see the Preparing Lab Reports at the bottom of the lab 1 assignment.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#learning-objectives",
    "href": "labs/lab2.html#learning-objectives",
    "title": "Lab 2",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe Lab 2 assignment focuses on you exploring any three or more variables, of which data can come from anywhere. You can use data located in one of the data frames in the critstats package or in gss_cat, or a data set that you have identified and would like to explore. You will also return to some of the functions we have used before to clean variables and manipulate data frames. Your analyses in this lab should focus on a bivariate analysis between two categorical variables, two numeric variables, or one numeric variable and one categorical variable.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#learning-activities",
    "href": "labs/lab2.html#learning-activities",
    "title": "Lab 2",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this lab you will be able to:\n\nLocate data; okay to use data sets in the critstats package, or use gss_cat\nDevelop an original research question\nClean and manipulate data for analysis\nExamine the relationship between three or more variables\n\nYou should submit your final output on Canvas here.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#task-0.1-create-a-new-rmarkdown",
    "href": "labs/lab2.html#task-0.1-create-a-new-rmarkdown",
    "title": "Lab 2",
    "section": "Task 0.1: Create a new RMarkdown",
    "text": "Task 0.1: Create a new RMarkdown\nIn your R session, navigate to: File &gt; New File &gt; R Markdown. Create a new markdown file using an appropriate title.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#task-0.2-check-your-working-directory",
    "href": "labs/lab2.html#task-0.2-check-your-working-directory",
    "title": "Lab 2",
    "section": "Task 0.2: Check your working directory",
    "text": "Task 0.2: Check your working directory\nCheck your working directory by typing getwd().\nIf you are not in the desired directory, you can change your directory using the associated path. This path should be the same as the project folder that you plan to work out of for the next several weeks.\n\n# insert your desired path in the parenthesis and remove the #\n# setwd(\"/your/working/directory/goes/here\") \n\nYou can add a new sub-folder manually or under the Files tab in the RStudio IDE.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#task-0.3-write-a-preamble",
    "href": "labs/lab2.html#task-0.3-write-a-preamble",
    "title": "Lab 2",
    "section": "Task 0.3: Write a preamble",
    "text": "Task 0.3: Write a preamble\n\n## Name: &lt;include your full name&gt;\n## Assignment: Lab 2\n## Date: &lt;here you may want to add a date&gt;\n## Purpose: &lt;insert the goals or purpose of the RScript&gt;",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#task-0.4-packages-and-libraries",
    "href": "labs/lab2.html#task-0.4-packages-and-libraries",
    "title": "Lab 2",
    "section": "Task 0.4: Packages and libraries",
    "text": "Task 0.4: Packages and libraries\n\n# install the tidyverse package\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n\n# load the libraries needed for today's analyses\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(critstats)\n\n## update packages if needed; remove # to run code\n# update.packages(\"package-name\")",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.1",
    "href": "labs/lab2.html#report-1.1",
    "title": "Lab 2",
    "section": "Report 1.1",
    "text": "Report 1.1\nWhat data set have you decided to use?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.2",
    "href": "labs/lab2.html#report-1.2",
    "title": "Lab 2",
    "section": "Report 1.2",
    "text": "Report 1.2\nWhich variables from your data set will be analyzed?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.3",
    "href": "labs/lab2.html#report-1.3",
    "title": "Lab 2",
    "section": "Report 1.3",
    "text": "Report 1.3\nWhat is your research question?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.4",
    "href": "labs/lab2.html#report-1.4",
    "title": "Lab 2",
    "section": "Report 1.4",
    "text": "Report 1.4\nWhat is your data analysis plan? Please be descriptive.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.5",
    "href": "labs/lab2.html#report-1.5",
    "title": "Lab 2",
    "section": "Report 1.5",
    "text": "Report 1.5\nWhat are some potential limitations for your analysis?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.6",
    "href": "labs/lab2.html#report-1.6",
    "title": "Lab 2",
    "section": "Report 1.6",
    "text": "Report 1.6\nDoes your data contain missing values? If so, how have you dealt with these values?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.7",
    "href": "labs/lab2.html#report-1.7",
    "title": "Lab 2",
    "section": "Report 1.7",
    "text": "Report 1.7\nPlease include all code used to clean and manipulate the variables.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.8",
    "href": "labs/lab2.html#report-1.8",
    "title": "Lab 2",
    "section": "Report 1.8",
    "text": "Report 1.8\nWhat relationship, if any, exists between the two variables?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.9",
    "href": "labs/lab2.html#report-1.9",
    "title": "Lab 2",
    "section": "Report 1.9",
    "text": "Report 1.9\nHow do these findings relate to your research question and theory?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2.html#report-1.10",
    "href": "labs/lab2.html#report-1.10",
    "title": "Lab 2",
    "section": "Report 1.10",
    "text": "Report 1.10\nWhat limitations exist as a result of the data analysis?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Lab 1",
    "section": "",
    "text": "For Lab 1, you should submit your solutions to Canvas as a RMarkdown syntax (i.e., you can render an html file or push your code to GitHub, or share the .Rmd file). Please see the Preparing Lab Reports section at the bottom of this assignment.\nThe Lab 1 assignment will reintroduce you to data in the critstats package and add a second data set known as gss_cat. However, for the lab 1 and paper 2 assignment, you may use your own data set and we can work together to find you a data set that is ready to be analyzed. For new users, I would recommend against data that needs to be cleaned. However, by visiting the case study 2 files, you can learn more about cleaning your data.\nThat said, during this lab, you will also return to some of the functions we have used before to clean variables and manipulate data frames. Your analyses in this lab should focus on a bivariate analysis between two categorical variables, two numeric variables, or one numeric variable and one categorical variable.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#learning-activities",
    "href": "labs/lab1.html#learning-activities",
    "title": "Lab 1",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this lab you will be able to:\n\nLocate data sets in the critstats package\nDevelop an original research question\nClean and manipulate data for analysis\nExamine the relationship between two variables\n\nYou should submit your final output on Canvas.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#task-0.1-create-a-new-rmarkdown",
    "href": "labs/lab1.html#task-0.1-create-a-new-rmarkdown",
    "title": "Lab 1",
    "section": "Task 0.1: Create a new RMarkdown",
    "text": "Task 0.1: Create a new RMarkdown\nIn your R session, navigate to: File &gt; New File &gt; R Markdown. Create a new markdown file using an appropriate title.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#task-0.2-check-your-working-directory",
    "href": "labs/lab1.html#task-0.2-check-your-working-directory",
    "title": "Lab 1",
    "section": "Task 0.2: Check your working directory",
    "text": "Task 0.2: Check your working directory\nCheck your working directory by typing getwd().\nIf you are not in the desired directory, you can change your directory using the associated path. This path should be the same as the project folder that you plan to work out of for the next several weeks.\n\n# insert your desired path in the parenthesis and remove the #\n# setwd(\"/your/working/directory/goes/here\") \n\nYou can add a new sub-folder manually or under the Files tab in the RStudio IDE.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#task-0.3-write-a-preamble",
    "href": "labs/lab1.html#task-0.3-write-a-preamble",
    "title": "Lab 1",
    "section": "Task 0.3: Write a preamble",
    "text": "Task 0.3: Write a preamble\nName:  Assignment: Lab 2 Date:  Purpose:",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#task-0.4-packages-and-libraries",
    "href": "labs/lab1.html#task-0.4-packages-and-libraries",
    "title": "Lab 1",
    "section": "Task 0.4: Packages and libraries",
    "text": "Task 0.4: Packages and libraries\n\n# install the tidyverse package\n#install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n#install.packages(\"devtools\")\n#install.packages(\"remotes\")\n#library(remotes)\n#remotes::install_github(\"professornaite/critstats\", force=TRUE)\n\n# load the libraries needed for today's analyses\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(critstats)\n\n## update packages if needed; remove # to run code\n# update.packages(\"package-name\")",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.1",
    "href": "labs/lab1.html#report-1.1",
    "title": "Lab 1",
    "section": "Report 1.1",
    "text": "Report 1.1\nWhat data set have you decided to use?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.2",
    "href": "labs/lab1.html#report-1.2",
    "title": "Lab 1",
    "section": "Report 1.2",
    "text": "Report 1.2\nWhich two variables from your data set will be analyzed?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.3",
    "href": "labs/lab1.html#report-1.3",
    "title": "Lab 1",
    "section": "Report 1.3",
    "text": "Report 1.3\nWhat is your research question?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.4",
    "href": "labs/lab1.html#report-1.4",
    "title": "Lab 1",
    "section": "Report 1.4",
    "text": "Report 1.4\nWhat is your data analysis plan? Please be descriptive.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.5",
    "href": "labs/lab1.html#report-1.5",
    "title": "Lab 1",
    "section": "Report 1.5",
    "text": "Report 1.5\nWhat are some potential limitations for your analysis?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.6",
    "href": "labs/lab1.html#report-1.6",
    "title": "Lab 1",
    "section": "Report 1.6",
    "text": "Report 1.6\nDoes your data contain missing values? If so, how have you dealt with these values?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.7",
    "href": "labs/lab1.html#report-1.7",
    "title": "Lab 1",
    "section": "Report 1.7",
    "text": "Report 1.7\nPlease include all code used to clean and manipulate the variables.",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.8",
    "href": "labs/lab1.html#report-1.8",
    "title": "Lab 1",
    "section": "Report 1.8",
    "text": "Report 1.8\nWhat relationship, if any, exists between the two variables?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.9",
    "href": "labs/lab1.html#report-1.9",
    "title": "Lab 1",
    "section": "Report 1.9",
    "text": "Report 1.9\nHow do these findings relate to your research question and theory?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1.html#report-1.10",
    "href": "labs/lab1.html#report-1.10",
    "title": "Lab 1",
    "section": "Report 1.10",
    "text": "Report 1.10\nWhat limitations exist as a result of the data analysis?",
    "crumbs": [
      "Appendix",
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "For Lab 3, you should be analyzing some set of data related to your paper 1 assignment. Please see the Preparing Lab Reports at the bottom of the lab 1 assignment."
  },
  {
    "objectID": "labs/lab3.html#learning-objectives",
    "href": "labs/lab3.html#learning-objectives",
    "title": "Lab 3",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe Lab 3 assignment will provide you with an opportunity to self-direct your analysis to write up a substantive argument started in paper 1 for paper 3."
  },
  {
    "objectID": "labs/lab3.html#report-1.1",
    "href": "labs/lab3.html#report-1.1",
    "title": "Lab 3",
    "section": "Report 1.1",
    "text": "Report 1.1\nWhat data set have you decided to use?"
  },
  {
    "objectID": "labs/lab3.html#report-1.2",
    "href": "labs/lab3.html#report-1.2",
    "title": "Lab 3",
    "section": "Report 1.2",
    "text": "Report 1.2\nWhich two variables from your data set will be analyzed?"
  },
  {
    "objectID": "labs/lab3.html#report-1.3",
    "href": "labs/lab3.html#report-1.3",
    "title": "Lab 3",
    "section": "Report 1.3",
    "text": "Report 1.3\nWhat is your research question?"
  },
  {
    "objectID": "labs/lab3.html#report-1.4",
    "href": "labs/lab3.html#report-1.4",
    "title": "Lab 3",
    "section": "Report 1.4",
    "text": "Report 1.4\nWhat is your data analysis plan? Please be descriptive."
  },
  {
    "objectID": "labs/lab3.html#report-1.5",
    "href": "labs/lab3.html#report-1.5",
    "title": "Lab 3",
    "section": "Report 1.5",
    "text": "Report 1.5\nWhat are some potential limitations for your analysis?"
  },
  {
    "objectID": "labs/lab3.html#report-1.6",
    "href": "labs/lab3.html#report-1.6",
    "title": "Lab 3",
    "section": "Report 1.6",
    "text": "Report 1.6\nDoes your data contain missing values? If so, how have you dealt with these values?"
  },
  {
    "objectID": "labs/lab3.html#report-1.7",
    "href": "labs/lab3.html#report-1.7",
    "title": "Lab 3",
    "section": "Report 1.7",
    "text": "Report 1.7\nPlease include all code used to clean and manipulate the variables."
  },
  {
    "objectID": "labs/lab3.html#report-1.8",
    "href": "labs/lab3.html#report-1.8",
    "title": "Lab 3",
    "section": "Report 1.8",
    "text": "Report 1.8\nWhat relationship, if any, exists between the variables?"
  },
  {
    "objectID": "labs/lab3.html#report-1.9",
    "href": "labs/lab3.html#report-1.9",
    "title": "Lab 3",
    "section": "Report 1.9",
    "text": "Report 1.9\nHow do these findings relate to your research question and theory outlined in your proposal for paper 1? Please be specific."
  },
  {
    "objectID": "labs/lab3.html#report-1.10",
    "href": "labs/lab3.html#report-1.10",
    "title": "Lab 3",
    "section": "Report 1.10",
    "text": "Report 1.10\nWhat limitations exist as a result of the data analysis?"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This page contains three sections:\n\nBrief overview of all course assignments.\nInformation about lab 0 (ungraded).\n\n\nOverview of course assignments\nOur course assignments will be split between reading and typing (code and analytic results).\n\n\n\n\n\n\n\n\nCourse component\nAssignment\nDate(s)\n\n\n\n\nPart I: Statistics and society\nLab #0\nDue: Tue Aug 26\n\n\n\n\n\n\n\n\nLab #1\nDue: Sun Sept 21\n\n\nPart II: Data and people\n\n\n\n\n\nLab #2\nDue: Sun Oct 12\n\n\nPart III: Data and policy\n\n\n\n\n\nLab #3\nDue: Sun Nov 5\n\n\nPart IV: Data in practice\n\n\n\n\n\nFinal paper\nDue: Sun Nov 23\n\n\n\n\n\n\n\n\n\n\nHomework 0\nBelow are a few sample exercises of the types of problems we’ll explore in class. This work is ungraded, and while there is no prerequisite for this course, these problems should serve as a review and a preview of content that we’ll explore for the course. Please do not hesitate to reach out with questions.\nExercise 0.1. If an individual’s projected income is to be converted to a z-score, which of these z-scores would a “rational agent” prefer: -2.00, -1.00, 0, 1.00, or 2.00? What is a “rational agent”? Explain why the “rational agent” would prefer the z-score you selected? Cite any sources.\nExercise 0.2. What is an integer? What is the sum of the first 100 positive integers? Explain your solution. Cite any sources. Bonus points (but definitely not required for our course): write a proof of the solution.\nExercise 0.3. Have you ever heard of p-hacking? P-hacking is where a researcher conducts multiple tests and only reports the significant results from those tests. What are some main issues here?\n\n\nLab 0\nFor your first lab, you will install two software programs on your local machine: the first is base R and the second is the RStudio Integrated Development Environment, or IDE. Both programs are required.\n\n\n\n\n\n\nYou must download both R and RStudio!\n\n\n\n\n\nIn order to complete assignments, you must download base R and RStudio to your computer.\n\n\n\nRStudio is now called Posit. When you are searching online you will begin to see language differences.\nIt can all get very confusing. In order to reduce confusion, I am requesting that you watch this short tutorial so that we’re all on the same page. I will discuss this more when we meet.\n\n\nNext up: Computing\nOn the next page, I will walk you through downloading the appropriate software for our work this term.",
    "crumbs": [
      "Course information",
      "Assignments"
    ]
  },
  {
    "objectID": "weeks/week02-slides.html#what-is-statistics",
    "href": "weeks/week02-slides.html#what-is-statistics",
    "title": "DATA 202 - Week 2",
    "section": "What is Statistics?",
    "text": "What is Statistics?\nStatistics is a science. As a result, it follows a set of well-defined steps or methods. As we explore new terms and definitions, we will gain a better understanding of what statistics encompasses.\n\n\n\nDEFINITION: Statistics\n\n\nStatistics is the science of collecting, organizing, analyzing, interpreting, communicating, and visualizing data and information.\n\n\n\nThere are a multitude of ways to describe the steps, terms, and various processes undertaken in a statistical study. Importantly, however, modern statistics calls for more critical questions where we explore difference or change within specified contexts. We then use theory and concepts of variation to understand differences within or between a set (or sets) of measurements, resulting in a more critical orientation to statistics."
  },
  {
    "objectID": "weeks/week02-slides.html#what-is-critical-statistics",
    "href": "weeks/week02-slides.html#what-is-critical-statistics",
    "title": "DATA 202 - Week 2",
    "section": "What is Critical Statistics?",
    "text": "What is Critical Statistics?\nIn popular media, we might see information reported as follows:\n\nIn 2022, college enrollment for 18-24 year-olds in the United States was 39%, a two percent decrease from 41% in 2012. The enrollment rate for those aged 18-24 in 2022 who were Black was 36%, which was lower than the rates for Asian students, which was 61%, and White students, which was 41%.\n\nThe data above is from the U.S. National Center for Education Statistics (NCES). While reading the paragraph, what were some of your opinions? What questions did you have?\n\nHow was enrollment defined and measured?\nShould the differences be viewed as significant in some way?\nDo the percents mean that some students are less likely to go to college?"
  },
  {
    "objectID": "weeks/week02-slides.html#a-different-world-of-statistics",
    "href": "weeks/week02-slides.html#a-different-world-of-statistics",
    "title": "DATA 202 - Week 2",
    "section": "A Different World of Statistics",
    "text": "A Different World of Statistics\nThe idea of traditional statistics vs. non-traditional statistics may mean, on the surface at least, that we are in need of a critical statistics, and fast. But what if this dichotomy is a false one? What other pathways exist? Pathways of refusal? Pathways of exploration?\nWe will make attempts to reside in the space between refusal and exploration, as two key aspects of what we will come to know as critical statistics. By employing a practice of refusal, we will have space to refuse harmful beliefs and scientific practices. In the spirit of learning, we will also explore the potential benefits (and drawbacks) of critical statistics.\n\n\n\n\n\n\nTraditional approaches to statistics\n\n\nCritical approaches to statistics require interdisciplinary thinking."
  },
  {
    "objectID": "weeks/week02-slides.html#what-should-it-mean-to-be-critical-in-the-context-of-statistics",
    "href": "weeks/week02-slides.html#what-should-it-mean-to-be-critical-in-the-context-of-statistics",
    "title": "DATA 202 - Week 2",
    "section": "What should it mean to be critical in the context of statistics?",
    "text": "What should it mean to be critical in the context of statistics?\nNotes from Duncan (n.d.) reading.\nOn Canvas, in the Week 2 folder, there is a document titled “Critical Thinking” by Jennifer Duncan. This document is one example of how we can frame what it could or should mean to be critical in statistics. Please review this document."
  },
  {
    "objectID": "weeks/week02-slides.html#sets-and-numbers",
    "href": "weeks/week02-slides.html#sets-and-numbers",
    "title": "DATA 202 - Week 2",
    "section": "Sets and numbers",
    "text": "Sets and numbers\n\n\n\nDEFINITIONS: Sets of numbers\n\n\n– Natural numbers: \\(\\mathbb{N} = \\{1, 2, 3, ...\\}\\)\n– Whole numbers: \\(\\mathbb{N_0} = \\{0, 1, 2, 3, ...\\}\\)\n– Integers: \\(\\mathbb{Z} = \\{..., -3, -2, -1, 0, 1, 2, 3, ...\\}\\)\n– Rational numbers: \\(\\mathbb{Q} = \\Big\\{\\dfrac{p}{q}, p \\in \\mathbb{Z}, q \\in \\mathbb{Z}, q \\neq 0 \\Big\\}\\)"
  },
  {
    "objectID": "weeks/week02-slides.html#getting-started-in-rstudio",
    "href": "weeks/week02-slides.html#getting-started-in-rstudio",
    "title": "DATA 202 - Week 2",
    "section": "Getting started in RStudio",
    "text": "Getting started in RStudio\nIn Lab 0, you downloaded and installed base R and RStudio. In this section, we will learn more about R and RStudio.\nLet’s start with a little fun!"
  },
  {
    "objectID": "weeks/week02-slides.html#arithmetic-in-r",
    "href": "weeks/week02-slides.html#arithmetic-in-r",
    "title": "DATA 202 - Week 2",
    "section": "Arithmetic in R",
    "text": "Arithmetic in R\nWe will learn how to calculate values in R."
  },
  {
    "objectID": "weeks/week02-slides.html#variables-in-r",
    "href": "weeks/week02-slides.html#variables-in-r",
    "title": "DATA 202 - Week 2",
    "section": "Variables in R",
    "text": "Variables in R\nWe will learn to give a variable (or character) a value."
  },
  {
    "objectID": "weeks/week02.html",
    "href": "weeks/week02.html",
    "title": "DATA 202 - Week 2",
    "section": "",
    "text": "Statistics is a science. As a result, it follows a set of well-defined steps or methods. As we explore new terms and definitions, we will gain a better understanding of what statistics encompasses.\n\n\n\n\n\n\nDEFINITION: Statistics\n\n\n\nStatistics is the science of collecting, organizing, analyzing, interpreting, communicating, and visualizing data and information.\n\n\nThere are a multitude of ways to describe the steps, terms, and various processes undertaken in a statistical study. Importantly, however, modern statistics calls for more critical questions where we explore difference or change within specified contexts. We then use theory and concepts of variation to understand differences within or between a set (or sets) of measurements, resulting in a more critical orientation to statistics.\n\n\n\n\nIn popular media, we might see information reported as follows:\n\nIn 2022, college enrollment for 18-24 year-olds in the United States was 39%, a two percent decrease from 41% in 2012. The enrollment rate for those aged 18-24 in 2022 who were Black was 36%, which was lower than the rates for Asian students, which was 61%, and White students, which was 41%.\n\nThe data above is from the U.S. National Center for Education Statistics (NCES). While reading the paragraph, what were some of your opinions? What questions did you have?\n\nHow was enrollment defined and measured?\nShould the differences be viewed as significant in some way?\nDo the percents mean that some students are less likely to go to college?\n\n\nIn traditional statistics, a quantitative research question is answered using the scientific method. A traditionalist may blindly follow the steps of this method, focusing on model selection and assumptions while also ignoring any broader social and historical contexts.\nIn the social sciences, for example, statistics continues to be used to perpetuate negative stereotypes – which does not simply give it a bad rap but it results in real-world harm to communities. Does this mean we are just in need of critical statistics?\n\n\n\n\n\n\n\nExample: Challenging Statistics in Media\n\n\n\nThe American sitcom A Different World challenged negative stereotypes associated with Black youth and families regarding the pursuit of higher education. By portraying a vibrant college life at Hillman, a predominately Black college in the U.S., the series highlighted the importance of education as a priority within the Black community.\n\n\n\nImage of ‘A Different World’ cast\n\n\n\n\n\n\n\n\n\n\n\nPractice\n\n\n\nIn a discussion about the U.S. college enrollment rate of Black 18-24 year-olds, your colleague Rachel cites Bill Cosby and two shows that he produced, A Different World and The Cosby Show, as important examples to combat deficit racial stereotypes. However, during the discussion, another colleague mentions how Bill Cosby was found guilty of aggravated indecent assault and sexual predation, and mentions that we have to be mindful of the work we cite and the persons responsible for producing the work. The colleague states that ``one problematic case should not be combated with another problematic case” referring to Cosby; Rachel disagrees. Both colleagues ask for your opinion on the discussion. How might you respond?\n\n\n\n\n\nThe idea of traditional statistics vs. non-traditional statistics may mean, on the surface at least, that we are in need of a critical statistics, and fast. But what if this dichotomy is a false one? What other pathways exist? Pathways of refusal? Pathways of exploration?\nWe will make attempts to reside in the space between refusal and exploration, as two key aspects of what we will come to know as critical statistics. By employing a practice of refusal, we will have space to refuse harmful beliefs and scientific practices. In the spirit of learning, we will also explore the potential benefits (and drawbacks) of critical statistics.\n\n\n\n\n\n\nTraditional approaches to statistics\n\n\n\nCritical approaches to statistics require interdisciplinary thinking.\n\n\n\nTraditional approaches to statistics in some areas of study, like the environmental sciences, provide important information about changes and differences in global patterns. In other areas of study, such as education and the social sciences, statistics has a different history.\nIn the specific case of U.S. college enrollment rates, you may be concerned with some broader questions about data in the education sciences. In the spirit of exploration, you might ask:\n\nShould we interpret these enrollment statistics as indicative of broader societal issues affecting access to higher education?\nWhat are the historical and systemic barriers that could explain the differences in enrollment rates among students?\n\n\nAlternatively, in the spirit of refusal, some different questions come to the surface:\n\nWhat beliefs underlie the analysis of college enrollment rates?\nWhat assumptions are being made when quantifying educational pathways?\nHow does rejecting conventional racial comparisons challenge power dynamics?\n\nThis second set of questions, as early examples of a practice of refusal, encourage your critical thinking in a few ways. First, the questions ask you to think about the less explicit components of the paragraph. Second, the questions present an option to reject conventional approaches to how we measure educational outcomes and ask why. Third, and to the seeming contradiction between refusal and exploration, a set of new pathways arise.\n\n\n\n\n\n\n\nPractice\n\n\n\nBad Stats (or BS), outlined by Professor Ivory Toldson, are data points that are poorly contextualized, generally negative, and they are often incomplete or incorrect. They are part of a problematic trend in which statistics are used to reinforce negative stereotypes. Identify two examples of Bad Stats in popular media.",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#what-is-statistics",
    "href": "weeks/week02.html#what-is-statistics",
    "title": "DATA 202 - Week 2",
    "section": "",
    "text": "Statistics is a science. As a result, it follows a set of well-defined steps or methods. As we explore new terms and definitions, we will gain a better understanding of what statistics encompasses.\n\n\n\n\n\n\nDEFINITION: Statistics\n\n\n\nStatistics is the science of collecting, organizing, analyzing, interpreting, communicating, and visualizing data and information.\n\n\nThere are a multitude of ways to describe the steps, terms, and various processes undertaken in a statistical study. Importantly, however, modern statistics calls for more critical questions where we explore difference or change within specified contexts. We then use theory and concepts of variation to understand differences within or between a set (or sets) of measurements, resulting in a more critical orientation to statistics.",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#what-is-critical-statistics",
    "href": "weeks/week02.html#what-is-critical-statistics",
    "title": "DATA 202 - Week 2",
    "section": "",
    "text": "In popular media, we might see information reported as follows:\n\nIn 2022, college enrollment for 18-24 year-olds in the United States was 39%, a two percent decrease from 41% in 2012. The enrollment rate for those aged 18-24 in 2022 who were Black was 36%, which was lower than the rates for Asian students, which was 61%, and White students, which was 41%.\n\nThe data above is from the U.S. National Center for Education Statistics (NCES). While reading the paragraph, what were some of your opinions? What questions did you have?\n\nHow was enrollment defined and measured?\nShould the differences be viewed as significant in some way?\nDo the percents mean that some students are less likely to go to college?\n\n\nIn traditional statistics, a quantitative research question is answered using the scientific method. A traditionalist may blindly follow the steps of this method, focusing on model selection and assumptions while also ignoring any broader social and historical contexts.\nIn the social sciences, for example, statistics continues to be used to perpetuate negative stereotypes – which does not simply give it a bad rap but it results in real-world harm to communities. Does this mean we are just in need of critical statistics?\n\n\n\n\n\n\n\nExample: Challenging Statistics in Media\n\n\n\nThe American sitcom A Different World challenged negative stereotypes associated with Black youth and families regarding the pursuit of higher education. By portraying a vibrant college life at Hillman, a predominately Black college in the U.S., the series highlighted the importance of education as a priority within the Black community.\n\n\n\nImage of ‘A Different World’ cast\n\n\n\n\n\n\n\n\n\n\n\nPractice\n\n\n\nIn a discussion about the U.S. college enrollment rate of Black 18-24 year-olds, your colleague Rachel cites Bill Cosby and two shows that he produced, A Different World and The Cosby Show, as important examples to combat deficit racial stereotypes. However, during the discussion, another colleague mentions how Bill Cosby was found guilty of aggravated indecent assault and sexual predation, and mentions that we have to be mindful of the work we cite and the persons responsible for producing the work. The colleague states that ``one problematic case should not be combated with another problematic case” referring to Cosby; Rachel disagrees. Both colleagues ask for your opinion on the discussion. How might you respond?",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#a-different-world-of-statistics",
    "href": "weeks/week02.html#a-different-world-of-statistics",
    "title": "DATA 202 - Week 2",
    "section": "",
    "text": "The idea of traditional statistics vs. non-traditional statistics may mean, on the surface at least, that we are in need of a critical statistics, and fast. But what if this dichotomy is a false one? What other pathways exist? Pathways of refusal? Pathways of exploration?\nWe will make attempts to reside in the space between refusal and exploration, as two key aspects of what we will come to know as critical statistics. By employing a practice of refusal, we will have space to refuse harmful beliefs and scientific practices. In the spirit of learning, we will also explore the potential benefits (and drawbacks) of critical statistics.\n\n\n\n\n\n\nTraditional approaches to statistics\n\n\n\nCritical approaches to statistics require interdisciplinary thinking.\n\n\n\nTraditional approaches to statistics in some areas of study, like the environmental sciences, provide important information about changes and differences in global patterns. In other areas of study, such as education and the social sciences, statistics has a different history.\nIn the specific case of U.S. college enrollment rates, you may be concerned with some broader questions about data in the education sciences. In the spirit of exploration, you might ask:\n\nShould we interpret these enrollment statistics as indicative of broader societal issues affecting access to higher education?\nWhat are the historical and systemic barriers that could explain the differences in enrollment rates among students?\n\n\nAlternatively, in the spirit of refusal, some different questions come to the surface:\n\nWhat beliefs underlie the analysis of college enrollment rates?\nWhat assumptions are being made when quantifying educational pathways?\nHow does rejecting conventional racial comparisons challenge power dynamics?\n\nThis second set of questions, as early examples of a practice of refusal, encourage your critical thinking in a few ways. First, the questions ask you to think about the less explicit components of the paragraph. Second, the questions present an option to reject conventional approaches to how we measure educational outcomes and ask why. Third, and to the seeming contradiction between refusal and exploration, a set of new pathways arise.\n\n\n\n\n\n\n\nPractice\n\n\n\nBad Stats (or BS), outlined by Professor Ivory Toldson, are data points that are poorly contextualized, generally negative, and they are often incomplete or incorrect. They are part of a problematic trend in which statistics are used to reinforce negative stereotypes. Identify two examples of Bad Stats in popular media.",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#what-should-it-mean-to-be-critical-in-the-context-of-statistics",
    "href": "weeks/week02.html#what-should-it-mean-to-be-critical-in-the-context-of-statistics",
    "title": "DATA 202 - Week 2",
    "section": "What should it mean to be critical in the context of statistics?",
    "text": "What should it mean to be critical in the context of statistics?\n\nNotes from Duncan (n.d.) reading.\nOn Canvas, in the Week 2 folder, there is a document titled “Critical Thinking” by Jennifer Duncan. This document is one example of how we can frame what it could or should mean to be critical in statistics. Please review this document.\n\n\nUsing a higher order of thinking. Duncan emphasizes that critical thinking is a higher order of thinking with different advanced thinking skills, and offers a few suggestions.\n\nWe base our thinking on logic and not on feelings.\nWe should look deeper into inferences for hidden assumptions or values.\nAsk complex questions that help build a critical inquiry.\n\n\n\n\nAsking complex questions. Duncan breaks down the process into a few sub-questions.\n\nWho is the implied audience?\nWhat are the strengths and weaknesses of the argument?\nWhat are the underlying assumptions and values?\n\n\n\n\nUsing a variety of thinking processes. Duncan defines a process around analyzing, synthesizing, interpreting, and evaluating information that helps with our thinking.\n\n\n\nReflecting on how we answer a question. Duncan ends with a set of questions that help us think about different points of view, if we have clarity, and if more details are needed.\n\n\nThe quantification of information can help us understand and represent important situations. We’ll begin by exploring the concept of a set, and how it is defined in mathematics and used to frame various situations.\n\n\n\n\n\n\n\nDEFINITION: Set\n\n\n\nA set is a well-defined collection of elements or items.\n\n\nA set is characterized by its contents, or what is generally referred to as a set’s elements. If we are given two sets, the sets are considered equal if and only if they have exactly the same elements. The basic relation for sets is that of membership in a particular set.\n\nWe write \\(x \\in X\\) to indicate that the object \\(x\\) is an element (or member) of the set \\(X\\).\n\n\nA FEW IMPORTANT NOTES:\nNote 1: We tend to label sets using capital letters.\n\nFor example, we may label two different sets as \\(X\\) and \\(Y\\) or as \\(A\\) and \\(B\\).\n\nNote 2: We use curly brackets { and } to enclose the elements of a set.\n\nParentheses ( and ) are often used to indicate a point like \\((x, f(x))\\) or an open interval\nSquare brackets [ and ] are often used to separate sets or to indicate a closed interval.\n\nNote 3: We tend to list the elements of a set using lower case letters with subscripts, \\(x_i\\).\n\nThe \\(i\\) in \\(x_i\\) is a subscript that is used as a “position indicator,” with \\(i = 1, 2, 3, ...\\)\nWe use subscripts to index the elements of a set: \\(X = \\{x_1, x_2, ..., x_n\\}\\) and \\(A = \\{a_1, a_2, ..., a_n\\}\\).\n\n\n\n\n\n\n\n\nEXAMPLES – Sets as a collection of elements or items\n\n\n\nSets can be defined in many different ways.\n\nConsider a set of electronics \\(E\\) = {laptop, phone, tablet, watch} = \\(\\{e_1, e_2, e_3, e_4\\}\\)\nConsider a set of friends \\(F\\) = {Akeah, Brandon, Cris, Daveon, Evelyn}\nConsider a set of numbers \\(N = \\{1, 2, 3, ...\\}\\) = \\(\\{n_1, n_2, n_3, ...\\}\\), so \\(n_1 = 1\\), \\(n_2 = 2\\), …\nConsider a set of sets \\(S\\) = {{laptop, phone, tablet, watch}, {1, 2, 3, …}, …}\n\n\n\n\nQuantifying elements of a set allows us to perform mathematical operations on those elements.\nTogether, the elements and operations combine to create equations, functions, and models that help us understand and communicate details about the elements of a set – which is a form of data.\nWe will need a host of math concepts. The different sets of numbers can be a fun starting point.",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#sets-and-numbers",
    "href": "weeks/week02.html#sets-and-numbers",
    "title": "DATA 202 - Week 2",
    "section": "Sets and numbers",
    "text": "Sets and numbers\n\n\n\n\n\n\nDEFINITIONS: Sets of numbers\n\n\n\n– Natural numbers: \\(\\mathbb{N} = \\{1, 2, 3, ...\\}\\)\n– Whole numbers: \\(\\mathbb{N_0} = \\{0, 1, 2, 3, ...\\}\\)\n– Integers: \\(\\mathbb{Z} = \\{..., -3, -2, -1, 0, 1, 2, 3, ...\\}\\)\n– Rational numbers: \\(\\mathbb{Q} = \\Big\\{\\dfrac{p}{q}, p \\in \\mathbb{Z}, q \\in \\mathbb{Z}, q \\neq 0 \\Big\\}\\)\n\n\n\n\n\n\n\n\n\nDEFINITIONS: Sets of numbers, continued…\n\n\n\n\nIrrational numbers\n\nany number that is not a rational number; irrational means not rational (no ratio)\ne.g., you may know some irrational numbers such as \\(\\pi\\), \\(\\sqrt{2}\\), \\(\\sqrt{3}\\), \\(e\\) (Euler’s number)\n\nReal numbers: \\(\\mathbb{R}\\)\n\nThe set of numbers on the real number line\nThis set is constructed by combining the rational and irrational numbers\n\nImaginary numbers: \\(\\mathbb{I}\\)\n\na number that has a negative value when it is squared\n\\(i\\) is the unit imaginary number, \\(\\sqrt{-1} = i\\) by definition\nso \\(i\\) is a complex number since \\(i^2 = -1\\)\n\nComplex numbers: \\(\\mathbb{C}\\)\n\na number in the form \\(a + bi\\) where \\(a \\in \\mathbb{R}\\), \\(b \\in \\mathbb{R}\\), and \\(i\\) is an imaginary number",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#getting-started-in-rstudio",
    "href": "weeks/week02.html#getting-started-in-rstudio",
    "title": "DATA 202 - Week 2",
    "section": "Getting started in RStudio",
    "text": "Getting started in RStudio\nIn Lab 0, you downloaded and installed base R and RStudio. In this section, we will learn more about R and RStudio.\nLet’s start with a little fun!\n\nFirst, install the ‘praise’ package.\n\n# install the package\ninstall.packages(\"praise\", repos = \"http://cran.us.r-project.org\")\n\n\nNext, load the library for the ‘praise’ package.\n\n# load library\nlibrary(praise)\n\n\nNow, get some praise!\n\n# get some praise\npraise()\n\nYou can keep inserting the code above to get praise when you need it!",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#arithmetic-in-r",
    "href": "weeks/week02.html#arithmetic-in-r",
    "title": "DATA 202 - Week 2",
    "section": "Arithmetic in R",
    "text": "Arithmetic in R\nWe will learn how to calculate values in R.\n\n\n1 + 2  # the 'plus sign' computes the sum\n\n[1] 3\n\n\n\n\n2 - 3  # the 'minus sign' computes the difference\n\n[1] -1\n\n\n\n\n3 * 4  # the 'asterisk' computes the product\n\n[1] 12\n\n\n\n\n4 / 5 # the 'forward slash' computes the quotient\n\n[1] 0.8\n\n\n\n\n# from hw exercise 0.2, we can compute the sum of the first 100 positive integers\nsum(1:100) \n\n[1] 5050",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week02.html#variables-in-r",
    "href": "weeks/week02.html#variables-in-r",
    "title": "DATA 202 - Week 2",
    "section": "Variables in R",
    "text": "Variables in R\nWe will learn to give a variable (or character) a value.\n\nUse the different assignment operators\n\ny = 2 # the equal sign can be used as an assignment operator\n\ny &lt;-2 # a \"less than\" sign and dash can also be used as an assignment operator\n\ny # R stores all values you assign, so you must \"call\" any variables to see their values\n\n[1] 2\n\n\n\nSet x equal to two added to three\n\nx = 2 + 3\nx\n\n[1] 5\n\n\n\nSet y equal to two minus three\n\ny = 2 - 3\ny\n\n[1] -1\n\n\n\nSet z equal to two times three\n\nz = 2 * 3\nz\n\n[1] 6\n\n\n\nOverwrite the value of y by setting y equal to x divided by z\n\ny = x / z\ny\n\n[1] 0.8333333\n\n\n\nIn the next module, we will continue our explorations in R by learning how to load data sets into our data frame, and perform some basic operations using some additional packages. These packages will allow us to consider how we can construct original data sets to develop unique questions for our analysis.",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "analysis/bivariate.html",
    "href": "analysis/bivariate.html",
    "title": "DATA 202 - Bivariate analysis",
    "section": "",
    "text": "Load the libraries we needed. Be sure to install.packages() where needed.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "analysis/bivariate.html#load-the-data-from-github",
    "href": "analysis/bivariate.html#load-the-data-from-github",
    "title": "DATA 202 - Bivariate analysis",
    "section": "Load the data from github",
    "text": "Load the data from github\nWe’ll use data on the gender pay gap that I have prepared for today’s discussion.\n\npay_gap_data &lt;- read.csv(\"https://raw.githubusercontent.com/data-202/sp25/refs/heads/master/data/pay_data.csv\")"
  },
  {
    "objectID": "analysis/bivariate.html#research-question",
    "href": "analysis/bivariate.html#research-question",
    "title": "DATA 202 - Bivariate analysis",
    "section": "Research question",
    "text": "Research question\nRQ: What is the relationship between years of experience and annual salary?\n\nScatterplot\nWe’ll start with a scatterplot to visualize the data.\n\n# Let's visualize the dat a\nggplot(pay_gap_data, aes(x = years_experience, y = annual_salary, color = gender)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Years of Experience vs Annual Salary by Gender\",\n       x = \"Years of Experience\", y = \"Annual Salary\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCorrelation\nWe’ll then conduct a correlation analysis.\n\ncor.test(pay_gap_data$years_experience, pay_gap_data$annual_salary)\n\n\n    Pearson's product-moment correlation\n\ndata:  pay_gap_data$years_experience and pay_gap_data$annual_salary\nt = 15.413, df = 98, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7726828 0.8906291\nsample estimates:\n      cor \n0.8414022 \n\n\n\n\nSimple linear regression\nGiven the nature of our variables, we can run a simple linear regression.\n\nmodel &lt;- lm(annual_salary ~ years_experience, data = pay_gap_data)\n\nWe then want to call a summary of our model.\n\nsummary(model)\n\n\nCall:\nlm(formula = annual_salary ~ years_experience, data = pay_gap_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18654.6  -6516.7    -72.8   6192.4  24311.7 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       45733.6     1765.1   25.91   &lt;2e-16 ***\nyears_experience   1932.6      125.4   15.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9339 on 98 degrees of freedom\nMultiple R-squared:  0.708, Adjusted R-squared:  0.705 \nF-statistic: 237.6 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nIn a future class session, we’ll talk about model specifications and how to apply the tenets of critical quantification. For now, please focus on the code a nd syntax to help you get practice."
  },
  {
    "objectID": "analysis/bivariate.html#research-question-1",
    "href": "analysis/bivariate.html#research-question-1",
    "title": "DATA 202 - Bivariate analysis",
    "section": "Research question",
    "text": "Research question\nRQ: Is there an association between gender and job title?\n\nContingency Table: Gender vs Job Title\n\ntable(pay_gap_data$gender, pay_gap_data$job_title)\n\n            \n             Biologist Chemist Data Scientist Other Software Engineer\n  Female             8       7              6    10                 6\n  Male              10      12             13    12                 9\n  Non-binary         2       0              0     1                 4\n\n\n\n\nChi-square test for independence\n\nchisq.test(pay_gap_data$gender, pay_gap_data$job_title)\n\nWarning in chisq.test(pay_gap_data$gender, pay_gap_data$job_title): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  pay_gap_data$gender and pay_gap_data$job_title\nX-squared = 10.259, df = 8, p-value = 0.2473\n\n\n\n\nBoxplot: Annual Salary by Gender\n\nggplot(pay_gap_data, aes(x = gender, y = annual_salary, fill = gender)) +\n  geom_boxplot() +\n  labs(title = \"Annual Salary Distribution by Gender\",\n       x = \"Gender\", y = \"Annual Salary\")"
  },
  {
    "objectID": "analysis/bivariate.html#research-question-2",
    "href": "analysis/bivariate.html#research-question-2",
    "title": "DATA 202 - Bivariate analysis",
    "section": "Research Question",
    "text": "Research Question\n\nANOVA: Annual salary differences among genders\n\nanova_result &lt;- aov(annual_salary ~ gender, data = pay_gap_data)\n\n\nsummary(anova_result)\n\n            Df    Sum Sq   Mean Sq F value   Pr(&gt;F)    \ngender       2 5.462e+09 2.731e+09   11.13 4.46e-05 ***\nResiduals   97 2.380e+10 2.454e+08                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nt-test: Salary difference between two genders (e.g., Male vs Female)\n\nt.test(annual_salary ~ gender, data = pay_gap_data[pay_gap_data$gender %in% c(\"Male\", \"Female\"),])\n\n\n    Welch Two Sample t-test\n\ndata:  annual_salary by gender\nt = -4.7815, df = 84.835, p-value = 7.246e-06\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -21961.12  -9061.08\nsample estimates:\nmean in group Female   mean in group Male \n            59756.76             75267.86 \n\n\n\n\nMultiple linear regression: Salary vs experience and Gender\nWe can also do a multiple linear regression model.\nMore on this soon.\n\nmulti_model &lt;- lm(annual_salary ~ years_experience + gender, data = pay_gap_data)\n\nThen we call a summary of our model.\n\nsummary(multi_model)\n\n\nCall:\nlm(formula = annual_salary ~ years_experience + gender, data = pay_gap_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12628.5  -4703.1   -528.8   3620.1  19084.8 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       38180.5     1521.7  25.091  &lt; 2e-16 ***\nyears_experience   1878.4       90.8  20.688  &lt; 2e-16 ***\ngenderMale        13724.7     1430.6   9.594 1.11e-15 ***\ngenderNon-binary   7346.5     2779.7   2.643   0.0096 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6740 on 96 degrees of freedom\nMultiple R-squared:  0.851, Adjusted R-squared:  0.8463 \nF-statistic: 182.7 on 3 and 96 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "papers/papers-instructions.html",
    "href": "papers/papers-instructions.html",
    "title": "Instructions for each paper",
    "section": "",
    "text": "These are detailed instructions for each paper. See the syllabus for the due dates for each paper. See also another document for course papers: More information for course papers\n\n\nCourse papers require that you do original data analysis and write up your results in a manuscript using APA. All papers should be written by you (try to make the text clear but sound professional, though the research questions/theories may be simple) and should include the elements described below. Please give each paper a title!\nEach paper should be written as a narrative essay. In writing the essay, you should structure it by using section headings as indicated for each paper. This should not detract from the narrative form (it should read like a paper not like answers to questions in a problem set). Each theory (or graph) should be described fully in about a paragraph, and more when necessary. Describe and justify the statistical relationship involving the theoretical variables that will be examined (including the variable’s unit of analysis and “what’s the story,” in terms of why we care about the issue(s); this is a great place to insert historical work).\nInclude a graph of some kind along with your opening at the beginning. Next, describe the data that you will be using to examine the theory. Describe the data source and for any survey data used describe the sampling method. For nationally representative data on high school students, I might say something like “The 2009 HSLS longitudinal sample is a two-stage stratified random sample of the nation’s high school students collected at the school level.” This detailed information can usually be found in the code books for the data sets you find. Be mindful, then, that it will require that you review these files in detail as it pertains to your own variables, your own analyses, and its relation to the social issue at hand. Theory is important.\nNext, describe the specific measures you are using and how they were obtained. Comment on how well the measures fit your theoretical variables (i.e., the face validity of the measures). In the case of survey data, report the full question wordings (verbatim) and specify the response categories and report how the variables were coded and recorded. Present the frequency distributions (so your coding and treatment of “missing data” categories can be checked); if you want to comment on the frequency distributions, you should do so in no more than 2-3 sentences (we are interested more in what comes after the distribution of the members of your sample or population!).\nIn your papers, specify the hypotheses for the expected relationships (correlations/regressions) of the variables and present the operational flow graph. Then report the statistical results, describing the tables, etc. and relevant statistics and any additional calculations. Describe to what extent the evidence is consistent with your hypothesis or hypotheses and lends support to your theorizing. What can you conclude about your original theory based upon your analysis? (*Note: Due to space limitations, when presenting exploratory data analysis and in presenting relationships of variables in research and writing, it is often useful to examine and to report simple tables of means or percentages to summarize bivariate relationships as well, especially when these include nominal or ordinal level (categorical) variables. Keep this in mind in doing research and data analysis beyond this course!)",
    "crumbs": [
      "Appendix",
      "Papers",
      "Instructions for each paper"
    ]
  },
  {
    "objectID": "papers/papers-instructions.html#preparing-papers",
    "href": "papers/papers-instructions.html#preparing-papers",
    "title": "Instructions for each paper",
    "section": "",
    "text": "Course papers require that you do original data analysis and write up your results in a manuscript using APA. All papers should be written by you (try to make the text clear but sound professional, though the research questions/theories may be simple) and should include the elements described below. Please give each paper a title!\nEach paper should be written as a narrative essay. In writing the essay, you should structure it by using section headings as indicated for each paper. This should not detract from the narrative form (it should read like a paper not like answers to questions in a problem set). Each theory (or graph) should be described fully in about a paragraph, and more when necessary. Describe and justify the statistical relationship involving the theoretical variables that will be examined (including the variable’s unit of analysis and “what’s the story,” in terms of why we care about the issue(s); this is a great place to insert historical work).\nInclude a graph of some kind along with your opening at the beginning. Next, describe the data that you will be using to examine the theory. Describe the data source and for any survey data used describe the sampling method. For nationally representative data on high school students, I might say something like “The 2009 HSLS longitudinal sample is a two-stage stratified random sample of the nation’s high school students collected at the school level.” This detailed information can usually be found in the code books for the data sets you find. Be mindful, then, that it will require that you review these files in detail as it pertains to your own variables, your own analyses, and its relation to the social issue at hand. Theory is important.\nNext, describe the specific measures you are using and how they were obtained. Comment on how well the measures fit your theoretical variables (i.e., the face validity of the measures). In the case of survey data, report the full question wordings (verbatim) and specify the response categories and report how the variables were coded and recorded. Present the frequency distributions (so your coding and treatment of “missing data” categories can be checked); if you want to comment on the frequency distributions, you should do so in no more than 2-3 sentences (we are interested more in what comes after the distribution of the members of your sample or population!).\nIn your papers, specify the hypotheses for the expected relationships (correlations/regressions) of the variables and present the operational flow graph. Then report the statistical results, describing the tables, etc. and relevant statistics and any additional calculations. Describe to what extent the evidence is consistent with your hypothesis or hypotheses and lends support to your theorizing. What can you conclude about your original theory based upon your analysis? (*Note: Due to space limitations, when presenting exploratory data analysis and in presenting relationships of variables in research and writing, it is often useful to examine and to report simple tables of means or percentages to summarize bivariate relationships as well, especially when these include nominal or ordinal level (categorical) variables. Keep this in mind in doing research and data analysis beyond this course!)",
    "crumbs": [
      "Appendix",
      "Papers",
      "Instructions for each paper"
    ]
  },
  {
    "objectID": "papers/paper3.html",
    "href": "papers/paper3.html",
    "title": "Paper 3",
    "section": "",
    "text": "For review, you may also refer to more information for course papers in two additional documents:\n\nInstructions for papers\nMore information for course papers\n\n\nStep 1: Theory and logic diagram\nPaper #3 is meant for those for whom two papers was not enough!\nFor this paper, we are interested in exploring more advanced theories pertaining to the relationship between variables explored in papers 1 or 2. Specifically, we are interested in understanding the association of characteristics, co-variates, and other relationships. Your paper 3 assignment should align with any goals you have upon completing your studies.\nNote: For your paper, please remember to address the theoretical relationship that the literature has identified between the conceptual variables selected. That is, before describing the measures and the survey you will be using, explain your theory and why you think that your independent variable is having an effect on your dependent variable.\n\n\nStep 2: Variables, Measurement, Hypothesis\nAll variables and analyses should be described in detail.\n\n\nStep 3: Statistical Analysis\nPlease be sure to utilize analyses on the interactions between multiple variables.\n\n\nStep 4: Conclusion\nFor this paper, please be sure to focus on a solid conclusion based on your statistical analysis."
  },
  {
    "objectID": "papers/annotated.html",
    "href": "papers/annotated.html",
    "title": "Annotated Bibliography",
    "section": "",
    "text": "This page will support you with annotated bibliography assignment. In class, we will review how to develop a single file in Markdown format (.Rmd) to produce your annotated bibliography and course papers.\n\nPurpose\nEvery research paper should include a relevant literature review.\nLiterature reviews can help your readers understand the need for your study, outline a paper’s central thesis, and support readers in making sense of closely related results and findings. As a result, literature reviews can come in many different lengths and formats.\nDoing a literature review is similar to doing any kind of research. A literature review should identify a central question, methodology, and also report findings. One effective way to start a literature review is to create an annotated bibliography.\nPrior to starting an annotated bibliography, it is useful to develop a question that will help you explore and better understand theoretical and methodological connections.\n\n\nFraming a question\nLiterature reviews, like most research projects, can begin from a basic question.\n\nDoes income relate to the availability of resources for [a population]?\nAre years of experience for [a sample] related to their perceptions of power?\n\nOnce you have identified a suitable question, you can use keywords to find sources for an annotated bibliography. The library website can be used to search periodicals or sources like the ERIC system, and you can also utilize popular search engines that house similar works, such as Research Rabbit and Google Scholar.\n\n\nAnnotated bibliographies\nAn annotated bibliography is a list of sources about a specific research question or topic. Each source contains a short statement about the contents of the source (e.g., research paper, online article, or other scholarly and/or published works). Annotated bibliographies are not abstracts, although their length and structure may be similar.\nEach source included in an annotated bibliography should begin with an appropriate citation of the source (in APA, MLA, or Chicago style) and a brief description of the purpose and contents of the source, as well as an evaluation or reflection. The inclusion of an evaluation or reflection when summarizing a published source is one effective way to tell the difference between the abstract and the annotation.\nView samples of annotated bibliographies."
  },
  {
    "objectID": "cases/case02-pt1.html",
    "href": "cases/case02-pt1.html",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "",
    "text": "In Case Study 2, we will explore the social politics of maps and globally oriented data to help us make sense of what we mean by a “population.” The case study will integrate a series of new packages, functions, and code to support our explorations.\nThere are two parts to this case study, this is part 1.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#learning-objectives",
    "href": "cases/case02-pt1.html#learning-objectives",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nIn this case study component, you will be introduced to the dplyr package, which is one of the many packages in the tidyverse. The tidyverse is a set of packages that will be used for cleaning and organizing data.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#learning-activities",
    "href": "cases/case02-pt1.html#learning-activities",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Learning Activities",
    "text": "Learning Activities\nBy the end of this case study you will be able to:\n\nInstall and/or update R packages\nAssign data frames to different names for efficient exploration\nGenerate a set of outputs using the dplyr package\nOverwrite a data frame while using the pipe operator\nProduce simple plots using data located in an R package",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#developing-a-workflow",
    "href": "cases/case02-pt1.html#developing-a-workflow",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Developing a workflow",
    "text": "Developing a workflow\nCoding workflows are an essential component of project completion.\nWhen analyzing data, it is important to understand the possible intersections between the context, content, and code. The best way to explore these relationships is by conducting a literature review. Reading about what others have done is more valuable than starting a workflow prematurely.\nTime may be used inefficiently and clear but standard outputs provide narratives that can likely be confirmed by or support what is already in the research literature. Without an understanding of these connections, analytic outputs may do less to move our understanding of issues forward.\nThis case study will help you explore and create your own workflow. The goal of a coding workflow is not to simply copy and paste arguments that you find. Instead, you want to develop clear pathways to identifying solutions as you work with your data.\nThe topics in case study 2 cover one way to approach a new data set. In this case study, you’ll cover how to load data from a package, generate a set of outputs using small code chunks, and produce and submit a few simple plots.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-0.1-check-your-working-directory",
    "href": "cases/case02-pt1.html#task-0.1-check-your-working-directory",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 0.1: Check your working directory",
    "text": "Task 0.1: Check your working directory\nIn your console, type in the following code to ensure you are in the desired directory:\n\ngetwd()\n\nIf you are not in the desired directory, you can change your directory using the associated path. This path should be the same as the project folder that you plan to work out of and set up in lecture five.\n\n# insert your desired path in the parenthesis and remove the #\n# setwd(\"/your/working/directory/goes/here\") \n\nYou can add a new sub-folder manually or under the Files tab in the RStudio IDE.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-0.2-start-a-new-rmarkdown-file",
    "href": "cases/case02-pt1.html#task-0.2-start-a-new-rmarkdown-file",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 0.2: Start a new RMarkdown file",
    "text": "Task 0.2: Start a new RMarkdown file\nOnce you have confirmed that you are in the correct directory, start a new RMarkdown file (.Rmd) and write your preamble.\n\n---\ntitle: \"Case Study 2\"\nauthor: \"Your Full Name\"\ndate: \"2024-09-09\"\noutput:\n  pdf_document: default\n  html_document:\n    theme: flatly\neditor_options:\n  markdown:\n  wrap: sentence\n ---",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-0.3-write-setup-code-chunks",
    "href": "cases/case02-pt1.html#task-0.3-write-setup-code-chunks",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 0.3: Write setup code chunks",
    "text": "Task 0.3: Write setup code chunks\n\n# ```{r, eval=F}\n# install.packages(\"devtools\")\n# library(devtools)",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-0.4-packages-and-libraries",
    "href": "cases/case02-pt1.html#task-0.4-packages-and-libraries",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 0.4: Packages and libraries",
    "text": "Task 0.4: Packages and libraries\n\n# install package\n# install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n# install.packages(\"remotes\", repos = \"http://cran.us.r-project.org\")\n \n# load the necessary libraries\nlibrary(tidyverse) #collection of R packages designed for data science\nlibrary(dplyr)\nlibrary(remotes)\n\nThe dplyr package supports data analyst with efficient data manipulation. As a part of the tidyverse package, the functions included in dplyr we loaded earlier will help you generate efficient workflows. Though, in reality, most analysts transition between classic code found widely on the internet and the more recent dplyr commands.\nThe remotes library will allow you to remotely install critstats data.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-1.1-explore-notes-on-the-social-politics-of-maps",
    "href": "cases/case02-pt1.html#task-1.1-explore-notes-on-the-social-politics-of-maps",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 1.1: Explore notes on the social politics of maps",
    "text": "Task 1.1: Explore notes on the social politics of maps\n\nWhat is a map? This National Geographic education resource presents a clear overview of maps, geography, and Geographic Information Systems (GIS).\nWhat’s the real size of Africa? is a CNN Africa Marketplace article that examines the Western foundations of maps and representations of the African continent.\nVaughan (2018) is an open access publication on the spatial dimensions of social cartography. The text contains valuable information about how maps have been used to understand health and human development issues, such as poverty, disease, housing, and the like. The text also contains notes on race and nationality, crime and disorder, and a host of references for further reading.\nManson & Matson (2017) present an overview of society and mapping with new technological tools. While doing so, the authors provide a history of maps and examine the basic social elements of maps, the technical elements of maps, and how maps have been integrated into liberal arts education.\nCrampton (2015) writes on Maps and the Social Construction of Race in a larger volume on maps produced by the University of Chicago Press.\nAlderman & Inwood (2021) describe how Black cartographers use maps to examine issues of racial inequality. The authors provide a more focused discussion on the social politics of maps, as opposed to a more general overview of their functions.\nCan maps be racist? Palmer (2014) provides some context to understand the technical aspects of maps as they relate to our social construction of the global world. In this review, the author situates the common functions of maps onto the social dimensions while attending to the particular periods of the development and construction of global maps; thus integrating the political dimension of knowledge creation via map making.\n– Britton (2021) in a blog post on the “non-racism of maps” offers a very different perspective on the Mercator projection. The author focuses on ideology and science in modern society. He argues that the original purpose of maps does not make them racist.\nHow maps distort our perception of the world is a short and focused resource written by Lee (2023) on the Anti-Racism Daily site. The author focuses on the social politics of perception.\n\n\n\n\nThe world’s continents. Image from https://www.visualcapitalist.com/map-true-size-of-africa/",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-1.2-load-the-true_size-data",
    "href": "cases/case02-pt1.html#task-1.2-load-the-true_size-data",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 1.2: Load the true_size data",
    "text": "Task 1.2: Load the true_size data\n\nTask 1.2.1: Install the critstats package\nTo begin, we will install and/or update the installation of critstats.\n\n# use the remote install function to call in your data\nremotes::install_github(\"professornaite/critstats\", force=TRUE)\n\n# load the `critstats` library\nlibrary(critstats)\n\n# update the `critstats` package if needed\n# update.packages(\"critstats\")\n\n\n\nTask 1.2.2: Call the true_size data\n\ncritstats::true_size\n\n\n\nTask 1.2.3: Inspect the true_size documentation\nUsing the ??data prompt, you can inspect the contents of the data frame.\n\n??critstats::true_size\n\nAs noted before, this serves as the data’s documentation and is the basis of a code book (or codebook). A codebook contains very specific details about a database, data set, and the variables each contains. We will explore codebooks more in the future.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-1.3-explore-the-true_size-data",
    "href": "cases/case02-pt1.html#task-1.3-explore-the-true_size-data",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 1.3: Explore the true_size data",
    "text": "Task 1.3: Explore the true_size data\n\nTask 1.3.1: Assign the true_size data frame to df1\nUse the assignment operator to assign the true_size data frame to the object df1.\n\ndf1 &lt;- critstats::true_size\n\n\n\nTask 1.3.2: Inspect your data\nUse the str() function to inspect your data frame.\nstr() displays the structure of R objects.\n\nstr(df1)\n\ntibble [18 × 4] (S3: tbl_df/tbl/data.frame)\n $ Country       : chr [1:18] \"United States\" \"China\" \"India\" \"Mexico\" ...\n $ percent.africa: num [1:18] 32.4 31.6 10.8 6.5 4.2 2.1 1.7 1.5 1.5 1.3 ...\n $ area.sq.km    : num [1:18] 9.83 9.6 3.29 1.96 1.29 0.64 0.51 0.46 0.45 0.38 ...\n $ area.sq.mi    : num [1:18] 3.8 3.71 1.27 0.76 0.5 0.25 0.2 0.18 0.17 0.15 ...\n\n\nYou can also run similar commands separately:\n\nTask 1.3.2a: dim()\nUse the dim() function to check the dimensions of your data.\n\n# check the dimensions of your data\ndim(df1)\n\n[1] 18  4\n\n\nNote that the dimensions are reported as a \\(n \\times m\\) matrix with \\(n\\) rows and \\(m\\) columns.\n\n\nTask 1.3.2b: view()\nUse the View() function to see all of your data in a separate window.\n\n# view the data\nView(df1)\n\n\n\nTask 1.3.2c: glimpse()\nTake a glimpse of your data using the glimpse() function.\n\n# get a glimpse of your data frame\nglimpse(df1)\n\nRows: 18\nColumns: 4\n$ Country        &lt;chr&gt; \"United States\", \"China\", \"India\", \"Mexico\", \"Peru\", \"F…\n$ percent.africa &lt;dbl&gt; 32.4, 31.6, 10.8, 6.5, 4.2, 2.1, 1.7, 1.5, 1.5, 1.3, 1.…\n$ area.sq.km     &lt;dbl&gt; 9.83, 9.60, 3.29, 1.96, 1.29, 0.64, 0.51, 0.46, 0.45, 0…\n$ area.sq.mi     &lt;dbl&gt; 3.80, 3.71, 1.27, 0.76, 0.50, 0.25, 0.20, 0.18, 0.17, 0…\n\n\n\n\nTask 1.3.2d: head()\nView the first six observations in your data using the head() function.\n\n# view the \"top\" of your data\nhead(df1)\n\n# A tibble: 6 × 4\n  Country       percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 United States           32.4       9.83       3.8 \n2 China                   31.6       9.6        3.71\n3 India                   10.8       3.29       1.27\n4 Mexico                   6.5       1.96       0.76\n5 Peru                     4.2       1.29       0.5 \n6 France                   2.1       0.64       0.25\n\n\n\n\nTask 1.3.2e: tail()\nView the last six observations in your data using the tail() function.\n\n# view the \"bottom\" of your data\ntail(df1)\n\n# A tibble: 6 × 4\n  Country        percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Italy                     1         0.3        0.12\n2 New Zealand               0.9       0.27       0.1 \n3 United Kingdom            0.8       0.24       0.09\n4 Nepal                     0.5       0.15       0.06\n5 Bangladesh                0.5       0.15       0.06\n6 Greece                    0.4       0.13       0.05\n\n\n\n\nTask 1.3.2f: Specify n in head() or tail()\nYou can change the number of observations viewed by being more explicit in your code.\n\nhead(df1, n = 10) # view the top 10 observations\n\n# A tibble: 10 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n\ntail(df1, n = 3) # view the bottom 3 observations\n\n# A tibble: 3 × 4\n  Country    percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Nepal                 0.5       0.15       0.06\n2 Bangladesh            0.5       0.15       0.06\n3 Greece                0.4       0.13       0.05\n\n\n\n\nTask 1.3.2g: summary()\nGet a summary of all variables in the data set.\n\n# get a summary of your data frame\nsummary(df1)\n\n   Country          percent.africa     area.sq.km       area.sq.mi    \n Length:18          Min.   : 0.400   Min.   :0.1300   Min.   :0.0500  \n Class :character   1st Qu.: 0.925   1st Qu.:0.2775   1st Qu.:0.1050  \n Mode  :character   Median : 1.400   Median :0.4150   Median :0.1600  \n                    Mean   : 5.556   Mean   :1.6850   Mean   :0.6522  \n                    3rd Qu.: 3.675   3rd Qu.:1.1275   3rd Qu.:0.4375  \n                    Max.   :32.400   Max.   :9.8300   Max.   :3.8000",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#task-1.4-use-dplyr-verbs-on-true_size",
    "href": "cases/case02-pt1.html#task-1.4-use-dplyr-verbs-on-true_size",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Task 1.4: Use dplyr verbs on true_size",
    "text": "Task 1.4: Use dplyr verbs on true_size\nIn this section, we will review the dplyr verbs that help us get our data into a format that works for our analysis. These verbs can be used in any order. We can also use the pipe operator %&gt;% and use multiple verbs in a single code chunk.\n\nTask 1.4.1: Subset columns (variables) using select()\nThe select() command retains only those columns that are listed.\nIt uses the logic select(data, variable1, variable2, ...).\n\n# keep only the Country and percent.africa columns\nselect(df1, Country, percent.africa) \n\n# A tibble: 18 × 2\n   Country          percent.africa\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 United States              32.4\n 2 China                      31.6\n 3 India                      10.8\n 4 Mexico                      6.5\n 5 Peru                        4.2\n 6 France                      2.1\n 7 Spain                       1.7\n 8 Papua New Guinea            1.5\n 9 Sweden                      1.5\n10 Japan                       1.3\n11 Germany                     1.2\n12 Norway                      1.1\n13 Italy                       1  \n14 New Zealand                 0.9\n15 United Kingdom              0.8\n16 Nepal                       0.5\n17 Bangladesh                  0.5\n18 Greece                      0.4\n\n# keep only the Country and area.sq.mi columns\nselect(df1, Country, area.sq.mi)\n\n# A tibble: 18 × 2\n   Country          area.sq.mi\n   &lt;chr&gt;                 &lt;dbl&gt;\n 1 United States          3.8 \n 2 China                  3.71\n 3 India                  1.27\n 4 Mexico                 0.76\n 5 Peru                   0.5 \n 6 France                 0.25\n 7 Spain                  0.2 \n 8 Papua New Guinea       0.18\n 9 Sweden                 0.17\n10 Japan                  0.15\n11 Germany                0.14\n12 Norway                 0.13\n13 Italy                  0.12\n14 New Zealand            0.1 \n15 United Kingdom         0.09\n16 Nepal                  0.06\n17 Bangladesh             0.06\n18 Greece                 0.05\n\n\nWe can also subset columns by deleting others\nTo do so, we use a minus sign ahead of the column names.\n\n# remove the area.sq.mi variable\nselect(df1, -area.sq.km)\n\n# A tibble: 18 × 3\n   Country          percent.africa area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       3.8 \n 2 China                      31.6       3.71\n 3 India                      10.8       1.27\n 4 Mexico                      6.5       0.76\n 5 Peru                        4.2       0.5 \n 6 France                      2.1       0.25\n 7 Spain                       1.7       0.2 \n 8 Papua New Guinea            1.5       0.18\n 9 Sweden                      1.5       0.17\n10 Japan                       1.3       0.15\n11 Germany                     1.2       0.14\n12 Norway                      1.1       0.13\n13 Italy                       1         0.12\n14 New Zealand                 0.9       0.1 \n15 United Kingdom              0.8       0.09\n16 Nepal                       0.5       0.06\n17 Bangladesh                  0.5       0.06\n18 Greece                      0.4       0.05\n\n# remove the listed variables in the data frame\nselect(df1, -area.sq.km, -area.sq.mi) \n\n# A tibble: 18 × 2\n   Country          percent.africa\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 United States              32.4\n 2 China                      31.6\n 3 India                      10.8\n 4 Mexico                      6.5\n 5 Peru                        4.2\n 6 France                      2.1\n 7 Spain                       1.7\n 8 Papua New Guinea            1.5\n 9 Sweden                      1.5\n10 Japan                       1.3\n11 Germany                     1.2\n12 Norway                      1.1\n13 Italy                       1  \n14 New Zealand                 0.9\n15 United Kingdom              0.8\n16 Nepal                       0.5\n17 Bangladesh                  0.5\n18 Greece                      0.4\n\n\n\n\nTask 1.4.2: Filter rows (cases) using filter()\nfilter() allows us to select rows based on specific criteria.\n\n# keep only those rows where the percent.africa value is grater than 30\nfilter(df1, percent.africa &gt; 30)\n\n# A tibble: 2 × 4\n  Country       percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 United States           32.4       9.83       3.8 \n2 China                   31.6       9.6        3.71\n\n# keep only those rows where the percent.africa value is less than 1\nfilter(df1, percent.africa &lt; 1)\n\n# A tibble: 5 × 4\n  Country        percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 New Zealand               0.9       0.27       0.1 \n2 United Kingdom            0.8       0.24       0.09\n3 Nepal                     0.5       0.15       0.06\n4 Bangladesh                0.5       0.15       0.06\n5 Greece                    0.4       0.13       0.05\n\n# keep only those rows where percent.africa is less than 10 and greater than 1\nfilter(df1, percent.africa &lt; 10 & percent.africa &gt; 1)\n\n# A tibble: 9 × 4\n  Country          percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Mexico                      6.5       1.96       0.76\n2 Peru                        4.2       1.29       0.5 \n3 France                      2.1       0.64       0.25\n4 Spain                       1.7       0.51       0.2 \n5 Papua New Guinea            1.5       0.46       0.18\n6 Sweden                      1.5       0.45       0.17\n7 Japan                       1.3       0.38       0.15\n8 Germany                     1.2       0.36       0.14\n9 Norway                      1.1       0.32       0.13\n\n# keep only those rows where Country is equal to \"China\"\nfilter(df1, Country == \"China\")\n\n# A tibble: 1 × 4\n  Country percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 China             31.6        9.6       3.71\n\n\nNotice the use of a == equal sign when referencing a cell’s value. This will become an important component of base logic and analysis when writing code.\n\n\nTask 1.4.3: Add/remove columns (variables) using mutate()\nWe use mutate() to create new variables from existing variables.\nIt is not clear what area.sq.mi and area.sq.km refer to in our data. Further inspection and a bit of internet searching will show us that these values are in the millions and that they represent estimates.\nWe can transform these as follows:\n\n# add a new column with a more accurate label for land area estimate (sq mi)\nmutate(df1, est.square.miles = df1$area.sq.mi * 1000000) \n\n# A tibble: 18 × 5\n   Country          percent.africa area.sq.km area.sq.mi est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8           3800000\n 2 China                      31.6       9.6        3.71          3710000\n 3 India                      10.8       3.29       1.27          1270000\n 4 Mexico                      6.5       1.96       0.76           760000\n 5 Peru                        4.2       1.29       0.5            500000\n 6 France                      2.1       0.64       0.25           250000\n 7 Spain                       1.7       0.51       0.2            200000\n 8 Papua New Guinea            1.5       0.46       0.18           180000\n 9 Sweden                      1.5       0.45       0.17           170000\n10 Japan                       1.3       0.38       0.15           150000\n11 Germany                     1.2       0.36       0.14           140000\n12 Norway                      1.1       0.32       0.13           130000\n13 Italy                       1         0.3        0.12           120000\n14 New Zealand                 0.9       0.27       0.1            100000\n15 United Kingdom              0.8       0.24       0.09            90000\n16 Nepal                       0.5       0.15       0.06            60000\n17 Bangladesh                  0.5       0.15       0.06            60000\n18 Greece                      0.4       0.13       0.05            50000\n\n\n\nTask 1.4.3a: Add new variables using the pipe %&gt;%\nWe can also use the pipe operator to mutate the variable.\n\n# we can create the same output when using the %&gt;% (pipe)\ndf1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000) \n\n# A tibble: 18 × 5\n   Country          percent.africa area.sq.km area.sq.mi est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8           3800000\n 2 China                      31.6       9.6        3.71          3710000\n 3 India                      10.8       3.29       1.27          1270000\n 4 Mexico                      6.5       1.96       0.76           760000\n 5 Peru                        4.2       1.29       0.5            500000\n 6 France                      2.1       0.64       0.25           250000\n 7 Spain                       1.7       0.51       0.2            200000\n 8 Papua New Guinea            1.5       0.46       0.18           180000\n 9 Sweden                      1.5       0.45       0.17           170000\n10 Japan                       1.3       0.38       0.15           150000\n11 Germany                     1.2       0.36       0.14           140000\n12 Norway                      1.1       0.32       0.13           130000\n13 Italy                       1         0.3        0.12           120000\n14 New Zealand                 0.9       0.27       0.1            100000\n15 United Kingdom              0.8       0.24       0.09            90000\n16 Nepal                       0.5       0.15       0.06            60000\n17 Bangladesh                  0.5       0.15       0.06            60000\n18 Greece                      0.4       0.13       0.05            50000\n\n# add a new column with a more accurate label for land area estimate (sq km)\ndf1 %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000)\n\n# A tibble: 18 × 5\n   Country          percent.africa area.sq.km area.sq.mi est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8        9830000\n 2 China                      31.6       9.6        3.71       9600000\n 3 India                      10.8       3.29       1.27       3290000\n 4 Mexico                      6.5       1.96       0.76       1960000\n 5 Peru                        4.2       1.29       0.5        1290000\n 6 France                      2.1       0.64       0.25        640000\n 7 Spain                       1.7       0.51       0.2         510000\n 8 Papua New Guinea            1.5       0.46       0.18        460000\n 9 Sweden                      1.5       0.45       0.17        450000\n10 Japan                       1.3       0.38       0.15        380000\n11 Germany                     1.2       0.36       0.14        360000\n12 Norway                      1.1       0.32       0.13        320000\n13 Italy                       1         0.3        0.12        300000\n14 New Zealand                 0.9       0.27       0.1         270000\n15 United Kingdom              0.8       0.24       0.09        240000\n16 Nepal                       0.5       0.15       0.06        150000\n17 Bangladesh                  0.5       0.15       0.06        150000\n18 Greece                      0.4       0.13       0.05        130000\n\n\n\n\nTask 1.4.3b: Add new variables and remove old variables\nIt is easiest to put all of the verbs together in a single chunk of code.\n\n# remove the old column; use the pipe command to do both operations at once\ndf1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km) # remove the columns we do not want\n\n# A tibble: 18 × 4\n   Country          percent.africa est.square.miles est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000\n 2 China                      31.6          3710000       9600000\n 3 India                      10.8          1270000       3290000\n 4 Mexico                      6.5           760000       1960000\n 5 Peru                        4.2           500000       1290000\n 6 France                      2.1           250000        640000\n 7 Spain                       1.7           200000        510000\n 8 Papua New Guinea            1.5           180000        460000\n 9 Sweden                      1.5           170000        450000\n10 Japan                       1.3           150000        380000\n11 Germany                     1.2           140000        360000\n12 Norway                      1.1           130000        320000\n13 Italy                       1             120000        300000\n14 New Zealand                 0.9           100000        270000\n15 United Kingdom              0.8            90000        240000\n16 Nepal                       0.5            60000        150000\n17 Bangladesh                  0.5            60000        150000\n18 Greece                      0.4            50000        130000\n\n\nThese values seem to represent the data more clearly.\n\n\n\nTask 1.4.4: Rename a column using rename()\nWe can also use rename() to modify a column’s label.\n\ndf1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km)  %&gt;% \n  rename(country = Country)  # make the 'C' in country lowercase\n\n# A tibble: 18 × 4\n   country          percent.africa est.square.miles est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000\n 2 China                      31.6          3710000       9600000\n 3 India                      10.8          1270000       3290000\n 4 Mexico                      6.5           760000       1960000\n 5 Peru                        4.2           500000       1290000\n 6 France                      2.1           250000        640000\n 7 Spain                       1.7           200000        510000\n 8 Papua New Guinea            1.5           180000        460000\n 9 Sweden                      1.5           170000        450000\n10 Japan                       1.3           150000        380000\n11 Germany                     1.2           140000        360000\n12 Norway                      1.1           130000        320000\n13 Italy                       1             120000        300000\n14 New Zealand                 0.9           100000        270000\n15 United Kingdom              0.8            90000        240000\n16 Nepal                       0.5            60000        150000\n17 Bangladesh                  0.5            60000        150000\n18 Greece                      0.4            50000        130000\n\n\n\n\nTask 1.4.5: Use relocate() to reorder the columns\n\ndf1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km)  %&gt;% \n  rename(country = Country) %&gt;% \n  relocate(country, percent.africa, est.square.miles) # reorder the columns\n\n# A tibble: 18 × 4\n   country          percent.africa est.square.miles est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000\n 2 China                      31.6          3710000       9600000\n 3 India                      10.8          1270000       3290000\n 4 Mexico                      6.5           760000       1960000\n 5 Peru                        4.2           500000       1290000\n 6 France                      2.1           250000        640000\n 7 Spain                       1.7           200000        510000\n 8 Papua New Guinea            1.5           180000        460000\n 9 Sweden                      1.5           170000        450000\n10 Japan                       1.3           150000        380000\n11 Germany                     1.2           140000        360000\n12 Norway                      1.1           130000        320000\n13 Italy                       1             120000        300000\n14 New Zealand                 0.9           100000        270000\n15 United Kingdom              0.8            90000        240000\n16 Nepal                       0.5            60000        150000\n17 Bangladesh                  0.5            60000        150000\n18 Greece                      0.4            50000        130000\n\n\n\n\nTask 1.4.6: Overwrite your data frame\nNow that we’ve restructured the data into a format that is more accurate, we can reassign our data frame using the pipe operator. Take note of how the code is built with new commands starting on a new line and ending with the %&gt;% operator.\n\ntrue_size_modified &lt;- df1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km)  %&gt;% \n  rename(country = Country) %&gt;% \n  relocate(country, percent.africa, est.square.miles) # reorder the columns\n\nNow view your modified data frame.\n\ntrue_size_modified\n\n# A tibble: 18 × 4\n   country          percent.africa est.square.miles est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000\n 2 China                      31.6          3710000       9600000\n 3 India                      10.8          1270000       3290000\n 4 Mexico                      6.5           760000       1960000\n 5 Peru                        4.2           500000       1290000\n 6 France                      2.1           250000        640000\n 7 Spain                       1.7           200000        510000\n 8 Papua New Guinea            1.5           180000        460000\n 9 Sweden                      1.5           170000        450000\n10 Japan                       1.3           150000        380000\n11 Germany                     1.2           140000        360000\n12 Norway                      1.1           130000        320000\n13 Italy                       1             120000        300000\n14 New Zealand                 0.9           100000        270000\n15 United Kingdom              0.8            90000        240000\n16 Nepal                       0.5            60000        150000\n17 Bangladesh                  0.5            60000        150000\n18 Greece                      0.4            50000        130000\n\n\n\n\nTask 1.4.7: Explore summarise(), arrange(), and other verbs\nThere are other verbs in the dplyr package.\nFor example, we will use the summarise() and arrange() commands in the next part of the case study.\nYou can learn more about other dplyr data transformations here.\n\nNow that you have a few tools to explore and modify data frames, we return to the africa_data_all data in the critstats package. We will use this data frame to work more with dplyr and explore univariate analyses.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#report-1.1",
    "href": "cases/case02-pt1.html#report-1.1",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Report 1.1",
    "text": "Report 1.1\nWhat are some of the main concepts in Vaughan (2018)? Could the data in the true_size data be used to respond to and advance our understanding of the concepts in Vaughan (2018)? If so, how might it be used to examine both the social context (period) and historical consequences (uses) of inequity in map making? If not, explain.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#report-1.2",
    "href": "cases/case02-pt1.html#report-1.2",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Report 1.2",
    "text": "Report 1.2\nIf the data in true_size_modified is accurate, what is the expected correlation between the percent.africa and est.square.miles variables? Specifically, why do we get the below scatter plot based on the data values?",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#report-1.3",
    "href": "cases/case02-pt1.html#report-1.3",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Report 1.3",
    "text": "Report 1.3\nBased on the original values in the true_size data, is there enough information to confirm if the claims about the size of Africa and the social politics of maps is true? Explain why or why not.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#report-1.4",
    "href": "cases/case02-pt1.html#report-1.4",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Report 1.4",
    "text": "Report 1.4\nWrite code to add a new variable to the true_size_modified data called proportion.\nUse mutate() and arithmetic to generate the new variable.\nHint: If \\(Y\\) = proportion, then \\(y_i = \\dfrac{x_i}{sum(x)}\\) for some variable \\(X\\) in data set.\n\n\nRows: 18\nColumns: 5\n$ country          &lt;chr&gt; \"United States\", \"China\", \"India\", \"Mexico\", \"Peru\", …\n$ percent.africa   &lt;dbl&gt; 32.4, 31.6, 10.8, 6.5, 4.2, 2.1, 1.7, 1.5, 1.5, 1.3, …\n$ est.square.miles &lt;dbl&gt; 3800000, 3710000, 1270000, 760000, 500000, 250000, 20…\n$ est.square.km    &lt;dbl&gt; 9830000, 9600000, 3290000, 1960000, 1290000, 640000, …\n$ proportion       &lt;dbl&gt; 0.323679727, 0.316013629, 0.108177172, 0.064735945, 0…\n\n\n# A tibble: 6 × 5\n  country       percent.africa est.square.miles est.square.km proportion\n  &lt;chr&gt;                  &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 United States           32.4          3800000       9830000     0.324 \n2 China                   31.6          3710000       9600000     0.316 \n3 India                   10.8          1270000       3290000     0.108 \n4 Mexico                   6.5           760000       1960000     0.0647\n5 Peru                     4.2           500000       1290000     0.0426\n6 France                   2.1           250000        640000     0.0213\n\n\nOverwrite true_size_modified with a new data framed titled true_size_updated.\nYou should be able to call the data as follows:\n\ntrue_size_updated\n\n# A tibble: 18 × 5\n   country          percent.africa est.square.miles est.square.km proportion\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000    0.324  \n 2 China                      31.6          3710000       9600000    0.316  \n 3 India                      10.8          1270000       3290000    0.108  \n 4 Mexico                      6.5           760000       1960000    0.0647 \n 5 Peru                        4.2           500000       1290000    0.0426 \n 6 France                      2.1           250000        640000    0.0213 \n 7 Spain                       1.7           200000        510000    0.0170 \n 8 Papua New Guinea            1.5           180000        460000    0.0153 \n 9 Sweden                      1.5           170000        450000    0.0145 \n10 Japan                       1.3           150000        380000    0.0128 \n11 Germany                     1.2           140000        360000    0.0119 \n12 Norway                      1.1           130000        320000    0.0111 \n13 Italy                       1             120000        300000    0.0102 \n14 New Zealand                 0.9           100000        270000    0.00852\n15 United Kingdom              0.8            90000        240000    0.00767\n16 Nepal                       0.5            60000        150000    0.00511\n17 Bangladesh                  0.5            60000        150000    0.00511\n18 Greece                      0.4            50000        130000    0.00426",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case02-pt1.html#report-1.5",
    "href": "cases/case02-pt1.html#report-1.5",
    "title": "Case Study 2, Part 1: The True Size of Africa",
    "section": "Report 1.5",
    "text": "Report 1.5\nTo confirm that you have generated the new variable and overwritten the data frame, create the plot below using the following code. Be sure to add your first name and last name in the quotes.\nThe code should be verbatim with the exception of your name.\n\nplot(true_size_updated$proportion, true_size_updated$percent.africa)\ntitle(\"first.name last.name\") # Add your first name and last name\n\n\n\n\n\n\n\n\nFor example, my code would read:\n\nplot(true_size_updated$proportion, true_size_updated$percent.africa)\ntitle(\"Nathan Alexander\") # Add your first name and last name\n\n\n\n\n\n\n\n\nNotice the use of quotes when using title() under a plot.\nIf you experience issues making the plot, it is likely that you have made an error in the previous steps. Remember that R is case sensitive in all instances, and space sensitive in some instances.\nPlease be sure to go back and carefully check your code.\n{Save this plot as a pdf and submit it with case study files.",
    "crumbs": [
      "Appendix",
      "Case Studies",
      "Case Study 2, pt. 1"
    ]
  },
  {
    "objectID": "cases/case-02-test.html",
    "href": "cases/case-02-test.html",
    "title": "Untitled",
    "section": "",
    "text": "# load libraries for this session\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(remotes)\n\nLoad the critstats package.\n\n# use the remote install function to call in your data\n# remotes::install_github(\"professornaite/critstats\", force=TRUE)\n\n# load the critstats library\nlibrary(critstats)\n\nLoad the true_size data frame in the critstats package.\n\ncritstats::true_size\n\n# A tibble: 18 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n11 Germany                     1.2       0.36       0.14\n12 Norway                      1.1       0.32       0.13\n13 Italy                       1         0.3        0.12\n14 New Zealand                 0.9       0.27       0.1 \n15 United Kingdom              0.8       0.24       0.09\n16 Nepal                       0.5       0.15       0.06\n17 Bangladesh                  0.5       0.15       0.06\n18 Greece                      0.4       0.13       0.05\n\n\nLabel my true_size data frame as df1.\n\ndf1 &lt;- critstats::true_size\ndf1\n\n# A tibble: 18 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n11 Germany                     1.2       0.36       0.14\n12 Norway                      1.1       0.32       0.13\n13 Italy                       1         0.3        0.12\n14 New Zealand                 0.9       0.27       0.1 \n15 United Kingdom              0.8       0.24       0.09\n16 Nepal                       0.5       0.15       0.06\n17 Bangladesh                  0.5       0.15       0.06\n18 Greece                      0.4       0.13       0.05\n\n\nInspect the data.\n\nstr(df1) # This will show us the structure of data frame 1 (df1)\n\ntibble [18 × 4] (S3: tbl_df/tbl/data.frame)\n $ Country       : chr [1:18] \"United States\" \"China\" \"India\" \"Mexico\" ...\n $ percent.africa: num [1:18] 32.4 31.6 10.8 6.5 4.2 2.1 1.7 1.5 1.5 1.3 ...\n $ area.sq.km    : num [1:18] 9.83 9.6 3.29 1.96 1.29 0.64 0.51 0.46 0.45 0.38 ...\n $ area.sq.mi    : num [1:18] 3.8 3.71 1.27 0.76 0.5 0.25 0.2 0.18 0.17 0.15 ...\n\ndim(df1) # This will show me the dimensions of the data frame\n\n[1] 18  4\n\nglimpse(df1) # This will give you an output that is similar to str(df1) but it doesn't have as much info\n\nRows: 18\nColumns: 4\n$ Country        &lt;chr&gt; \"United States\", \"China\", \"India\", \"Mexico\", \"Peru\", \"F…\n$ percent.africa &lt;dbl&gt; 32.4, 31.6, 10.8, 6.5, 4.2, 2.1, 1.7, 1.5, 1.5, 1.3, 1.…\n$ area.sq.km     &lt;dbl&gt; 9.83, 9.60, 3.29, 1.96, 1.29, 0.64, 0.51, 0.46, 0.45, 0…\n$ area.sq.mi     &lt;dbl&gt; 3.80, 3.71, 1.27, 0.76, 0.50, 0.25, 0.20, 0.18, 0.17, 0…\n\n\nView the top part and bottom part of our data frame.\n\nhead(df1)\n\n# A tibble: 6 × 4\n  Country       percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 United States           32.4       9.83       3.8 \n2 China                   31.6       9.6        3.71\n3 India                   10.8       3.29       1.27\n4 Mexico                   6.5       1.96       0.76\n5 Peru                     4.2       1.29       0.5 \n6 France                   2.1       0.64       0.25\n\ntail(df1)\n\n# A tibble: 6 × 4\n  Country        percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Italy                     1         0.3        0.12\n2 New Zealand               0.9       0.27       0.1 \n3 United Kingdom            0.8       0.24       0.09\n4 Nepal                     0.5       0.15       0.06\n5 Bangladesh                0.5       0.15       0.06\n6 Greece                    0.4       0.13       0.05\n\nhead(df1, n = 10)\n\n# A tibble: 10 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n\ntail(df1, n = 10)\n\n# A tibble: 10 × 4\n   Country        percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Sweden                    1.5       0.45       0.17\n 2 Japan                     1.3       0.38       0.15\n 3 Germany                   1.2       0.36       0.14\n 4 Norway                    1.1       0.32       0.13\n 5 Italy                     1         0.3        0.12\n 6 New Zealand               0.9       0.27       0.1 \n 7 United Kingdom            0.8       0.24       0.09\n 8 Nepal                     0.5       0.15       0.06\n 9 Bangladesh                0.5       0.15       0.06\n10 Greece                    0.4       0.13       0.05\n\n\nView a summary of the data frame.\n\nsummary(df1)\n\n   Country          percent.africa     area.sq.km       area.sq.mi    \n Length:18          Min.   : 0.400   Min.   :0.1300   Min.   :0.0500  \n Class :character   1st Qu.: 0.925   1st Qu.:0.2775   1st Qu.:0.1050  \n Mode  :character   Median : 1.400   Median :0.4150   Median :0.1600  \n                    Mean   : 5.556   Mean   :1.6850   Mean   :0.6522  \n                    3rd Qu.: 3.675   3rd Qu.:1.1275   3rd Qu.:0.4375  \n                    Max.   :32.400   Max.   :9.8300   Max.   :3.8000  \n\n\nWe’ll look at some of the dplyr variables.\n\nselect(df1, Country, percent.africa)\n\n# A tibble: 18 × 2\n   Country          percent.africa\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 United States              32.4\n 2 China                      31.6\n 3 India                      10.8\n 4 Mexico                      6.5\n 5 Peru                        4.2\n 6 France                      2.1\n 7 Spain                       1.7\n 8 Papua New Guinea            1.5\n 9 Sweden                      1.5\n10 Japan                       1.3\n11 Germany                     1.2\n12 Norway                      1.1\n13 Italy                       1  \n14 New Zealand                 0.9\n15 United Kingdom              0.8\n16 Nepal                       0.5\n17 Bangladesh                  0.5\n18 Greece                      0.4\n\nselect(df1, -area.sq.km)\n\n# A tibble: 18 × 3\n   Country          percent.africa area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       3.8 \n 2 China                      31.6       3.71\n 3 India                      10.8       1.27\n 4 Mexico                      6.5       0.76\n 5 Peru                        4.2       0.5 \n 6 France                      2.1       0.25\n 7 Spain                       1.7       0.2 \n 8 Papua New Guinea            1.5       0.18\n 9 Sweden                      1.5       0.17\n10 Japan                       1.3       0.15\n11 Germany                     1.2       0.14\n12 Norway                      1.1       0.13\n13 Italy                       1         0.12\n14 New Zealand                 0.9       0.1 \n15 United Kingdom              0.8       0.09\n16 Nepal                       0.5       0.06\n17 Bangladesh                  0.5       0.06\n18 Greece                      0.4       0.05\n\n\nWe use filter to select row, or deselect rows in our data frame.\n\nfilter(df1, percent.africa &gt; 30)\n\n# A tibble: 2 × 4\n  Country       percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 United States           32.4       9.83       3.8 \n2 China                   31.6       9.6        3.71\n\nfilter(df1, percent.africa &lt; 1)\n\n# A tibble: 5 × 4\n  Country        percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 New Zealand               0.9       0.27       0.1 \n2 United Kingdom            0.8       0.24       0.09\n3 Nepal                     0.5       0.15       0.06\n4 Bangladesh                0.5       0.15       0.06\n5 Greece                    0.4       0.13       0.05\n\nfilter(df1, percent.africa &lt; 11 & percent.africa &gt; 0)\n\n# A tibble: 16 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 India                      10.8       3.29       1.27\n 2 Mexico                      6.5       1.96       0.76\n 3 Peru                        4.2       1.29       0.5 \n 4 France                      2.1       0.64       0.25\n 5 Spain                       1.7       0.51       0.2 \n 6 Papua New Guinea            1.5       0.46       0.18\n 7 Sweden                      1.5       0.45       0.17\n 8 Japan                       1.3       0.38       0.15\n 9 Germany                     1.2       0.36       0.14\n10 Norway                      1.1       0.32       0.13\n11 Italy                       1         0.3        0.12\n12 New Zealand                 0.9       0.27       0.1 \n13 United Kingdom              0.8       0.24       0.09\n14 Nepal                       0.5       0.15       0.06\n15 Bangladesh                  0.5       0.15       0.06\n16 Greece                      0.4       0.13       0.05\n\n\n\ndf1\n\n# A tibble: 18 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n11 Germany                     1.2       0.36       0.14\n12 Norway                      1.1       0.32       0.13\n13 Italy                       1         0.3        0.12\n14 New Zealand                 0.9       0.27       0.1 \n15 United Kingdom              0.8       0.24       0.09\n16 Nepal                       0.5       0.15       0.06\n17 Bangladesh                  0.5       0.15       0.06\n18 Greece                      0.4       0.13       0.05\n\nfilter(df1, Country == \"China\")\n\n# A tibble: 1 × 4\n  Country percent.africa area.sq.km area.sq.mi\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 China             31.6        9.6       3.71\n\n\nAdd and remove columns from a data set.\n\nmutate(df1, est.square.miles = df1$area.sq.mi * 1000000)\n\n# A tibble: 18 × 5\n   Country          percent.africa area.sq.km area.sq.mi est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8           3800000\n 2 China                      31.6       9.6        3.71          3710000\n 3 India                      10.8       3.29       1.27          1270000\n 4 Mexico                      6.5       1.96       0.76           760000\n 5 Peru                        4.2       1.29       0.5            500000\n 6 France                      2.1       0.64       0.25           250000\n 7 Spain                       1.7       0.51       0.2            200000\n 8 Papua New Guinea            1.5       0.46       0.18           180000\n 9 Sweden                      1.5       0.45       0.17           170000\n10 Japan                       1.3       0.38       0.15           150000\n11 Germany                     1.2       0.36       0.14           140000\n12 Norway                      1.1       0.32       0.13           130000\n13 Italy                       1         0.3        0.12           120000\n14 New Zealand                 0.9       0.27       0.1            100000\n15 United Kingdom              0.8       0.24       0.09            90000\n16 Nepal                       0.5       0.15       0.06            60000\n17 Bangladesh                  0.5       0.15       0.06            60000\n18 Greece                      0.4       0.13       0.05            50000\n\n# let's use a pipe %&gt;% to run the same operation as above\n# the pipe operator literally means \"and then\"\ndf1 %&gt;%\n  mutate(est.square.miles = df1$area.sq.mi * 1000000)\n\n# A tibble: 18 × 5\n   Country          percent.africa area.sq.km area.sq.mi est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8           3800000\n 2 China                      31.6       9.6        3.71          3710000\n 3 India                      10.8       3.29       1.27          1270000\n 4 Mexico                      6.5       1.96       0.76           760000\n 5 Peru                        4.2       1.29       0.5            500000\n 6 France                      2.1       0.64       0.25           250000\n 7 Spain                       1.7       0.51       0.2            200000\n 8 Papua New Guinea            1.5       0.46       0.18           180000\n 9 Sweden                      1.5       0.45       0.17           170000\n10 Japan                       1.3       0.38       0.15           150000\n11 Germany                     1.2       0.36       0.14           140000\n12 Norway                      1.1       0.32       0.13           130000\n13 Italy                       1         0.3        0.12           120000\n14 New Zealand                 0.9       0.27       0.1            100000\n15 United Kingdom              0.8       0.24       0.09            90000\n16 Nepal                       0.5       0.15       0.06            60000\n17 Bangladesh                  0.5       0.15       0.06            60000\n18 Greece                      0.4       0.13       0.05            50000\n\n\nAdd two new variables and remove the old variables.\n\ndf1 %&gt;% \n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km) # remove the columns that we do not need\n\n# A tibble: 18 × 4\n   Country          percent.africa est.square.miles est.square.km\n   &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 United States              32.4          3800000       9830000\n 2 China                      31.6          3710000       9600000\n 3 India                      10.8          1270000       3290000\n 4 Mexico                      6.5           760000       1960000\n 5 Peru                        4.2           500000       1290000\n 6 France                      2.1           250000        640000\n 7 Spain                       1.7           200000        510000\n 8 Papua New Guinea            1.5           180000        460000\n 9 Sweden                      1.5           170000        450000\n10 Japan                       1.3           150000        380000\n11 Germany                     1.2           140000        360000\n12 Norway                      1.1           130000        320000\n13 Italy                       1             120000        300000\n14 New Zealand                 0.9           100000        270000\n15 United Kingdom              0.8            90000        240000\n16 Nepal                       0.5            60000        150000\n17 Bangladesh                  0.5            60000        150000\n18 Greece                      0.4            50000        130000\n\n\n\ndf1 %&gt;% \n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km) %&gt;% # remove the columns that we do not need\n  rename(country = Country) %&gt;% # making the 'C' in the old Country column lowercase\n  relocate(country, percent.africa, est.square.km)\n\n# A tibble: 18 × 4\n   country          percent.africa est.square.km est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9830000          3800000\n 2 China                      31.6       9600000          3710000\n 3 India                      10.8       3290000          1270000\n 4 Mexico                      6.5       1960000           760000\n 5 Peru                        4.2       1290000           500000\n 6 France                      2.1        640000           250000\n 7 Spain                       1.7        510000           200000\n 8 Papua New Guinea            1.5        460000           180000\n 9 Sweden                      1.5        450000           170000\n10 Japan                       1.3        380000           150000\n11 Germany                     1.2        360000           140000\n12 Norway                      1.1        320000           130000\n13 Italy                       1          300000           120000\n14 New Zealand                 0.9        270000           100000\n15 United Kingdom              0.8        240000            90000\n16 Nepal                       0.5        150000            60000\n17 Bangladesh                  0.5        150000            60000\n18 Greece                      0.4        130000            50000\n\n\nOverwrite the data frame with all of the changes that I have made.\n\ntrue_size_modified &lt;- df1 %&gt;% \n  mutate(est.square.miles = df1$area.sq.mi * 1000000) %&gt;% \n  mutate(est.square.km = df1$area.sq.km * 1000000) %&gt;% \n  select(-area.sq.mi, -area.sq.km) %&gt;% # remove the columns that we do not need\n  rename(country = Country) %&gt;% # making the 'C' in the old Country column lowercase\n  relocate(country, percent.africa, est.square.km)\n\ntrue_size_modified\n\n# A tibble: 18 × 4\n   country          percent.africa est.square.km est.square.miles\n   &lt;chr&gt;                     &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n 1 United States              32.4       9830000          3800000\n 2 China                      31.6       9600000          3710000\n 3 India                      10.8       3290000          1270000\n 4 Mexico                      6.5       1960000           760000\n 5 Peru                        4.2       1290000           500000\n 6 France                      2.1        640000           250000\n 7 Spain                       1.7        510000           200000\n 8 Papua New Guinea            1.5        460000           180000\n 9 Sweden                      1.5        450000           170000\n10 Japan                       1.3        380000           150000\n11 Germany                     1.2        360000           140000\n12 Norway                      1.1        320000           130000\n13 Italy                       1          300000           120000\n14 New Zealand                 0.9        270000           100000\n15 United Kingdom              0.8        240000            90000\n16 Nepal                       0.5        150000            60000\n17 Bangladesh                  0.5        150000            60000\n18 Greece                      0.4        130000            50000"
  },
  {
    "objectID": "cases/sample-case-study-1.html",
    "href": "cases/sample-case-study-1.html",
    "title": "Case Study No. 2",
    "section": "",
    "text": "I am updating my working directory.\n\n# getwd() # identify the working directory\n# setwd(\"/Users/nathanalexander/Dropbox/Teaching/Howard/data-202-files/sp25/labs\")"
  },
  {
    "objectID": "cases/sample-case-study-1.html#task-0.1-change-working-directory",
    "href": "cases/sample-case-study-1.html#task-0.1-change-working-directory",
    "title": "Case Study No. 2",
    "section": "",
    "text": "I am updating my working directory.\n\n# getwd() # identify the working directory\n# setwd(\"/Users/nathanalexander/Dropbox/Teaching/Howard/data-202-files/sp25/labs\")"
  },
  {
    "objectID": "cases/sample-case-study-1.html#task-0.4-packages-and-libraries",
    "href": "cases/sample-case-study-1.html#task-0.4-packages-and-libraries",
    "title": "Case Study No. 2",
    "section": "Task 0.4: Packages and libraries",
    "text": "Task 0.4: Packages and libraries\nLoad the packages and libraries for the case study.\n\n# install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n# install.packages(\"remotes\", repos = \"http://cran.us.r-project.org\")\n\n# load the necessary libraries\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(remotes)\n\n\nTask 1.2.1: Load the data\nI am going to load the true_size data frame from the critstats package.\n\n# use the remote install function to call in your data\nremotes::install_github(\"professornaite/critstats\", force=TRUE)\n\nUsing GitHub PAT from the git credential store.\n\n\nDownloading GitHub repo professornaite/critstats@HEAD\n\n\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘/private/var/folders/t2/v2ypghs120z45678ty2nqfk00000gn/T/RtmpOiTR4d/remotes131cd2f2174a7/professornaite-critstats-0016822/DESCRIPTION’ ... OK\n* preparing ‘critstats’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building ‘critstats_0.0.0.9000.tar.gz’\n\n# load the `critstats` library\nlibrary(critstats)\n\n# update the `critstats` package if needed\n# update.packages(\"critstats\")\n\n\n\nTask 1.2.2: Call the true_size data frame.\n\ncritstats::true_size\n\n# A tibble: 18 × 4\n   Country          percent.africa area.sq.km area.sq.mi\n   &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 United States              32.4       9.83       3.8 \n 2 China                      31.6       9.6        3.71\n 3 India                      10.8       3.29       1.27\n 4 Mexico                      6.5       1.96       0.76\n 5 Peru                        4.2       1.29       0.5 \n 6 France                      2.1       0.64       0.25\n 7 Spain                       1.7       0.51       0.2 \n 8 Papua New Guinea            1.5       0.46       0.18\n 9 Sweden                      1.5       0.45       0.17\n10 Japan                       1.3       0.38       0.15\n11 Germany                     1.2       0.36       0.14\n12 Norway                      1.1       0.32       0.13\n13 Italy                       1         0.3        0.12\n14 New Zealand                 0.9       0.27       0.1 \n15 United Kingdom              0.8       0.24       0.09\n16 Nepal                       0.5       0.15       0.06\n17 Bangladesh                  0.5       0.15       0.06\n18 Greece                      0.4       0.13       0.05"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to DATA 202",
    "section": "",
    "text": "Part\nWeek\nDay\nTopics\nLabs\nPapers\nMain reading\n\n\n\n\nI\n1\nWed, Aug 20\nIntroduction to DATA 202\nLab 0\n\nCase study 1\n\n\n\n2\nWed, Aug 27\nFoundations  Measurement, variables, context\n\n\nPelham (2013, ch. 1)\n\n\n\n\nWed, Sept 3\nTheory Construction  Building explanatory frameworks\n\n\nShore (2008)\n\n\n\n\nWed, Sept 10\nProbability Theory  Frameworks for uncertainty\nLab 1\n\nCase study 2\n\n\nII\n\nWed, Sept 17\nUnivariate Analysis  Summarizing distributions\n\n\nFrisby (2024)\n\n\n\n\nWed, Sept 24\nBivariate Analysis  Relationships between two variables\n\n\nZuberi (2000)\n\n\n\n\nWed, Oct 1\nExploratory Analysis  Patterns and anomalies\n\nPaper 1\nKvam et al. (2015)\n\n\n\n\nWed, Oct 8\nHypothesis Testing  Inference in context\nLab 2\n\nGarcia et al. (2018)\n\n\nIII\n\nWed, Oct 15\nNotes on Causal Theories  Thinking about cause and effect\n\n\nCase study 3\n\n\n\n\nWed, Oct 22\nModeling Social In/justice\n\n\nEveritt & Hothorn (2011), ch. 1\n\n\n\n\nWed, Oct 29\nRegression  Modeling relationships\n\n\nWard (2013)\n\n\n\n\nWed, Nov 5\nMultivariable Analysis  Modeling beyond two dimensions\nLab 3\n\nEveritt & Hothorn (2011), ch. 2\n\n\nIV\n\nWed, Nov 12\nWriting Critical Statistics  Framing arguments\n\nPaper 2\nStroup (2015)\n\n\n\n\nWed, Nov 19\nStatistical Learning  Connections, extensions & course wrap-up\n\n\n—",
    "crumbs": [
      "Course information",
      "Course landing page"
    ]
  },
  {
    "objectID": "index.html#site-description",
    "href": "index.html#site-description",
    "title": "Welcome to DATA 202",
    "section": "Site Description",
    "text": "Site Description\nThe pages on this site outline the coding components of the DATA 202: Statistically Measuring and Modeling Social Justice course at Howard University, taught by me: Professor Nathan Alexander. The information on this page will serve as a technical companion to our Canvas site.\nThis page will support you in our course in the following ways: - Help you work with data sets and complete small tasks over time. - Walk you through measurement aspects of research questions relevant to modeling issues of social justice. - Integrate mathematical ideas and technical formulas into your work. - Support your use of theory in your statistical practice, and document reproducible code around social justice topics.\nOur canvas site (click here) contains readings and is where you will submit all assignments.\nWhen turning in assignments on Canvas: - Submit PDFs unless otherwise stated.\n- Only standard links or clear Github repos (no shorteners).\n- RMarkdown (.Rmd) is encouraged for integrating code and analysis.\n\nCredit\n\nDuke University’s STAT 101 course site\n\nNoli Brazil’s Quantitative Methods in Community Research\n\n\n\nNext up: Overview\nThe overview will walk you through the technical flow of the course, show preview topics at the bottom of each page, and outline assignments.",
    "crumbs": [
      "Course information",
      "Course landing page"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "This page will contain resources to support you in our course.",
    "crumbs": [
      "Appendix",
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#the-organic-chemistry-tutors-channel-on-youtube",
    "href": "resources.html#the-organic-chemistry-tutors-channel-on-youtube",
    "title": "Resources",
    "section": "The Organic Chemistry Tutor’s Channel on YouTube",
    "text": "The Organic Chemistry Tutor’s Channel on YouTube\nDespite the profile’s title, this channel offers a wealth of resources spanning mathematics and science. The resources offer detailed examples and explanations that you can follow along with as you watch the video. The below series of video review basic statistics.",
    "crumbs": [
      "Appendix",
      "Resources"
    ]
  }
]